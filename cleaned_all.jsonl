{"id": 3796, "text": "The light sheet system that was funded by the IAA is now managed by Matt Winter a central imaging facility. This is in itself an impact since the system has moved from the developmental stage to a tool that is routinely used for biomedical research.", "entities": [{"id": 1292, "label": "Software", "start_offset": 4, "end_offset": 22}]}
{"id": 3797, "text": "The AR app 'Glastonbury Stories' was developed in collaboration with Arcade immersive heritage and Glastonbury Abbey. It is free to users and can be downloaded from App Store, Play Store and from a webpage on the Glastonbury Abbey website. It was launched to the public in March 2023.", "entities": [{"id": 1494, "label": "Software", "start_offset": 12, "end_offset": 31}]}
{"id": 3798, "text": "A simple method of using existing software for ridge regression to independently penalized two sets of predictors. THis is never less accurate than using either set alone or both sets pooled and treated as one. Applications are predicting traits from a combination of genetic markers and metabolites or predicting hybrid performance from co-dominant markers, fitting separate additive an dominance effects at each. Can be used in genomic selection and association mapping.", "entities": []}
{"id": 3799, "text": "An R script which uses genetic algorithms to select a subset of lines from a larger collection. The algorithm searches for the subset with either the greatest genetic diversity or which captures the greatest number of alleles. This is a replacement for similar functions previously available in the package PowerMarker.", "entities": []}
{"id": 3800, "text": "This tool provides a framework to identify the broad range of influences of different built infrastructure sectors and natural ecosystems and their services across various targets of the Sustainable Development Goals. The tool provides evidence for decision-makers and practitioners on the direct and indirect influences of various services across all SDG targets, as well as an understanding of interdependencies between them.", "entities": []}
{"id": 3801, "text": "LSST DESC Core Cosmology Library (CCL) provides routines to compute basic cosmological observables with validated numerical accuracy. The library is written in C99 and all functionality is directly callable from C and C++ code. We also provide python bindings for higher-level functions. Although CCL has been developed within DESC, it aims to be of use for the cosmology community as a whole, and this has guided is design.", "entities": [{"id": 1057, "label": "Software", "start_offset": 10, "end_offset": 32}, {"id": 1058, "label": "Software", "start_offset": 34, "end_offset": 37}, {"id": 1059, "label": "Software", "start_offset": 297, "end_offset": 300}]}
{"id": 3802, "text": "NaMaster is a software package to compute the power spectrum of any two-dimensional astronomical datasets. It provides generic tools to estimate power spectra in the presence of complex masks, systematic contamination from an arbitrary number of sources and E-B leakage in the case of spin-2 fields. It supports calculations in both curved and flat skies. The code has been designed so it implements generic methods that can be applied to any astronomical dataset, facilitating the joint analysis of a wide range of current and future datasets.", "entities": [{"id": 1293, "label": "Software", "start_offset": 0, "end_offset": 8}]}
{"id": 3803, "text": "schNell is a very lightweight python module that can be used to compute basic map-level noise properties for generic networks of gravitational wave interferometers. This includes primarily the noise power spectrum &quot;N_ell&quot;, but also other things, such as antenna patterns, overlap functions, inverse variance maps etc.", "entities": [{"id": 1495, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 3804, "text": "This software provides functions for finding relative positions between points in 3D space and plotting as distance histograms for single molecule localisation data e.g. direct stochastic optical reconstruction microscopy (dSTORM) or photoactivated light microscopy (PALM).", "entities": []}
{"id": 3805, "text": "This provides 3 pyqt5 samples that demonstrate 2 advanced topics in pyqt5 application development. These are:\n1,) Region selection of a part of an image and shares the results in a table following the MVC (model-View-Controller) paradigm https://github.com/jonathanHuwP/RegionSelection\n2,) Displays web (html) files and prints them within a pyqt5 application https://github.com/jonathanHuwP/QWebEngineDemo\n3,) Displays the results of an election stored in an array in a table so that the values in the table can be edited and the array updated, using the MVC (model-View-Controller) paradigm - https://github.com/jonathanHuwP/PyQtDemoElection", "entities": [{"id": 625, "label": "Software", "start_offset": 114, "end_offset": 130}, {"id": 627, "label": "Software_Url", "start_offset": 238, "end_offset": 285}, {"id": 628, "label": "Software_Url", "start_offset": 359, "end_offset": 405}, {"id": 629, "label": "Software_Url", "start_offset": 594, "end_offset": 642}]}
{"id": 3806, "text": "This software is the start of automating the computational pipeline or workflow for XAS Analysis. There are python 4 scripts for each state of matter ie, gas, liquid and solid, however the experimental spectra peak fitting (E2) and the comparison (C1) are the same for all these states. \n\nThe software was created by Laila Al-Madhagi for her PhD project on the 2018/05/17. Joanna Leng contributed to the design and development.", "entities": []}
{"id": 3807, "text": "This project extracts data on the growth rates of individual faces from x-ray video shadowgraphs of growing crystals.\n\nThe software was designed and developed with Gunjan Das and Sven Shroeder while the algorithm and software in this project were developed by Jonathan Pickering and Joanna Leng at the University of Leeds.", "entities": []}
{"id": 3808, "text": "Software developed for the extraction of crystal growth rates from 2D shadowgraphs of crystals precipitating onto a substrate, taken using X-rays of synchrotron radiation.", "entities": []}
{"id": 3809, "text": "Release to upload repository on Zenodo.", "entities": []}
{"id": 3810, "text": "Simulation, data analysis, and plotting scripts to reproduce results reported in M. Beg et al. Stable and manipulable Bloch point. Scientific Reports 9, 7959 (2019)..", "entities": []}
{"id": 3811, "text": "Micromagnetic tests for Ubermag calculators", "entities": [{"id": 624, "label": "Software", "start_offset": 0, "end_offset": 19}]}
{"id": 3812, "text": "Accompanying repository for &quot;Using Jupyter for reproducible scientific workflows&quot;.", "entities": []}
{"id": 3813, "text": "Supporting information for &quot;Ubermag: Towards more effective micromagnetic workflows&quot;", "entities": []}
{"id": 3814, "text": "Micromagnetic tests for Ubermag calculators", "entities": []}
{"id": 3815, "text": "All software used for the Canvas-GitLab Integration Framework, presented in Integrating Canvas and GitLab to Enrich Learning Processes:gitlab-haskell: Haskell client library for the GitLab API.canvas-haskell: Haskell client library for the Canvas API.OpenAPI specification of the Canvas API.Canvas-GitLab Integration consisting of eight use cases.These four project are version-controlled on the www.gitlab.com website.Abstract of paper:Version Control Systems (VCS) are increasingly being adopted for effective software education. However they are often used independently of general-purpose Learning Management Systems (LMS), leading to poor user experiences and data fragmentation. This paper presents a high level programming framework that enables integration of the Canvas LMS and the web based GitLab VCS. Eight use case software applications are implemented with it, motivated by related work, educator and student surveys we conducted, and our early experience of using GitLab for software education. The framework semi-automates feedback loops, improves the overall user experience for students and educators and reduces administrative time - saving educators up to 16.7 hours in a 12 week semester. The components of our framework are open source for learning technologists to develop their own use cases.The full paper is attached as Paper.pdf.", "entities": [{"id": 1497, "label": "Software", "start_offset": 26, "end_offset": 61}]}
{"id": 3816, "text": "The Citadel Programming Lab is an online virtual secure coding game-based computer lab. The Lab combines a tower defence game with 6 security programming tasks.&nbsp;\n\nThe Citadel Programming Lab was developed as part of a joint interdisciplinary research between Heriot-Watt University and the Glasgow School of Art.\n\nThe research was supported by:\n\n\n\nNCSC-RISCS Developer-Centred Security approach in 2017-18, PI Manuel Maarek, Co-I Sandy Louchart.\n\nEPSRC Secrious Project Expansion into an education virtual computer lab in 2021.\n\nCyBOK Development of the link with CyBOK v1.1, packaging and dissemination in 2021-22, PI Manuel Maarek, Co-I Sheung Chi Chan.", "entities": [{"id": 426, "label": "Software", "start_offset": 0, "end_offset": 27}, {"id": 427, "label": "Software", "start_offset": 168, "end_offset": 195}]}
{"id": 3817, "text": "No description provided.", "entities": []}
{"id": 3818, "text": "It allows compatibility between the work of TRE-FX, the HDR Programme (Cohort Discovery) and BC Platforms software", "entities": []}
{"id": 3819, "text": "It is the workflow to process an HDR Cohort Discovery tool query", "entities": []}
{"id": 3820, "text": "An open source version of the BC Platforms link software", "entities": [{"id": 1294, "label": "Software", "start_offset": 30, "end_offset": 56}]}
{"id": 3821, "text": "The system allows researchers to find cohorts of patients via an online platform.", "entities": []}
{"id": 3822, "text": "The platform allows rules to be generated to convert data from source to OMOP.", "entities": []}
{"id": 3823, "text": "Estimation of genetic model parameters from polygenic association statistics", "entities": []}
{"id": 3824, "text": "The app is an implementation of the Tuning approach published in the Paper Experiment in a Box (10.1007/s10458-022-09579-1) to support individuals running and reflecting on guided experiments in a suite of healthful practices.", "entities": []}
{"id": 3825, "text": "The CamilleX framework is a plug-in for the Rodin platform for formal modelling and analysis using Event-B. The framework provides a textual representation and persistence for the Event-B modelling constructs. It supports direct extensions to the Event-B syntax such as machine inclusion and record structures, as well as indirect extensions provided by other plugins such as UML-B diagrams.", "entities": [{"id": 1060, "label": "Software", "start_offset": 4, "end_offset": 22}]}
{"id": 3826, "text": "A software simulator of the ARMv6-M Instruction Set Architecture (ISA). Only a subset of the Thumb instructions are currently simulated in a timing accurate fashion according to the information in the ARM reference manual for the Cortex-M0 processor.", "entities": []}
{"id": 3827, "text": "Interactive Digital version of the Thriving Definitions - still under construction, future iterations will have increased functionality. Being developed by the Glasgow University Software Service (GUSS). Discussion still to be had about appropriate licence - GUSS can facilitate different types of licence depending on our requirements.", "entities": [{"id": 1498, "label": "Software", "start_offset": 35, "end_offset": 55}]}
{"id": 3828, "text": "I (Richard Parker) developed a software toolkit incorporating ML to automate the annotation of 18 types of behaviour related to pose, movement, interaction, facial expression and audio events. Following testing on artificial examples, I evaluated the software under realistic conditions through two case studies: children on the autism spectrum and adults with disorders of movement. For each, I compared the information yielded by my models with the annotation scheme used by the therapist and applied selected models to video extracts.\nBoth of the studies were viewed as credible by the therapists. I compared and contrasted my tool with related tools and have identified opportunities to build on this research. My main finding is that ML can support video analysis for MT by (1) extracting from MT videos data for human body movement, facial expression and the location of objects of interest and (2) processing those data to detect specific types of client behaviour. This, is, to my knowledge, the first time that the feasibility of automated annotation for videos featuring a range of MT client types has been demonstrated in a single integrated tool.", "entities": []}
{"id": 3829, "text": "We developed system level simulators based on Matlab, which included 802.11p DSRC based PHY and MAC layer functionalities, and road safety applications based on the connected cars and GPS mobility information.", "entities": [{"id": 630, "label": "Software", "start_offset": 13, "end_offset": 36}]}
{"id": 3830, "text": "This is a climate model with relatively low resolution (2.8 degrees in the atmosphere and 2 degrees in the ocean), but optimised for MP and open MP parallel processing so that it is fast enough to multicentennial and millennial climate simulations. It is easily configurable so that different continental and orographic/ocean bathymetry configurations can be explored. The model can be run with our without a stratosphere. There are basic thermodynamic sea ice and land soi/vegetation models", "entities": [{"id": 853, "label": "Software", "start_offset": 10, "end_offset": 24}]}
{"id": 3831, "text": "The algorithms resulting from this project have been implemented into the open source simulation package, called Spinach, maintained by Kuprov group (http://spindynamics.org).", "entities": [{"id": 1061, "label": "Software", "start_offset": 113, "end_offset": 120}, {"id": 1062, "label": "Software_Url", "start_offset": 150, "end_offset": 173}]}
{"id": 3832, "text": "A web-based tool for estimation of risk of vector-/water-borne diseases as a function of climate variables is being co-developed and co-tested with real data climate and epidemiological data. This enhanced our understanding of how vector-/water-borne diseases relate to climate variables, thus, allow relevant stakeholders to trigger adequate actions that favour early adaptation to climate risk within the Municipality.", "entities": []}
{"id": 3833, "text": "R package for preprocessing raw data from the Sleepsight platform. It is still in development.", "entities": []}
{"id": 3834, "text": "App for passive rest-activity monitoring, and active symptom sampling, in people with schizophrenia", "entities": []}
{"id": 3835, "text": "The CAPTAIN Toolbox is a collection of Matlab functions for system identification, time series analysis, forecasting and control. The current developers are Prof. Peter Young, Dr. Wlodek Tych and Prof. James Taylor, Lancaster University, UK. Although the toolbox has been available for many years, new and improved algorithms have been added to the package as a result of recent EPSRC funded research. For details see e.g. Taylor, C.J., Young, P.C., Tych, W., Wilson, E.D. (2018) New developments in the CAPTAIN Toolbox for Matlab with case study examples, IFAC-PapersOnLine, 51, 15, 694-699, 2018 (https://doi.org/10.1016/j.ifacol.2018.09.202).", "entities": [{"id": 631, "label": "Software", "start_offset": 4, "end_offset": 20}, {"id": 632, "label": "Software_Url", "start_offset": 599, "end_offset": 643}]}
{"id": 3836, "text": "Outcomes of research are released to community and partners as part of the L-CAS ROS software repository", "entities": [{"id": 854, "label": "Software", "start_offset": 75, "end_offset": 104}]}
{"id": 3837, "text": "A system resulting from the co-design sessions with visually impaired and sighted children and their teachers, is a multisensory story mapping prototype for facilitating storytelling tasks (including mapping, sequencing, composition and performance) with groups of primary-aged children with mixed visual abilities. The system is comprised of four main components; i) an audio sampler and playback unit; ii) a grid for organising the narrative structure; iii) a character module for exploring the narrative; and iv) a scene module, which introduces further multisensory elements to the story, including light and scent display.", "entities": []}
{"id": 3838, "text": "a Voice-based User Interface application using Amazon Alexa named Voxtopus. Voxtopus allows groups of pupils to engage in peer revision and augments the Echo device with a set of physical controllers that support audio-tactile display and can be used for answering and navigating questions. Importantly, Voxtopus supports potential for collaborative learning activities, where pupils participate in the design of personalised revision materials (summaries and MCQ quizzes) and share them with others. The technology therefore enables and supports inclusive pedagogy and activities.", "entities": [{"id": 1296, "label": "Software", "start_offset": 66, "end_offset": 74}, {"id": 1297, "label": "Software", "start_offset": 76, "end_offset": 84}, {"id": 1298, "label": "Software", "start_offset": 304, "end_offset": 312}]}
{"id": 3839, "text": "Initial release Article published in PNAS. Description This project provides the codes written to analyze the data of the above article and produce all figures shown in the manuscript. The folder /TSL_experiments/ contains the codes to generate and deliver the sequences of stimuli. Associated data are available on an OSF repository. Running All codes are written in Matlab and were ran using Matlab R2019b. To collect data and run experiments in the lab, you need a stimulator and DAQ device Matlab with the DAQ and Psychtoolbox all codes can be ran from run_all_stim_TCS2.m (check sessions, training, test sessions) To analyze the behavioral data behavioral data from the OSF repository always start by running add_all_paths_TSL.m that will add the required sub-folders to the Matlab path TSL_anayze_ratings.m: loads and analyzes the behavioral data of all the subjects, for one model and one parameter set. The path fn_dir should correspond to the behavioral data folder. TSL_fit_on_ratings.m: computes the fit of different models (with different parameters) and does the model comparison. To analyze the EEG data EEG data from the OSF repository always start by running add_all_paths_TSL.m that will add the required sub-folders to the Matlab path TSL_analyze_EEG.m: loads and analyzes the EEG recordings. The path fn_dir_EEG should correspond to the EEG data folder. Data are saved as specified in the function and can be reloaded and plotted using other functions. TSL_plot_avg_EEG.m: reloads useful data and displays the average EEG responses. Data must have been saved by running TSL_analyze_EEG.m with save_avg_eeg = 1 beforehand. TSL_plot_IO_fit.m: reloads useful data and displays the model fitting. Data must have been saved by running TSL_analyze_EEG.m with IO_fit_opt = 1 beforehand. To perform the parameter recovery analysis, using codes from the folder /param_recovery/ start by running add_paths_recov.m to add the required folders to the Matlab path simulate_behavior.m: simulates behavior using a range of parameters consistent with the ones observed in the original data set. fit_simulated_data.m: computes the quality of fit on data simulated in simulate_behavior.m. disp_param_recovery.m: plots the outcomes of the parameter recovery analysis. The data saved in /data_simu/ enables producing the figures without re-computing the simulations. Dependencies The codes for the Bayesian models (in the &quot;IdealObserversCode&quot; folder) were written by Florent Meyniel and Maxime Maheau (Minimal Transition Probs Model Library - Meyniel F, Maheu M, Dehaene S (2016) Human Inferences about Sequences: A Minimal Transition Probability Model. PLoS Comput Biol 12(12): e1005260). These codes are provided in this repository with some updates enabling to test variants of the initial models (with different priors, learning AF, ...). The VBA toolbox (in the &quot;VBA-toolbox&quot; folder) was developed by J. Daunizeau, V. Adam, L. Rigoux (2014): VBA: a probabilistic treatment of nonlinear models for neurobiological and behavioural data. PLoS Comp Biol 10(1): e1003441. Contact You can contact me at dounia **dot** mulders **at** uclouvain.be for any question. :-)", "entities": [{"id": 1500, "label": "Software", "start_offset": 197, "end_offset": 212}]}
{"id": 3840, "text": "v1.0.0 initial release # Computational and neural mechanisms of statistical pain learning Suyi Zhang, Ben Seymour, Flavia Mancini In press in Nature Communications An older version of the paper: doi: https://doi.org/10.1101/2021.10.21.465270 \n ## Usage The code in folder exp_code is used to generate the sequence of stimuli.\n The experiment is launched by the matlab function exp_MR_1500ms(sub,sess,stimCurrent,MR_state). See detailed comments inside the exp_MR_1500ms.m file. For behavioural data analysis, the following directories contain code for specific use. \n * data (behavioural data from fMRI sessions)\n * model_fit (fit models to behavioural data)\n * model_comparison (performs model comparison)\n * model_gen (generate parametric modulators for fMRI analyses using fitted model parameters) For imaging analysis, \n * imaging (1st and 2nd level analysis scripts based on nipype)\n * imaging_plot (result visualisation using nilearn) Please change data paths and parameter settings within the scripts. The analysis code is written by Suyi Zhang. \n The raw MRI data are available on [OpenNeuro](https://openneuro.org/datasets/ds003836). ## Requirements To run the code for sequence generation, you will need:\n * MATLAB\n * [Psychotoolbox 3](http://psychtoolbox.org)\n * a DAQ\n * a stimulus generator To run the code for behavioural analyses, you will need the following:\n * MATLAB\n * [Minimal Transition Probs Model package](https://github.com/florentmeyniel/MinimalTransitionProbsModel)\n * [VBA toolbox](https://mbb-team.github.io/VBA-toolbox/) For imaging analyses, the required python packages are listed in `requirements.txt`. Nipype scripts are best run inside its docker/singularity container, a useful tutorial can be found [here](https://miykael.github.io/nipype_tutorial/).", "entities": [{"id": 428, "label": "Software", "start_offset": 377, "end_offset": 390}, {"id": 429, "label": "Software", "start_offset": 456, "end_offset": 469}, {"id": 430, "label": "Software", "start_offset": 272, "end_offset": 280}]}
{"id": 3841, "text": "- implemented 7 prognosis risk prediction models for COVID-19. Detailed info in this paper: DOI:10.1093/jamia/ocaa295\n- introduced a competence quantification framework for assessing the competence/confidence of a model in predicting a given data entry (i.e. a digital representation of a covid patient)\n- ensembled 7 prediction models for prediction using fusion strategies based on their competences\n- evaluated single models and the ensembled mode on two large COVID-19 cohorts from Wuhan, China (N=2,384) and King's College Hospital (N=1,475)", "entities": []}
{"id": 3842, "text": "The seaMass software is our open source dissemination route for the LC-MS (Liquid Chromatography - Mass Spectrometry) analysis algorithms developed by our group, including signal restoration and visualisation.", "entities": [{"id": 855, "label": "Software", "start_offset": 4, "end_offset": 20}]}
{"id": 3843, "text": "Interactive real-time streaming visualisation platform for raw proteomics and metabolomics LC-MS data.", "entities": [{"id": 1063, "label": "Software", "start_offset": 0, "end_offset": 54}]}
{"id": 3844, "text": "Tool to check Android applications for malicious activities. Produces and verifies evidence.", "entities": []}
{"id": 3845, "text": "This repository contains example code for bare metal development on the Morello Platform. More information regarding these examples can be found in the CAP-TEE Morello Getting Started Guide. https://github.com/cap-tee/cheri-docs/blob/main/morello-getting-started.md.", "entities": [{"id": 1499, "label": "Software_Url", "start_offset": 191, "end_offset": 265}]}
{"id": 3846, "text": "Pandora is a symbolic execution tool designed for truthful validation of Intel SGX enclave shielding runtimes. Pandora is based on the fabulous angr and extends it with enclave semantics such as Intel SGX instruction support, a realistic enclave memory view, attacker taint tracking, and report generation for a set of powerful vulnerability plugins.", "entities": [{"id": 431, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 432, "label": "Software", "start_offset": 111, "end_offset": 118}]}
{"id": 3847, "text": "This software checks and demonstrates the vulnerabilities reported in the paper &quot;PMFault: Faulting and Bricking Server CPUs through Management Interfaces&quot;, to appear at TCHES 2023.", "entities": []}
{"id": 3848, "text": "Snapshot of the three implementations (in Sail, Proteus and Morello, found in the respective homonymous folders) discussed in our EuroS&amp;P 2023 paper &quot;CHERI-TrEE: Flexible enclaves on capability machines&quot;", "entities": []}
{"id": 3849, "text": "Developed by Allison Parrish and the Creative AI Lab, this open-source chatbot prototype allows users to chat with Serpentine's Artistic Director Hans Ulrich Obrist. The dataset (the words spoken by the chatbot) is comprised of a small database of 500 interviews conducted between Hans Ulrich Obrist and various artists between 2015 and the present. (access via http://157.245.129.50:6037 username: huobot password: 9000)", "entities": [{"id": 1064, "label": "Software", "start_offset": 59, "end_offset": 79}]}
{"id": 3850, "text": "An app to record everyday activities with minimal effort. This app is used for our research to collect time-stamped activity records alongside survey and enjoyment information. The Corodva platform allows easy porting and adoption for alternative uses. The app was translated into German by our partners at the University of Muenster.", "entities": [{"id": 1299, "label": "Software", "start_offset": 181, "end_offset": 197}]}
{"id": 3851, "text": "The Machine Learning Reputation Test Bed (MLRTB) has been developed as part of JASPR for research into trust and reputation in agent based systems. The aim of MLRTB is to enable development of reputation models driven by provenance records, generated by interactions and stored in a provenance store. Reputation assessment models process these records and produce reputation scores of agents in the simulation, which are then used to inform decisions about future interactions. Our goal is to use machine learning, provided by the WEKA and MEKA machine learning toolkits, in learning these provenance records and predicting future interaction outcomes.\n\nDeveloping new reputation assessment models in MLRTB is straightforward, and implementations of several existing reputation assessment models are provided for comparison, including FIRE, BRS, TRAVOS, STAGE, BLADE, and HABIT. Written in Scala and Java, the MLRTB is extensible to new environments with different kinds of interaction and reputation assessments. There are currently three marketplace environments implemented that each focus on different aspects of reputation assessment. A logistics simulation is focussed on reputation of provider agents in compositions, a bootstrapping simulation introduces provider stereotypes, and a marketplace simulation builds on this by also modelling user and service contexts.", "entities": [{"id": 1501, "label": "Software", "start_offset": 4, "end_offset": 40}, {"id": 1502, "label": "Software", "start_offset": 42, "end_offset": 47}, {"id": 1503, "label": "Software", "start_offset": 159, "end_offset": 164}, {"id": 1504, "label": "Software", "start_offset": 701, "end_offset": 706}, {"id": 1505, "label": "Software", "start_offset": 910, "end_offset": 915}]}
{"id": 3852, "text": "The iPhone app aims at delivering the auditory illusion of being in the middle of a virtual rectangular room. This is achieved by means of the scattering delay network (SDN) technology, together with binaural reproduction technique. The app is capable of simulating the acoustics of the room in real time thanks to the extremely low computational complexity of the SDN method, while at the same time delivering important perceptual cues in an accurate manner. The app uses the iPhone gyroscope in order to track the movement of the listener's head and adjusts the simulation accordingly.", "entities": []}
{"id": 3853, "text": "Software for dynamic spatialisation of sound sources in a dynamically changing environment, e.g. rendition of a VR audio content, that is compatible with multichannel and binaural rendering.", "entities": []}
{"id": 3854, "text": "Crosslink is a software program able to create genetic maps from genotype data collected from the progeny of a cross between two individuals. The program is suitable for use with an &quot;outcross&quot; where the two parents do not need to be genetically inbred, and there is applicable to a wide range of plants where inbreeding cannot be used. The program is designed to scale efficiently to handle the large number of genetic markers typically being generated by modern and emerging genotyping technologies.", "entities": [{"id": 856, "label": "Software", "start_offset": 0, "end_offset": 9}]}
{"id": 3855, "text": "The app will eventually be freely available for download but is currently being updated. It will allow films of stories to be accessed via the map using a mobile phone or iPad.", "entities": []}
{"id": 3856, "text": "ReaTK is the Reactive System Verification and Synthesis ToolKit. It provides the ReaVer tool dedicated to the static verification of logico-numerical systems by abstract interpretation, and the ReaX tool performing discrete controller synthesis for such systems.\nReaX implements various algorithms for synthesizing controllers that target safety objectives, reachability objectives (an &quot;easy&quot; subclass of liveness properties), as well as numerical optimization objectives.\nFulfilling the latter class of objectives consists in controlling the system so that value of a cost function expressed on its variables is minimized over a specified time interval.\nReaX implements various algorithms that handle such objectives on sliding windows, or with discounted costs (not published yet).\nControllers synthesized with ReaX are always implementable, which means that they can easily be translated into efficient sequential code, or alternatively, into hardware circuits.", "entities": [{"id": 1300, "label": "Software", "start_offset": 0, "end_offset": 5}, {"id": 1301, "label": "Software", "start_offset": 823, "end_offset": 827}, {"id": 1302, "label": "Software", "start_offset": 665, "end_offset": 669}, {"id": 1303, "label": "Software", "start_offset": 263, "end_offset": 267}, {"id": 1304, "label": "Software", "start_offset": 194, "end_offset": 203}, {"id": 1305, "label": "Software", "start_offset": 81, "end_offset": 92}]}
{"id": 3857, "text": "Graphical user interface for the Elfin software for design of modular protein structures", "entities": [{"id": 1506, "label": "Software", "start_offset": 0, "end_offset": 24}]}
{"id": 3858, "text": "ELFIN is a computational approach for design of custom proteins. It enables users to build protein structures with specific shapes, using experimentally validated repeat protein units as modular, compatible and rigid building blocks. Similar to computer assisted design (CAD) tools, we define a three-dimensional target shape and find the combination of building blocks that matches the target most closely.", "entities": [{"id": 433, "label": "Software", "start_offset": 0, "end_offset": 5}]}
{"id": 3859, "text": "A suite of software, based around the Unreal Engine, that allows for the real time simulation and control (via a custom interface) of virtual audiences and audition panels in realistic settings based on real-world or hypothetical venues.", "entities": []}
{"id": 3860, "text": "The SUPERPOWER app is a design by artist Lin Tan (Umbrellium). It allowed a group of sixteen students to generate and collect environmental data using their personal phones and focusing on how well/not well some spaces feel at school. The app facilitates research on the perception of space by registering geo-location, perception rating, a photograph of the space and a commentary. The data collected and its collective discussion allowed to make tangible issues of space, materiality, temperature, light, organization, sound and so on that are sometimes difficult to describe or speak about. Tan has used the app in different projects nationally and internationally but frequently it has involved perceptions in the city outdoors. These have included for example perceptions of safety in the city, or perceptions of air quality in pandemic times. For our study the SUPERPOWER software was adapted to be used inside the school building, which required to link the geo-location data to the school floor plan.", "entities": [{"id": 857, "label": "Software", "start_offset": 4, "end_offset": 14}, {"id": 858, "label": "Software", "start_offset": 867, "end_offset": 877}]}
{"id": 3861, "text": "No description provided.", "entities": []}
{"id": 3862, "text": "SLEEC-TK is an Eclipse-based environment for defining SLEEC rules in a domain-specific language with a timed process algebraic semantics. SLEEC-TK uses model checking to identify redundant and conflicting rules, and to verify conformance of autonomous agent design models with SLEEC rules.", "entities": [{"id": 1306, "label": "Software", "start_offset": 0, "end_offset": 8}, {"id": 1307, "label": "Software", "start_offset": 138, "end_offset": 146}]}
{"id": 3863, "text": "the software is a multi-scale emission calculator for China", "entities": []}
{"id": 3864, "text": "the software provides a framework of environmental footprint accounts and decomposition analysis", "entities": []}
{"id": 3865, "text": "Meteorological front identification and classification using the method of Hewson (1998). References: Sansom, P.G. and Catto, J.L. (2022), Improved objective identification of meteorological fronts: a case study with ERA-Interim. Geoscientific Model Development.", "entities": [{"id": 633, "label": "Software", "start_offset": 0, "end_offset": 55}]}
{"id": 3866, "text": "A package to get the hierarchical levels and influence centrality of a graph", "entities": []}
{"id": 3867, "text": "DualSPHysics is based on the Smoothed Particle Hydrodynamics model named SPHysics (www.sphysics.org). The code is developed to study free-surface flow phenomena where Eulerian methods can be difficult to apply, such as waves or impact of dam-breaks on off-shore structures. DualSPHysics is a set of C++, CUDA and Java codes designed to deal with real-life engineering problems. This LATEST VERSION, 5.0, included the multi-phase sediment-water technology developed during this grant.", "entities": [{"id": 1065, "label": "Software", "start_offset": 0, "end_offset": 12}, {"id": 1066, "label": "Software", "start_offset": 274, "end_offset": 286}]}
{"id": 3868, "text": "This contains python code to replicate the results for the publication: Multi-modal Doman Adaptation for Fine-grained Action Recognition.", "entities": []}
{"id": 3869, "text": "The weighted horizontal magnetic gradient (WG M ) as a flare precursor is developed. For details see https://iopscience.iop.org/article/10.3847/1538-4357/aab891/pdf", "entities": [{"id": 1507, "label": "Software", "start_offset": 4, "end_offset": 41}, {"id": 1508, "label": "Software", "start_offset": 43, "end_offset": 47}]}
{"id": 3870, "text": "SAC solves the MHD equations on CPU.\nSMAUG solves the MHD equations on GPU", "entities": [{"id": 434, "label": "Software", "start_offset": 0, "end_offset": 4}, {"id": 435, "label": "Software", "start_offset": 37, "end_offset": 42}]}
{"id": 3871, "text": "DyverseBMC (Dyverse Bounded Model Checker). DyverseBMC is a bounded model checker based on a lazy SMT (Satisfiability Modulo Theories) approach especially designed for verifying safety properties of systems with multiple impacts and friction. DyverseBMC uses the transition system generated by DyverseRBT as the computational semantics of the mechanical system.", "entities": [{"id": 634, "label": "Software", "start_offset": 0, "end_offset": 10}, {"id": 635, "label": "Software", "start_offset": 12, "end_offset": 41}, {"id": 636, "label": "Software", "start_offset": 43, "end_offset": 55}, {"id": 637, "label": "Software", "start_offset": 243, "end_offset": 253}]}
{"id": 3872, "text": "The DeadRegions toolbox creates a dead region on a hybrid automaton for a given inevitability property of reaching some desired live region. It is available at http://staff.cs.manchester.ac.uk/~navarroe/research/dyverse/liveness/", "entities": [{"id": 859, "label": "Software", "start_offset": 4, "end_offset": 23}, {"id": 860, "label": "Software_Url", "start_offset": 160, "end_offset": 229}]}
{"id": 3873, "text": "DyverseRBT (Dyverse Rigid Body Toolbox). DyverseRBT generates automatically a general-purpose dynamical transition system - based on a new type of hybrid automata - for the description of mechanical systems subject to multiple impacts with friction. DyverseRBT automatically generates a hybrid automaton - which includes non-dynamical discrete location - and its simulation from a mechanical specification given by the user. The implementation uses S-functions in the Simulink environment of MATLAB. We have built several demos under Simulink and Matlab and sent them to several groups of the UK, Europe and the USA (mainly, related to control of discontinuous dynamical systems and systems with impacts and friction). We also liaised with MathWorks Inc. to explore the possibilities of DyverseRBT to validate different types of models and controllers of discontinuous control systems.", "entities": [{"id": 1067, "label": "Software", "start_offset": 0, "end_offset": 11}, {"id": 1068, "label": "Software", "start_offset": 12, "end_offset": 38}, {"id": 1069, "label": "Software", "start_offset": 41, "end_offset": 51}, {"id": 1070, "label": "Software", "start_offset": 250, "end_offset": 260}, {"id": 1071, "label": "Software", "start_offset": 787, "end_offset": 797}]}
{"id": 3874, "text": "The package PWproveByTA abstracts a piecewise-linear system of a class of the form dx/dt=Ax to a timed automaton (TA) for proving inevitability (reaching a specified live zone). It then uses the stand-alone prover of TA prover UPPAAL to prove the property. It is available at http://staff.cs.manchester.ac.uk/~navarroe/research/dyverse/liveness/", "entities": [{"id": 1308, "label": "Software", "start_offset": 12, "end_offset": 23}]}
{"id": 3875, "text": "proveByTA toolbox (prove by timed automata toolbox). The proveByTA toolbox uses abstraction methods to prove inevitability properties for classes of continuous and hybrid systems (piecewise continuous dynamical systems). The implementation for the piecewise-continuous part involves extra complexities from the interaction of different dynamics.\n\nAn inevitability property says that a region of the state space will eventually be reached: this is a type of liveness property from the computer science viewpoint, and is related to attractivity of sets in dynamical systems. It is available at \nhttp://staff.cs.manchester.ac.uk/~navarroe/research/dyverse/liveness/", "entities": [{"id": 1509, "label": "Software", "start_offset": 0, "end_offset": 17}, {"id": 1510, "label": "Software", "start_offset": 57, "end_offset": 74}]}
{"id": 3876, "text": "ACRG standardisation and inversion code v0.2.0 Added Ability to convert calibration scale in get_obs New &quot;defaults&quot; file that specifies inlets and instruments to use for particular time periods An obs.db SQLite database that specifies the location of all obs files and basic details about their contents (species, inlet, time range, etc.) notebooks directory for Jupyter notebooks notebooks/tutorials directory for notebook based tutorials a tmp directory to store random job script output files added a dev environment that includes spyder and a lighter environment that does not Changed get_single_site now returns a list of xarray datasets, one for each combination of inlet and site. If defaults are specified, the list will contain the default instruments and inlets for each period get_obs now returns a dictionary containing lists of datasets calibration scale and inlet are now attributes to obs datasets (e.g. ds.attrs[&quot;scale&quot;]) fp_data_merge now works with new get_obs object The flux function will now look for species-total.nc named files first and then look for species.nc files. This will not be able to read both files. This can still accept an more explicit source such as co2-ff_*.nc as an alternative to this. arviz package version pinned to prevent conflict with pymc3 version", "entities": [{"id": 439, "label": "Software", "start_offset": 0, "end_offset": 39}]}
{"id": 3877, "text": "This software enables WebGL - optimised calculation of photometric models of galaxies inside the Zooniverse citizen science website. The software was first merged into the existing repository in March 2018, with a number of bug-fixes over the following few months.\n\nInteractive model rendering is a new frontier for Web-based citizen science, and the software developed for this award provides a good first step towards opening up itizen science to more complex, involved tasks.", "entities": []}
{"id": 3878, "text": "MetaWards implements a stochastic metapopulation model of disease transmission. It can scale from modelling local transmission up to full national- or international-scale metapopulation models. Please take a look at the features to see what MetaWards can do. Follow the quick start guide to see how to quickly get up and running using MetaWards to model your own custom disease or metapopulation model. Full Changelog: https://github.com/metawards/MetaWards/compare/1.6.0...1.6.1", "entities": [{"id": 861, "label": "Software", "start_offset": 0, "end_offset": 9}, {"id": 862, "label": "Software", "start_offset": 241, "end_offset": 250}, {"id": 863, "label": "Software_Url", "start_offset": 419, "end_offset": 479}, {"id": 864, "label": "Software", "start_offset": 335, "end_offset": 344}]}
{"id": 3879, "text": "A web application detailing the interactions and relationships between individuals who financed and engineered Brunel's three great steamships (SS Great Western, SS Great Britain and SS Great Eastern)", "entities": []}
{"id": 3880, "text": "Sire Molecular Simulation Framework 2016.X releases (2016.1, 2016.2, 2016.3, 2016.3.1)", "entities": [{"id": 1309, "label": "Software", "start_offset": 0, "end_offset": 35}]}
{"id": 3881, "text": "The 2018 releases of Sire included improved file format support and molecular parsing code which has provided the foundation for the development of the BioSimSpace project.", "entities": [{"id": 1511, "label": "Software", "start_offset": 21, "end_offset": 25}]}
{"id": 3882, "text": "Cluster-in-the-cloud provides on-demand, autoscaling, heterogeneous high performance computing clusters on a range of public cloud providers (Oracle, Google, Amazon).", "entities": [{"id": 436, "label": "Software", "start_offset": 0, "end_offset": 20}]}
{"id": 3883, "text": "Sire molecular simulation framework, used as the basis for many tools, e.g. SOMD, FESetup and BioSimSpace. The 2019.X versions of Sire have been used over 180,000 times (https://siremol.org/analytics/versionchart.html).", "entities": [{"id": 638, "label": "Software", "start_offset": 0, "end_offset": 35}]}
{"id": 3884, "text": "MetaWards implements a stochastic metapopulation model of disease transmission. It can scale from modelling local transmission up to full national- or international-scale metapopulation models. This is a Python port of the MetaWards package originally written by Leon Danon which was originally developed to support modelling of disease transmission in Great Britain and used to produce data that was used by SAGE to influence the Covid response. The Python port addressed the reproducibility, sustainability, robustness and extensibility of the original code, and has created a platform that now supports a community of epidemiologists who are using it to study the Covid spread.", "entities": [{"id": 866, "label": "Software", "start_offset": 0, "end_offset": 9}, {"id": 867, "label": "Software", "start_offset": 223, "end_offset": 232}]}
{"id": 3885, "text": "BioSimSpace is an interoperable Python framework for bimolecular simulation. It helps researchers easily build interoperable workflow components for running complex biomolecular simulations.", "entities": [{"id": 1072, "label": "Software", "start_offset": 0, "end_offset": 11}]}
{"id": 3886, "text": "Sire Molecular Simulation Framework 2017.X releases (2017.1, 2017.2, 2017.3)", "entities": [{"id": 1310, "label": "Software", "start_offset": 0, "end_offset": 35}]}
{"id": 3887, "text": "LINTools is a software program that can analyse MD trajectories and give a schematic representation figure that summarise the interactions of a ligand/small molecule with a larger macromolecule (typically a protein).", "entities": [{"id": 1512, "label": "Software", "start_offset": 0, "end_offset": 8}]}
{"id": 3888, "text": "MPT-Calculator is a series of python scripts which calls the NGSolve high order finite element method (FEM) library\n\nhttps://ngsolve.org\n\nfor computing the magnetic polarizability tensor (MPT) for object characterisation in metal detection. In the case of frequency sweeps, this is accelerated by the Proper Orthogonal Decomposition (POD) technique. It is designed as an educational and research tool for engineers, mathematicians and physicists working both academia and industry and it is hoped those interested in characterising conducting permeable objects will find it useful.\n\nThe MPT characterises the shape, conductivity, permeability of conducting permeable object, is frequency dependent and is independent of the object's position. The rank 2 MPT is symmetric and has at most 6 independent complex coefficients. However, for objects with mirror or rotational symmetries the number of independent coefficients is smaller.\n\nMPT-Calculator computes the MPT using a range of different numerical schemes\n\n1) A hp FEM discretisation of the transmission problems using NGSolve to compute MPT for a single frequency.\n2) A hp FEM discretisation of the transmission problems using NGSolve for performing the computation of the MPT over a range of frequencies.\n3) A Proper Orthogonal Decomposition (POD) reduced order model, which greatly accelerates the computation of the full order model in 2. for computing the MPT over a range of frequencies.\n\nThe technical details of the implementation have been described in paper submitted for publication.\n\nPlots of the computed tensor coefficients as a function of frequency are created and the output data and plots are automatically stored so that they can be recreated, if desired. A series of example geometries are included as is a detailed tutorial.", "entities": [{"id": 440, "label": "Software", "start_offset": 0, "end_offset": 14}, {"id": 441, "label": "Software", "start_offset": 933, "end_offset": 947}]}
{"id": 3889, "text": "The programme consists of a webbased platform and a smart phone application.", "entities": []}
{"id": 3890, "text": "Matlab codes to Airbus", "entities": []}
{"id": 3891, "text": "The GROMACS plugin for AiiDA aims to enable the capture and sharing of the full provenance of data when parameterising and running molecular dynamics simulations. The design pattern we are aiming for is to simply allow researchers to capture the full data provenance for their simulations by only switching on an AiiDA conda environment, along with modifying your command lines very slightly.", "entities": [{"id": 1073, "label": "Software", "start_offset": 4, "end_offset": 18}]}
{"id": 3892, "text": "An implementation of the Linked Art model onto the Fitzwilliam Museum's collections data - mapping elasticsearch endpoint to JSON-LD", "entities": [{"id": 1311, "label": "Software", "start_offset": 25, "end_offset": 41}]}
{"id": 3893, "text": "This software package enabled the Fitzwilliam Museum to harvest all records from their Antiquities section of their collection database and to georeference and display on an interactive web map.", "entities": [{"id": 1513, "label": "Software", "start_offset": 174, "end_offset": 193}]}
{"id": 3894, "text": "This software is a static HTML site, generated in Jekyll which will document the project and its outcomes and allow all members to edit and create content using version control.", "entities": []}
{"id": 3895, "text": "Sentiment analysis (SA) is the key element for a variety of opinion and attitude mining tasks. While various unsupervised SA tools already exist, a central problem is that they are lexicon-based where the lexicons used are limited, leading to a vocabulary mismatch. In this paper, we present an unsupervised word embedding-based sentiment scoring framework for sentiment intensity scoring (SIS). The framework generalizes and combines past works so that pre-existing lexicons (e.g. VADER, LabMT) and word embeddings (e.g. BERT, RoBERTa) can be used to address this problem, with no require training, and while providing fine grained SIS of words and phrases. The framework is scalable and extensible, so that custom lexicons or word embeddings can be used to core methods, and to even create new corpus specific lexicons without the need for extensive supervised learning and retraining.", "entities": [{"id": 639, "label": "Software", "start_offset": 295, "end_offset": 357}]}
{"id": 3896, "text": "DataMirror, is an initial prototype tool, that enables social network users to aggregate their online data so that they can search, browse and visualise what they have put online. The aim of the tool is to investigate and explore people's awareness of their data self that is projected online; not only in terms of the volume of information that they might share, but what it may mean when combined together, what pieces of sensitive information may be gleaned from their data, and what machine learning may infer about them given their data.", "entities": [{"id": 868, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 3897, "text": "This assessment app works on android phones after the freely downloadable Kobo Collect app has been installed via Google Play. The app was developed following pilot testing with five and six year olds in two languages. Data may be collected via pre-set tests accessible through a QR code, or customized tests set up manually by a user such as a class teacher or a local researcher of child outcomes. Tests piloted using the app used pictures (essential for child language testing), local scripts (essential for countries with Asian scripts), and simple layouts (essential for clarity on small phone screens). Use of the Kobo Connect Platform allows upload of data after the assessor reaches a place with stable internet connectivity. The user manual for use of this app was developed following cognitive interviews with teachers similar to the group the app aims to support. The Manual mainly uses screen shots and simple flow diagrams to help navigate the system from download to assessment to upload of test data and its first interpretation. A section on Frequently Asked Questions is based on the pilot and cognitive interviews. The app is for lay users including teachers, librarians and volunteers working with 3- to 9-year-olds in low- and middle-income country contexts to assess oral language ability. Child researchers may also use the app.", "entities": [{"id": 1074, "label": "Software", "start_offset": 74, "end_offset": 86}, {"id": 1075, "label": "Software", "start_offset": 620, "end_offset": 641}]}
{"id": 3898, "text": "The LZ complexity algorithm involves converting the original time series into a discrete sequence of a finite num-ber of symbols. In this study the median was used as the threshold Td in the sequence conversion, given that the me-dian is robust to outliers [Na02]. A sequence P = s(1), s(2),?, s(n) is created by comparison the original signal with the threshold, with s(i) given by: \n (1)\nOnce this coarse-grained sequence has been created from the original signal, P is scanned from left to right and the complexity counter c(n) is increased by one unit every time a new subsequence of consecutive characters is encountered. A detailed description of the complexity algorithm can be found in [Zh01].\nThe complexity algorithm is dependent on the sequence length. For this reason, c(n) should be normalized. For a sequence of length n and an alphabet of ? symbols, the upper bound of c(n) is given by [LZ76]: \n (2)\nwhere ?n is a small quantity and ?n ? 0 (n ? ?). In general,\n (3)\nTherefore, c(n) can be normalized via b(n): \n (4)\nC(n) is then the normalized LZ complexity. Greater C(n) values correspond to more complexity in the data.", "entities": [{"id": 1312, "label": "Software", "start_offset": 4, "end_offset": 27}]}
{"id": 3899, "text": "Provide pre- and post-processing tools for the FVCOM hydrodynamic model.", "entities": []}
{"id": 3900, "text": "Python tools for interrogating FVCOM model data.", "entities": []}
{"id": 3901, "text": "A validated multi-platform, user-friendly software tool for the robust, objective and automated optimisation of targeted LC-MS/MS analyses. MUSCLE can be used to optimise methods on a wide array of LC-MS platforms in a fully automated manner.", "entities": [{"id": 640, "label": "Software", "start_offset": 140, "end_offset": 147}]}
{"id": 3902, "text": "BioLayout Express3D is a powerful tool for the visualization and analysis of network graphs. Network-based approaches are becoming increasingly popular for the analysis of complex systems of interaction and high dimensional data. Networks can be produced from a wide variety of relationships between entities. In biology this includes the interactions between individuals, disease transmission, sequence similarity, metabolic pathways, protein interactions, pathways, regulatory cascades, gene expression, clinical data. \n\nThis tool represents the product of over 15 years research and development and uses a combination of high end 3D graphics, algorithms and user-friendly graphical interfaces to allow the user to explore and better analyse their data.", "entities": [{"id": 869, "label": "Software", "start_offset": 0, "end_offset": 19}]}
{"id": 3903, "text": "This is a network analysis tool designed for the analysis of biological data. It is a commercial product produced by Kajeka Ltd a company founded on the IP and know how behind BioLayout Express3D.", "entities": []}
{"id": 3904, "text": "This online tool allows users to generate tanscsequence graphs and then v", "entities": []}
{"id": 3905, "text": "Graphical 'wizard' software has been produced to automate the processing of force, displacement and camera images from the UBM test so that fracture toughness 'R-curves' can be derived.", "entities": [{"id": 1514, "label": "Software", "start_offset": 11, "end_offset": 17}]}
{"id": 3906, "text": "Database and associated web interface to handle pedigree populations, genotypes and phenotypes for genetic linkage mapping and quantitative trait linkage mapping studies. System checks inheritance of markers and formats/reformats data in readiness for import into common analysis programs.", "entities": []}
{"id": 3907, "text": "This is a climate model with relatively low resolution (2.8 degrees in the atmosphere and 2 degrees in the ocean), but optimised for MP and open MP parallel processing so that it is fast enough to multicentennial and millennial climate simulations. It is easily configurable so that different continental and orographic/ocean bathymetry configurations can be explored. The model can be run with our without a stratosphere. There are basic thermodynamic sea ice and land soi/vegetation models", "entities": [{"id": 641, "label": "Software", "start_offset": 9, "end_offset": 23}]}
{"id": 3908, "text": "Mass-spectrometry based spatial proteomics data sets from Dunkley et al. (2006), Foster et al. (2006), Tan et al. (2009), Hall et al. (2009), Trotter et al. (2010), Ferro et al. (2010), Nikolovski et al. (2012, 2014), Breckels et al. (2013), Groen et al. (2014) and Christoforou et al. (2015), and protein complex separation data from Kristensen et al. (2012), Havugimana et al. (2012), Kirkwood et al. (2013) and Fabre et al. (2015).", "entities": []}
{"id": 3909, "text": "Interactively visualisation of organelle (spatial) proteomics data on the basis of pRoloc, pRolocdata and shiny.", "entities": []}
{"id": 3910, "text": "pRoloc is a complete infrastructure to support and guide the sound analysis of quantitative mass-spectrometry-based spatial proteomics data. It provides functionality for unsupervised and supervised machine learning for data exploration and protein classification and novelty detection to identify new putative sub-cellular clusters. The software builds upon existing infrastructure for data management and data processing.", "entities": [{"id": 1313, "label": "Software", "start_offset": 0, "end_offset": 6}]}
{"id": 3911, "text": "An application is currently in development to make image analysis quicker and easier. The deep learning algorithm is in the learning stage at the moment.", "entities": []}
{"id": 3912, "text": "This software enables low cost multi-wavelengh imaging. For example, it can be used in neuroscience to simultaneously record intrinsic signal optical imaging with fluorescence, structural, haemodynamic data. Additionally analog channels can record further data, such as respiration signals simultaneously with imaging.", "entities": []}
{"id": 3913, "text": "Proteolabels is software for SILAC-style quantification in proteomics. The software has been licenced from University of Liverpool to Omic Analytics Ltd. for further develop and support. The software is onward licenced to Waters Corp for internatinoal sale", "entities": [{"id": 642, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 3914, "text": "The jsem package implements the methodology described in Kuha, J., Zhang, S., &amp; Steele, F. (forthcoming). Latent variable models for multivariate dyadic data with zero inflation: Analysis of intergenerational exchanges of family support. Annals of Applied Statistics.\n\nThe package contains tailored estimation code for the proposed joint latent variable framework using full Bayesian methods. R and C++ compiled code (Rcpp, RcppArmadillo) is used with OpenMP API for parallel computing to boost the estimation. Direct sampling (when applicable by using proper conjugate prior) and adaptive rejection Metropolis sampling are both employed in the program.", "entities": [{"id": 870, "label": "Software", "start_offset": 4, "end_offset": 16}]}
{"id": 3915, "text": "No description provided.", "entities": []}
{"id": 3916, "text": "Phantom generator", "entities": [{"id": 1314, "label": "Software", "start_offset": 0, "end_offset": 17}]}
{"id": 3917, "text": "A software to factorize emission spectra of single quantum dots undergoing jitter into the temporal shift and the intrinsic lineshape. It ises Non-negative matrix factorization. The jitter can be additionally constrained using a multiple charge trap model, returning the respective energy shifts affected by each charged site.", "entities": []}
{"id": 3918, "text": "This is a network analysis tool designed for the analysis of biological data. It is a commercial product produced by Kajeka Ltd a company founded on the IP and know how behind BioLayout Express3D.", "entities": []}
{"id": 3919, "text": "This online tool allows users to generate tanscsequence graphs and then v", "entities": []}
{"id": 3920, "text": "BioLayout Express3D is a powerful tool for the visualization and analysis of network graphs. Network-based approaches are becoming increasingly popular for the analysis of complex systems of interaction and high dimensional data. Networks can be produced from a wide variety of relationships between entities. In biology this includes the interactions between individuals, disease transmission, sequence similarity, metabolic pathways, protein interactions, pathways, regulatory cascades, gene expression, clinical data. \n\nThis tool represents the product of over 15 years research and development and uses a combination of high end 3D graphics, algorithms and user-friendly graphical interfaces to allow the user to explore and better analyse their data.", "entities": [{"id": 871, "label": "Software", "start_offset": 0, "end_offset": 19}]}
{"id": 3921, "text": "Named Entity (NE) based directed graph visualization for intelligence reports.\n\nOur graph visualization aims to generate small directed graphs of connected named entities (i.e. people, locations, species and organisations) with the target suspect as the root node. This automates to some degree the approach used in criminological analysis, where users are first identified and then posts analysed to see who is connected and what behaviours are being exhibited. Entity types are similar to the UK law enforcement and Home Office standard POLE format (People, Object, Location and Events).", "entities": [{"id": 1076, "label": "Software", "start_offset": 33, "end_offset": 77}]}
{"id": 3922, "text": "Plato is a set of programmes for performing electronic structure calculations using tight binding or density functional theory (DFT). It has been under constant development since 1997, but has been substantially rewritten recently to support electrochemistry generally, and corrosion of Mg in particular. Development is a continuous process, but some features were driven by this project. The most important was the development of a specialised DFT code that is built for systematic evaluation of tight binding models. It has been essential for clarifying what the various terms do, and thus enabling us to decide how to proceed with the simulation of Mg corrosion.", "entities": [{"id": 1315, "label": "Software", "start_offset": 0, "end_offset": 5}]}
{"id": 3923, "text": "These tools were built as part of my PhD project. &quot;Drug/Gene Target Explorer&quot; is the main dashboard and provides several views of the data for my thesis. Likewise the ML/AL model tool give you the option of flicking back and forth between the many approaches explored. The &quot;MSA&quot; explorer is useful for a high-level overview of sequence alighment and provides an easy way to see which positions experience high mutational frequency.", "entities": [{"id": 1515, "label": "Software", "start_offset": 56, "end_offset": 81}, {"id": 1516, "label": "Software", "start_offset": 289, "end_offset": 292}, {"id": 1517, "label": "Software", "start_offset": 177, "end_offset": 188}]}
{"id": 3924, "text": "CASTEP is a software package for predictive, quantum-mechanical simulations of materials and chemicals. It is based on density functional theory, and can simulate a wide range of materials proprieties including energetics, the structure at the atomic level, vibrational properties and electronic response properties. In particular, it has a wide range of spectroscopic features that link directly to experiment, such as infra-red and Raman spectroscopies, NMR, and core level spectra. CASTEP version 22 included a top-level Python layer to enable CASTEP to be embedded within other computational workflows, for example transition-state searches or multiscale modelling.", "entities": [{"id": 442, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 443, "label": "Software", "start_offset": 485, "end_offset": 491}, {"id": 444, "label": "Software", "start_offset": 547, "end_offset": 554}]}
{"id": 3925, "text": "This is a software interface to present a code-agnostic way of running various DFT codes", "entities": []}
{"id": 3926, "text": "A generic API to provide an abstract interface to atomistic simulation programs, without needing to know the implementation details of the simulation programs themselves. This enables high-level software frameworks and workflows to switch easily between different simulation packages (for example, to compute forces); similarly, developers of simulation software implement this API in their programs, and immediately have their software be usable in the high-level tools.", "entities": []}
{"id": 3927, "text": "This is a collection of MATLAB programs / functions to process the raw data from the Cloud Particle Imager probe, which is being used on the BAe-146 aircraft. It was developed during the INUPIAQ project to enable analysis of data from the field phase, so is listed here. It is available for anyone to use under the GPL.", "entities": []}
{"id": 3928, "text": "Data and code for: &quot;Monkeypox virus shows potential to infect a diverse range of native animal species across Europe, indicating high risk of becoming endemic in the region.&quot; Authors: Marcus SC Blagrove*1, Jack Pilgrim1, Aurelia Kotsiri1, Melody Hui1, Matthew Baylis1, Maya Wardeh*1,2 * = corresponding authors 1) Institute of Infection, Veterinary and Ecological Sciences, University of Liverpool, Liverpool, UK 2) Department of Mathematical Sciences, University of Liverpool, Liverpool, UK \n Abstract: Background: Monkeypox is a zoonotic virus which persists in animal reservoirs and periodically spills over into humans, causing outbreaks. During the current 2022 outbreak, monkeypox virus has persisted via human-human transmission, across all major continents and for longer than any previous record. This unprecedented spread creates the potential for the virus to 'spillback' into local susceptible animal populations. Persistent transmission amongst such animals raises the prospect of monkeypox virus becoming enzootic in new regions. However, the full and specific range of potential animal hosts and reservoirs of monkeypox remains unknown, especially in newly at-risk non-endemic areas. \n Methods: Here, our pipeline utilises ensembles of classifiers comprising different class balancing techniques and incorporating instance weights, to identify which animal species are potentially susceptible to monkeypox virus. Subsequently, we generate spatial distribution maps to highlight high-risk geographic areas at high resolution. \n Findings: We show that the number of potentially susceptible species is currently underestimated by 2.4 to 4.3-fold. We show a high density of susceptible wild hosts in Europe. We provide lists of these species, and highlight high-risk hosts for spillback and potential long-term reservoirs, which may enable monkeypox virus to become endemic.", "entities": []}
{"id": 3929, "text": "The data processing codes of Multiple-measurement.(for the proposed MPF method.)", "entities": []}
{"id": 3930, "text": "The data processing codes of Multiple-measurement.(for the proposed MPF method.)", "entities": [{"id": 445, "label": "Software", "start_offset": 0, "end_offset": 49}]}
{"id": 3931, "text": "A prototype of software required to drive the &quot;LEGO LIGO&quot; demonstration model, as produced by Cardiff University MSc Physics students (J. Zamorano-Osorio, V. Silva Neyra). The software is currently written in LabView, and will run on a RaspberryPi or similar in the final version. It will also be Open Source when it is complete.\n\nThe software takes an input from a simulated gravitational wave signal and drives LEGO Mindstorms in such a way to move the mirrors in the appropriate way. A student report on the prototype development is included as the link below.", "entities": []}
{"id": 3932, "text": "This code has been developed to perform the mapping of two structural databases: CATH and SCOP.", "entities": []}
{"id": 3933, "text": "Allow the user to compare either a DNA or protein sequence and compare it against the collection of InterPro member databases, assign InterPro annotations and associated GO terms.", "entities": []}
{"id": 3934, "text": "This process has been design based on a previous project (3Dpatch), it generates residue conservation annotations for PDBe and UniProt protein sequences and saves them in csv files.", "entities": []}
{"id": 3935, "text": "RESCAPER aids in outdoor ethnographic research and recording personal experience. The app allows the user to record their experience of their walk, i.e. take notes and pictures, record sounds, interviews or videos and annotate them with comments. The data they collect are automatically geo-referenced on a map marking the route they followed, accessible to review and share via rescaper.honestpartners.gr. The app was developed in McCord Centre for Landscape, Newcastle University and it is available for free from the App Store and Google Play. RESCAPER has received funding from the European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No 657050. It has also received funding from the UK Research and Innovation (AHRC) project ref. AH/P014453/1, the Newcastle University Faculty Impact Fund and McCord Centre.", "entities": [{"id": 1519, "label": "Software", "start_offset": 0, "end_offset": 8}, {"id": 1520, "label": "Software", "start_offset": 547, "end_offset": 555}]}
{"id": 3936, "text": "onetep is linear scaling density functional theory code. under a commercial license free to use for academics", "entities": [{"id": 446, "label": "Software", "start_offset": 0, "end_offset": 6}]}
{"id": 3937, "text": "Send personalised goals to people when they most need them, to support healthy eating.", "entities": []}
{"id": 3938, "text": "The Invisible East project has funds committed to the develpoment of a website from which the digital corpus of texts will be accessible. The website will provide a user friendly interface and a search tool which will allow specialists and non-specialists to easily survey and search the material uploaded to the website.", "entities": []}
{"id": 3939, "text": "We have started a GitHub repository of open source software for the visualization of health data", "entities": []}
{"id": 3940, "text": "This software tool implements a novel approach to tackle the challenges associated with the on-line diagnostics of loss of coolant accidents and the limitations of the current state of the art. The proposed strategy relies on the combination of more artificial neural network architectures through the use of Bayesian statistics, allowing to robustly absorb different sources of uncertainty without requiring their explicit characterization in input. As a result, it provides not only the quantification of the output confidence bounds but also the enhancement of the model response accuracy on the basis of the credibility of each individual architecture along the output domain. In addition to these advantages, the implemented methodology allows to relax the need for model selection as well as to limit the demand for user-defined analysis parameters, still guaranteeing the real-time feasibility of the computation.", "entities": []}
{"id": 3941, "text": "An image analysis tool allowing to translate two FLIM signals (parallel and perpendicular) into local rotation correlation parameter across the imaged region of interest. Applied to map local instantaneous molecular diffusion.", "entities": []}
{"id": 3942, "text": "A library of programs for Monte Carlo simulations of rapid molecular events inside and outside the synaptic cleft. Written by Drs L Savtchenko and K. Zheng.", "entities": []}
{"id": 3943, "text": "The Great British Public Toilet map now holds the largest database (10,000+) of Publicly Accessible Toilets available throughout the UK. The website provides location and access details of toilets and gives users the opportuniyt to comment, rate, add or delete toilet provision.", "entities": [{"id": 643, "label": "Software", "start_offset": 4, "end_offset": 35}]}
{"id": 3944, "text": "AUSTIN is a structural test data generation tool (for unit tests) for the C language. It is designed as a research prototype and the aim of this project is to aid researchers in automated test data generation using search-based algorithms. It is based on the CIL framework and currently supports a random search, as well as a simple hill climber that is augmented with a set of constraint solving rules for pointer type inputs.", "entities": [{"id": 872, "label": "Software", "start_offset": 0, "end_offset": 6}]}
{"id": 3945, "text": "Milu is an efficient and flexible C mutation testing tool designed for both first order and highe order mutation testing. The name 'Milu' is from a deer composed of four other animals. It has a horse's head, a deer's antlers, a donkey's body and a cow's hooves.", "entities": [{"id": 1077, "label": "Software", "start_offset": 0, "end_offset": 4}, {"id": 1078, "label": "Software", "start_offset": 132, "end_offset": 136}]}
{"id": 3946, "text": "MR4J is a MapReduce software component framework class building on standard Java parallel libraries to manage the scheduling of tasks in the different phases of execution on manycore processors. An optimiser is available to reduce the overhead associated with the intermediate data without extending the API.", "entities": [{"id": 1316, "label": "Software", "start_offset": 0, "end_offset": 4}]}
{"id": 3947, "text": "development/port of a compute-cache version of the Python 2.7 interpreter, based on earlier work from Stanford", "entities": []}
{"id": 3948, "text": "A Java-based utility to support domain-specific parallel programming abstractions (the map-reduce project in beehive-lab). This utility adapts the underlying code at runtime to improve its efficiency.", "entities": []}
{"id": 3949, "text": "The Tornado VM is a practical heterogeneous programming framework for automatically accelerating Java programs on heterogeneous (OpenCL-compatible, NVidia GPUs and Intel OneAPI) hardware.", "entities": [{"id": 644, "label": "Software", "start_offset": 4, "end_offset": 14}]}
{"id": 3950, "text": "An integrated internet-of-things framework with a user-friendly web front-end to show current environmental status (temperature, light, sound) and room occupancy within public spaces in the university campus.", "entities": []}
{"id": 3951, "text": "The Tornado VM is a practical heterogeneous programming framework for automatically accelerating Java programs on heterogeneous (OpenCL-compatible) hardware.", "entities": [{"id": 1079, "label": "Software", "start_offset": 4, "end_offset": 14}]}
{"id": 3952, "text": "Stochastic Hyperspace Embedding And Projection (SHEAP) is a dimensionality reduction method designed for visualising potential energy surfaces.\n\nComputational structure prediction can assist the discovery of new materials. One searches for the most stable configurations of a given set of atomic building blocks, which correspond to the deepest regions of an energy landscape-the system's energy as a function of the relative positions of its atoms. To explore these landscapes efficiently, it is important to understand their topologies. However, they exist in spaces with very large numbers of dimensions, making them difficult to visualise. SHEAP uses dimensionality reduction through manifold learning to effectively visualise the distribution of stable structures across a high-dimensional energy landscape.", "entities": [{"id": 1317, "label": "Software", "start_offset": 0, "end_offset": 46}, {"id": 1318, "label": "Software", "start_offset": 48, "end_offset": 53}, {"id": 1319, "label": "Software", "start_offset": 644, "end_offset": 649}]}
{"id": 3953, "text": "Ephemeral Data Derived Potentials (EDDP): The ddp package contains a suite of tools to construct and test data derived interatomic potentials. They are designed to be used with the airss first principles structure prediction package. Ab initio random structure searching (AIRSS) can be used to generate data, and exploit the generated ddp potentials to potentially accelerate searches. They are referred to as ephemeral data derived potentials as they are designed to be constructed for a particular set of structure searching parameters, discarded and regenerated as those parameters change. The methodology is introduced in Pickard, Ephemeral data derived potentials for random structure search, 2022.", "entities": [{"id": 1521, "label": "Software", "start_offset": 0, "end_offset": 33}, {"id": 1522, "label": "Software", "start_offset": 35, "end_offset": 39}]}
{"id": 3954, "text": "Ab initio Random Structure Searching (AIRSS) is a very simple, yet powerful and highly parallel, approach to structure prediction. The concept was introduced in 2006 and its philosophy more extensively discussed in 2011.\n\nRandom structures - or more precisely, random &quot;sensible&quot; structures - are generated and then relaxed to nearby local energy minima. Particular success has been found using density functional theory (DFT) for the energies, hence the focus on &quot;ab initio&quot; random structure searching. The sensible random structures are constructed so that they have reasonable densities, and atomic separations. Additionally they may embody crystallographic, chemical or prior experimental/computational knowledge. Beyond these explicit constraints the emphasis is on a broad, uniform, sampling of structure space.\n\nAIRSS has been used in a number of landmark studies in structure prediction, from the structure of SiH4 under pressure to providing the theoretical structures which are used to understand dense hydrogen (and anticipating the mixed Phase IV), incommensurate phases in aluminium under terapascal pressures, and ionic phases of ammonia.\n\nThe approach naturally extends to the prediction clusters/molecules, defects in solids, interfaces and surfaces (interfaces with vacuum).\n\nThe AIRSS package is tightly integrated with the CASTEP first principles total energy code. However, it is relatively straightforward to modify the scripts to use alternative codes to obtain the core functionality, and examples are provided.\n\nThe AIRSS package is released under the GPL2 licence.", "entities": [{"id": 447, "label": "Software", "start_offset": 0, "end_offset": 36}, {"id": 448, "label": "Software", "start_offset": 38, "end_offset": 43}, {"id": 449, "label": "Software", "start_offset": 838, "end_offset": 843}, {"id": 450, "label": "Software", "start_offset": 1316, "end_offset": 1321}, {"id": 451, "label": "Software", "start_offset": 1559, "end_offset": 1564}]}
{"id": 3955, "text": "MiSTree is a public python software used to construct and analyse data using the minimum spanning tree method we have outlined. The software has been complete for some time but is not publicly released yet but is planned to be released on an MIT licence.", "entities": [{"id": 645, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 3956, "text": "TwoWayMixer is a demonstration prototype that showcases the utilization of Deep Neural Networks to audio remixing through source separation, implemented using web audio technology.", "entities": [{"id": 873, "label": "Software", "start_offset": 0, "end_offset": 11}]}
{"id": 3957, "text": "Untwist is python library for audio source separation. It provides a self-contained object-oriented framework including common source separation algorithms as well as input/output functions, data management utilities and time-frequency transforms.", "entities": [{"id": 1080, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 3958, "text": "Code, procedures and designs available online, this webpage is continuously updated and as such the outcome date is always moved to the most recent year.", "entities": []}
{"id": 3959, "text": "Diversity.jl is a package for Julia based around a framework of similarity-sensitive diversity measures. It calculates the diversity of a population and its constituent subcommunities inclusive of similarity (taxonomic, phenotypic, genetic, phylogenetic, functional, and so on) between individuals.", "entities": [{"id": 1523, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 3960, "text": "rdiversity is a package for R based around a framework of similarity-sensitive diversity measures. It calculates the diversity of a population and its constituent subcommunities inclusive of similarity (taxonomic, phenotypic, genetic, phylogenetic, functional, and so on) between individuals.", "entities": [{"id": 452, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 3961, "text": "Model for the calculation of equilibrium constants that govern seawater acid base chemistry.", "entities": []}
{"id": 3962, "text": "This web tool was originally realised in 2020, in part as a response to the inception of the SARS-CoV-2 pandemic. Since its release and first publication, which were before the current award commenced, substantial time has been allocated (over the course of the current award) to maintaining the server and underlying software, including answering questions and fixing problems for users.\nIn addition, the server was used for an output from our group:\nComputational investigation of mechanisms for pH modulation of human chloride channels \nhttps://www.biorxiv.org/content/10.1101/2022.10.03.510624v1", "entities": []}
{"id": 3963, "text": "We co-designed a blueprint for a new women's health app. We then worked with a third party to build a prototype app and the tested it as part of a research project.", "entities": []}
{"id": 3964, "text": "Normative brain volumes were generated from participants in the UK Biobank. The calculator is fully automated and can be used to assess a patient's position on these nomograms.", "entities": [{"id": 1320, "label": "Software", "start_offset": 0, "end_offset": 23}]}
{"id": 3965, "text": "EyeTrackR consists of a set of R functions, bundled into a package, all geared towards analysing eye-tracking datasets.", "entities": [{"id": 1524, "label": "Software", "start_offset": 0, "end_offset": 9}]}
{"id": 3966, "text": "Software developed for the creation of stimuli for use in 3d visual search experiments.", "entities": []}
{"id": 3967, "text": "This software uses input from two inexpensive 3D cameras and generates a real-time visualisation of the mechanics of human breathing, including rib motions, diaphragm motions etc.", "entities": []}
{"id": 3968, "text": "The software developed is an image analysis tool to quantitatively retrieve concentrations of chemical components and spectral Raman-like profiles from hyperspectral CARS microscopy data", "entities": []}
{"id": 3969, "text": "A framework to develop, test and optimise fragmentation strategies in LC-MS metabolomics", "entities": []}
{"id": 3970, "text": "EBsim is a software that has been developed by our reserach group. It calculates the machined features under abrasive waterjet ablation and pulsed laser ablation based on the models developed in the STEEP euopean project. The solution of the inverse problem for both systems has been implmented in the software.", "entities": [{"id": 1321, "label": "Software", "start_offset": 0, "end_offset": 5}]}
{"id": 3971, "text": "I am co-leading the development of a Chatbot based on Chat-GPT for community health workers in India. We are developing a technical and clincial validation pipeline", "entities": []}
{"id": 3972, "text": "This software updates my previous 'brain-age' prediction software, with improved accuracy, as well as now being applicable to three different types of MRI scan, namely T1-weighted, T2-weighted and diffusion-weight imaging. The backend is completely new, this type implementing a ConvNet using Python. This software is also appropriate for use on raw, unprocessed MRI scans.", "entities": []}
{"id": 3973, "text": "The Huma Remote Monitoring App is a digital 'hospital at home' and decentralized clinical trial platform that uses real-time health data from smartphones to help patients, clinicians, researchers, and healthcare systems. We have developed a technical solution that enables the data, generated by the patients that are using the HUMA app, to be used in an integrated data platform. The data enables us to identify, quantify and measure the impact of changes made through patient pathways that can then be compared to the standards of care that exist today to evaluate co-designed improvements.", "entities": [{"id": 646, "label": "Software", "start_offset": 4, "end_offset": 30}, {"id": 647, "label": "Software", "start_offset": 328, "end_offset": 336}]}
{"id": 3974, "text": "FARSITE is web application which allows, at the front end, participating organisations/researchers to glean more information from an anonymised dataset. It can also allow the data controllers, if required, to access identifiable demographics information in order to recruit for research and improve care.", "entities": [{"id": 874, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 3975, "text": "A mu-wave programme has been developed to computationally model low reflection multi-layers windows for gyro-TWAs. This has not as yet been made open source as it could have commercial applications", "entities": [{"id": 1081, "label": "Software", "start_offset": 2, "end_offset": 19}]}
{"id": 3976, "text": "One of the key features of granular materials is the formation of force chains, which are chains of particles that bear strong forces. Force chains play a critical role in determining the mechanical behavior of granular materials, and their characterization is important for understanding the deformation patterns and failure mechanisms of granular materials. In this context, using a computational approach, the Force Chain Finder software has been developed to identify force chains in granular materials.", "entities": [{"id": 1322, "label": "Software", "start_offset": 413, "end_offset": 431}]}
{"id": 3977, "text": "Release Notes for GeNN 4.8.0 This release adds a number of significant new features to GeNN as well as including a number of bug fixes that have been identified since the 4.7.1 release. User Side Changes Custom updates extended to work on \n<code>SynapseMatrixWeight::KERNEL</code> weight update model variables (#524). Custom updates extended to perform reduction operations across neurons as well as batches (#539). PyGeNN can now automatically find Visual Studio build tools using functionality in \n<code>setuptools.msvc.msvc14_get_vc_env</code> (#471) GeNN now comes with a fully-functional Docker image and releases will be distributed via \n<a href=\"https://hub.docker.com/repository/docker/gennteam/genn\" rel=\"nofollow\">Dockerhub</a> as well as existing channels. Special thanks to @Stevinson , @jamesturner246 and @bdevans for their help on this (see the \n<a href=\"https://github.com/genn-team/genn/blob/master/README.md\" rel=\"nofollow\">README</a> for more information) (#548 and #550). Bug fixes Fixed bug relating to merging of synapse groups which perform presynaptic &quot;revInSyn&quot; updates (#520). Added missing parameter to PyGeNN. pygenn.genn_model.create_custom_postsynaptic_class function so postsynaptic models with extra global parameters can be created (#522). Correctly substitute 0 for \\$(batch) when using single-threaded CPU backend (#523). Fixed issues building PyGeNN with Visual Studio 2017 (#533). Fixed bug where model might not be rebuilt if sparse connectivity initialisation snippet was changed (#547). Fixed longstanding bug in the \n<code>gen_input_structured</code> tool -- used by some userprojects -- where data was written outside of array bounds (#551). Fixed issue with debug mode of \n<code>genn-buildmodel.bat</code> when used with single-threaded CPU backend (#551). Fixed issue where, if custom update models were the only part of a model that required an RNG for initialisation, one might not be instantiated (#540).", "entities": [{"id": 1526, "label": "Software", "start_offset": 18, "end_offset": 22}, {"id": 1527, "label": "Software", "start_offset": 87, "end_offset": 91}, {"id": 1529, "label": "Software", "start_offset": 417, "end_offset": 423}, {"id": 1530, "label": "Software", "start_offset": 555, "end_offset": 559}]}
{"id": 3978, "text": "As well as continuing to support the conversion of ANNs trained using TensorFlow to SNNs, this release adds a large amount of new functionality which enables SNNs to be defined from scratch in mlGeNN and trained directly using e-prop. User Side Changes New model description API for model description inspired by Keras (see documentation) Extensible Callback system allowing custom logic including for recording state to be triggered mid-simulation (see documentation) Extensible metrics system, allowing various metrics to be calculated efficiently (see documentation) Training using e-prop learning rule Conversion of ANNs trained in TensorFlow is now handled through the ml_genn_tf module (see documentation) Known issues The SpikeNorm algorithm for converting deep ANNs to rate-coded SNNs is currently broken - if you require this functionality please stick with mlGeNN 1.0", "entities": [{"id": 453, "label": "Software", "start_offset": 867, "end_offset": 873}, {"id": 454, "label": "Software", "start_offset": 193, "end_offset": 199}]}
{"id": 3979, "text": "Release Notes for GeNN v4.7.0 This release adds a number of significant new features to GeNN as well as including a number of bug fixes that have been identified since the 4.6.0 release. User Side Changes While a wide range of convolutional type connectivity can be implemented using \n<code>SynapseMatrixConnectivity::PROCEDURAL</code>, the performance is often worse than sparse connectivity. \n<code>SynapseMatrixConnectivity::TOEPLITZ</code> provides a more efficient solution with \n<code>InitToeplitzConnectivitySnippet::Conv2D</code> and \n<code>InitToeplitzConnectivitySnippet::AvgPoolConv2D</code> implementing some typical connectivity patterns (#484). Shared weight kernels had to be previously provided as extra global parameters via the \n<code>InitVarSnippet::Kernel</code> variable initialisation snippet. This meant kernels had to be manually allocated to the correct size and couldn't be initialised using standard functionality. \n<code>SynapseMatrixWeight::KERNEL</code> allows kernels to be treated as standard state variables (#478). Some presynaptic updates need to update the state of presynaptic neurons as well as postsynaptic. These updates can now be made using the \\$(addToPre,...) function from presynaptic update code and the destination additional input variable can be specified using \n<code>SynapseGroup::setPreTargetVar</code> (#479). On Windows, all models in the same directory would build their generated code into DLLs with the same name, prevented the the caching system introduced in v4.5.0 working properly. \n<code>CodeGenerator::PreferencesBase::includeModelNameInDLL</code> includes the name of the model in the DLL filename, resolving this problem. This is now the default behaviour in PyGeNN but, when using GeNN from C++, the flag must be manually set and MSBuild projects updated to link to the correct DLL (#476). Neuron code can now sample the binomial distribution using \\$(gennrand_binomial) and this can be used to initialise variables with \n<code>InitVarSnippet::Binomial</code> (#498). In the latest version of Windows Subsystem for Linux, CUDA is supported but libcuda is mounted in a non-standard location. GeNN's CUDA backend now adds this location to the linker paths (#500). Bug fixes: Fixed issues with some configurations of \n<code>InitSparseConnectivitySnippet::Conv2D</code> when stride &gt; 1 which caused incorrect connectivity to be instantiated as well as crashes when this snippet was used to generate sparse connectivity (#489, #491). Fixed issue where, if \\$(addToInSynDelay) was used in spike-like event code, it was not detected and dendritic delay structures were not correctly created (#494). Fixed issue where precision wasn't being correctly applied to neuron additional input variable and sparse connectivity row build state variable initialisation meaning double precision code could unintentially be generated (#489).", "entities": [{"id": 653, "label": "Software", "start_offset": 18, "end_offset": 22}, {"id": 654, "label": "Software", "start_offset": 88, "end_offset": 92}]}
{"id": 3980, "text": "This release adds a number of significant new features to mlGeNN including support for training models using EventProp, as well as including a number of bug fixes that have been identified since the 2.0 release. User Side Changes EventProp compiler for training models with EventProp (#57, #64, #70) System so compilers can define default settings for neuron models e.g. reset behaviour (#63) Support for time varying inputs as well as a wider range of input neuron types (#69) Spike-like event recording (#54) Spike count recording (#73) Bug fixes Fixed issues with manual training loops e.g. for augmentation (#74, #78) Fixed issue with management of callback state (#65) Fixed issue with loading and unloading compiled networks (#66)", "entities": [{"id": 875, "label": "Software", "start_offset": 58, "end_offset": 64}]}
{"id": 3981, "text": "Release Notes for GeNN 4.9.0 This release adds a number of significant new features to GeNN as well as including a number of bug fixes that have been identified since the 4.8.1 release. It is intended as the last release for GeNN 4.X.X. Fixes for serious bugs may be backported if requested but, otherwise, development will be switching to GeNN 5. User Side Changes Implemented \n<code>pygenn.GeNNModel.unload</code> to manually unload GeNN models to improve control in scenarios such as parameter sweeping where multiple PyGeNN models need to be instantiated (#581). Added Extra Global Parameter references to custom updates (see Defining Custom Updates, Defining your own custom update model and Extra Global Parameter references (#583). Expose \n<code>$(num_pre)</code>, \n<code>$(num_post)</code>, \n<code>$(num_batches)</code> to all user code strings (#576) Bug fixes Fixed handling of indices specified as sequences types other than numpy arrays in \n<code>pygenn.SynapseGroup.set_sparse_connections</code> (#597). Fixed bug in CUDA constant cache estimation bug which could cause nvLink errors in models with learning rules which required previous spike times (#589). Fixed longstanding issue with setuptools that meant PyGeNN sometimes had to be built twice to obtain a functional version. Massive thanks to @erolm-a for contributing this fix (#591). Optimisations Reduced the number of layers and generally optimised Docker image. Massive thanks to @bdevans for his work on this (#601).", "entities": [{"id": 1082, "label": "Software", "start_offset": 18, "end_offset": 22}, {"id": 1083, "label": "Software", "start_offset": 87, "end_offset": 91}, {"id": 1084, "label": "Software", "start_offset": 225, "end_offset": 230}, {"id": 1085, "label": "Software", "start_offset": 340, "end_offset": 344}, {"id": 1086, "label": "Software", "start_offset": 385, "end_offset": 408}, {"id": 1087, "label": "Software", "start_offset": 435, "end_offset": 446}, {"id": 1088, "label": "Software", "start_offset": 1223, "end_offset": 1229}, {"id": 1089, "label": "Software", "start_offset": 521, "end_offset": 527}]}
{"id": 3982, "text": "The Cardiac Electro-Mechanics Research Group Application (CemrgApp) is a platform with custom image processing and computer vision toolkits for applying statistical, machine learning, and simulation approaches to cardiovascular data. CemrgApp provides an integrated environment, where cardiac data visualisation and workflow prototyping are presented through a common user friendly graphical interface. CemrgApp at present supports:", "entities": [{"id": 1323, "label": "Software", "start_offset": 4, "end_offset": 56}, {"id": 1324, "label": "Software", "start_offset": 58, "end_offset": 66}, {"id": 1325, "label": "Software", "start_offset": 234, "end_offset": 242}, {"id": 1326, "label": "Software", "start_offset": 403, "end_offset": 411}]}
{"id": 3983, "text": "Finesse is a software package that allows to design and test par-axial laser optics setups, with a specific focus on precision length measurements. The package is well documented and open source. Development has started in 1997 and software has been used and improved within the international science collaborations ever since. It is still under active development with new features being implemented upon request from the community. Optics, active and adaptive optics, mirrors, aspherics, interferometers, photonics", "entities": [{"id": 1531, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 3984, "text": "We are working with Cambridge and Newcastle universities to create an adaptive mesh solver for turbulent reacting flows. Good progress is being made with the anticipation that the software will be released in late 2017 or 2018.", "entities": [{"id": 455, "label": "Software", "start_offset": 69, "end_offset": 119}]}
{"id": 3985, "text": "This is a library for verifying hybrid systems using Isabelle/HOL, which is strongly inspired by differential dynamic logic, but goes beyond it in several ways, e.g. addition of matrices and transcendental functions.", "entities": []}
{"id": 3986, "text": "<strong>Abstract</strong> Event-driven reactive programs combine traditional sequential programming constructs with primitives to allow communication with other concurrent agents. They are ubiquitous in modern applications, ranging from components systems and web services, to cyber physical systems and autonomous robots, and so verification support for them is highly desirable. We present a verification strategy for concurrent and reactive programs, with a large or infinite state space, utilising algebraic laws for reactive relations. We define novel operators to characterise interactions and state updates, and an associated equational theory. With this we can calculate a reactive program's denotational semantics, and thereby facilitate automated proof. Of note is our reasoning support for iterative programs with reactive invariants, which is supported by Kleene algebra, and parallel composition, which allows flexible specification of various concurrency schemes. We illustrate our strategy by verifying a reactive buffer. Our laws and strategy are mechanised in Isabelle/UTP, our implementation of Hoare and He's Unifying Theories of Programming (UTP) semantic framework, which provides soundness guarantees, and practical verification support. \n<strong>Isabelle Formalisation</strong> This archive accompanies the JLAMP journal submission, &quot;Automated Verification of Reactive and Concurrent Programs by Calculation&quot;. All of the Isabelle/HOL theories needed to support the theorems developed in this paper are included, and also the dependencies from the Archive of Formal Proofs (AFP). This development depends on Isabelle/2019 (from https://isabelle.in.tum.de/). In order to view the theories, you first need to make Isabelle aware of the Isabelle/UTP directly. You can either do this by adding a reference to its absolute path in the ROOTS file of your Isabelle installation, or else by invoking Isabelle on the command line with a command such as: \n<pre><code>isabelle jedit -d /path/to/isabelle/utp -l UTP-Circus</code></pre> The main heap images of interest are UTP, UTP-Reactive-Designs, and UTP-Circus. The first time you invoke the command, you may need to wait for a while to allow Isabelle to build the heap image. You can find the reactive buffer example under tutorial/utp_csp_buffer.thy and further reactive program examples in tutorial/utp_csp_ex.thy. The theories for reactive designs and stateful failure reactive designs may be found under theories/{rea_designs, sf_rdes}.", "entities": [{"id": 876, "label": "Software", "start_offset": 1269, "end_offset": 1278}, {"id": 877, "label": "Software", "start_offset": 1989, "end_offset": 1997}, {"id": 878, "label": "Software", "start_offset": 1881, "end_offset": 1889}, {"id": 879, "label": "Software", "start_offset": 1766, "end_offset": 1778}, {"id": 880, "label": "Software", "start_offset": 1454, "end_offset": 1462}, {"id": 881, "label": "Software", "start_offset": 1077, "end_offset": 1085}]}
{"id": 3987, "text": "Isabelle/SACM is an implementation of the OMG standard &quot;Structure Assurance Case Metamodel&quot;. It allows the development of assurance cases to support certification of critical systems.", "entities": [{"id": 1090, "label": "Software", "start_offset": 0, "end_offset": 13}]}
{"id": 3988, "text": "<strong>Abstract</strong> Isabelle/SACM is a tool for automated construction of model-based assurance cases with integrated formal methods, based on the Isabelle proof assistant. Assurance cases show how a system is safe to operate, through a human comprehensible argument demonstrating that the requirements are satisfied, using evidence of various provenances. They are usually required for certification of critical systems, often with evidence that originates from formal methods. Automating assurance cases increases rigour, and helps with maintenance and evolution. In this paper we apply Isabelle/SACM to a fragment of the assurance case for an autonomous underwater vehicle demonstrator. We encode the metric unit system (SI) in Isabelle, to allow modelling requirements and state spaces using physical units. We develop a behavioural model in the graphical RoboChart state machine language, embed the artifacts into Isabelle/SACM, and use it to demonstrate satisfaction of the requirements. \n<strong>Isabelle Formalisation</strong> This archive accompanies the FormaliSE 2020 paper &quot;Formal Model-Based Assurance Cases in Isabelle/SACM: An Autonomous Underwater Vehicle Case Study&quot;. The larger of the two files contains a Linux distribution of Isabelle2019 with all the additional files needed to start Isabelle/SACM and see the results presented in the paper. The archive also Isabelle/DOF 1.0 (from Prof. Achim Brucker and Prof. Burkhart Wolff), Isabelle/UTP, and several Archive of Formal Proofs (AFP) entries that our development depends upon. These theories are redistributed under the terms of the 2 and 3 clause BSD license. The smaller file contains only those Isabelle files directly related to the LRE case study. In order to get started, extract the larger archive to a suitable directory, and then from here execute \n<pre><code>bin/isabelle jedit -l RoboChart-Assurance</code></pre> This will start Isabelle and build several session heap images, including Isabelle/DOF and RoboChart. Once finished, the assurance case example can be found under src/CyPhyAssure/AUV/LRE/LRE.thy, and the various theory files it imports. In particular, the state machine can be found in LRE_Beh.thy.", "entities": [{"id": 1327, "label": "Software", "start_offset": 26, "end_offset": 39}, {"id": 1328, "label": "Software", "start_offset": 595, "end_offset": 608}, {"id": 1329, "label": "Software", "start_offset": 925, "end_offset": 938}, {"id": 1330, "label": "Software", "start_offset": 1135, "end_offset": 1148}, {"id": 1331, "label": "Software", "start_offset": 1321, "end_offset": 1335}, {"id": 1332, "label": "Software", "start_offset": 1396, "end_offset": 1408}, {"id": 1333, "label": "Software", "start_offset": 1466, "end_offset": 1478}, {"id": 1334, "label": "Software", "start_offset": 1492, "end_offset": 1516}, {"id": 1335, "label": "Software", "start_offset": 1518, "end_offset": 1521}, {"id": 1336, "label": "Software", "start_offset": 1687, "end_offset": 1695}, {"id": 1337, "label": "Software", "start_offset": 1987, "end_offset": 1999}, {"id": 1338, "label": "Software", "start_offset": 2004, "end_offset": 2013}, {"id": 1339, "label": "Software", "start_offset": 737, "end_offset": 745}]}
{"id": 3989, "text": "<strong>Abstract</strong> Isabelle/SACM is a tool for automated construction of model-based assurance cases with integrated formal methods, based on the Isabelle proof assistant. Assurance cases show how a system is safe to operate, through a human comprehensible argument demonstrating that the requirements are satisfied, using evidence of various provenances. They are usually required for certification of critical systems, often with evidence that originates from formal methods. Automating assurance cases increases rigour, and helps with maintenance and evolution. In this paper we apply Isabelle/SACM to a fragment of the assurance case for an autonomous underwater vehicle demonstrator. We encode the metric unit system (SI) in Isabelle, to allow modelling requirements and state spaces using physical units. We develop a behavioural model in the graphical RoboChart state machine language, embed the artifacts into Isabelle/SACM, and use it to demonstrate satisfaction of the requirements. \n<strong>Isabelle Formalisation</strong> This archive accompanies the FormaliSE 2020 paper &quot;Formal Model-Based Assurance Cases in Isabelle/SACM: An Autonomous Underwater Vehicle Case Study&quot;. The larger of the two files contains a Linux distribution of Isabelle2019 with all the additional files needed to start Isabelle/SACM and see the results presented in the paper. The archive also Isabelle/DOF 1.0 (from Prof. Achim Brucker and Prof. Burkhart Wolff), Isabelle/UTP, and several Archive of Formal Proofs (AFP) entries that our development depends upon. These theories are redistributed under the terms of the 2 and 3 clause BSD license. The smaller file contains only those Isabelle files directly related to the LRE case study. In order to get started, extract the larger archive to a suitable directory, and then from here execute \n<pre><code>bin/isabelle jedit -l RoboChart-Assurance</code></pre> This will start Isabelle and build several session heap images, including Isabelle/DOF and RoboChart. Once finished, the assurance case example can be found under src/CyPhyAssure/AUV/LRE/LRE.thy, and the various theory files it imports. In particular, the state machine can be found in LRE_Beh.thy.", "entities": [{"id": 1532, "label": "Software", "start_offset": 26, "end_offset": 39}, {"id": 1533, "label": "Software", "start_offset": 595, "end_offset": 608}, {"id": 1534, "label": "Software", "start_offset": 737, "end_offset": 745}, {"id": 1535, "label": "Software", "start_offset": 925, "end_offset": 938}, {"id": 1536, "label": "Software", "start_offset": 1135, "end_offset": 1148}, {"id": 1537, "label": "Software", "start_offset": 1466, "end_offset": 1478}, {"id": 1538, "label": "Software", "start_offset": 1396, "end_offset": 1408}, {"id": 1539, "label": "Software", "start_offset": 1987, "end_offset": 1999}, {"id": 1540, "label": "Software", "start_offset": 1321, "end_offset": 1334}]}
{"id": 3990, "text": "Hoare and He's Unifying Theories of Programming is a framework for construction of denotational semantic meta-models for a variety of programming languages based on an alphabetised relational calculus. Isabelle/UTP is an implementation of their framework based in Isabelle/HOL. It can be used to formalise semantic building blocks for programming language paradigms (based on UTP theories), prove algebraic laws of programming, and then use these laws to construct program verification tools.", "entities": [{"id": 456, "label": "Software", "start_offset": 0, "end_offset": 48}, {"id": 457, "label": "Software", "start_offset": 202, "end_offset": 215}]}
{"id": 3991, "text": "A library for verification and animation of sequential and concurrent systems based in Isabelle/HOL.", "entities": []}
{"id": 3992, "text": "<strong>Abstract</strong> Event-driven reactive programs combine traditional sequential programming constructs with primitives to allow communication with other concurrent agents. They are ubiquitous in modern applications, ranging from components systems and web services, to cyber physical systems and autonomous robots, and so verification support for them is highly desirable. We present a verification strategy for concurrent and reactive programs, with a large or infinite state space, utilising algebraic laws for reactive relations. We define novel operators to characterise interactions and state updates, and an associated equational theory. With this we can calculate a reactive program's denotational semantics, and thereby facilitate automated proof. Of note is our reasoning support for iterative programs with reactive invariants, which is supported by Kleene algebra, and parallel composition, which allows flexible specification of various concurrency schemes. We illustrate our strategy by verifying a reactive buffer. Our laws and strategy are mechanised in Isabelle/UTP, our implementation of Hoare and He's Unifying Theories of Programming (UTP) semantic framework, which provides soundness guarantees, and practical verification support. \n<strong>Isabelle Formalisation</strong> This archive accompanies the JLAMP journal submission, &quot;Automated Verification of Reactive and Concurrent Programs by Calculation&quot;. All of the Isabelle/HOL theories needed to support the theorems developed in this paper are included, and also the dependencies from the Archive of Formal Proofs (AFP). This development depends on Isabelle/2019 (from https://isabelle.in.tum.de/). In order to view the theories, you first need to make Isabelle aware of the Isabelle/UTP directly. You can either do this by adding a reference to its absolute path in the ROOTS file of your Isabelle installation, or else by invoking Isabelle on the command line with a command such as: \n<pre><code>isabelle jedit -d /path/to/isabelle/utp -l UTP-Circus</code></pre> The main heap images of interest are UTP, UTP-Reactive-Designs, and UTP-Circus. The first time you invoke the command, you may need to wait for a while to allow Isabelle to build the heap image. You can find the reactive buffer example under tutorial/utp_csp_buffer.thy and further reactive program examples in tutorial/utp_csp_ex.thy. The theories for reactive designs and stateful failure reactive designs may be found under theories/{rea_designs, sf_rdes}.", "entities": [{"id": 882, "label": "Software", "start_offset": 1077, "end_offset": 1089}, {"id": 883, "label": "Software", "start_offset": 1269, "end_offset": 1277}, {"id": 884, "label": "Software", "start_offset": 1454, "end_offset": 1462}, {"id": 885, "label": "Software", "start_offset": 1640, "end_offset": 1648}, {"id": 886, "label": "Software_Url", "start_offset": 1660, "end_offset": 1687}, {"id": 887, "label": "Software", "start_offset": 1765, "end_offset": 1778}, {"id": 888, "label": "Software", "start_offset": 1989, "end_offset": 1997}]}
{"id": 3993, "text": "The BioCatalogue is a Web-based Catalogue of Life Science Web Services.", "entities": [{"id": 1091, "label": "Software", "start_offset": 4, "end_offset": 16}]}
{"id": 3994, "text": "A Catalogue of Biodiversity Web Services", "entities": [{"id": 1340, "label": "Software", "start_offset": 0, "end_offset": 40}]}
{"id": 3995, "text": "Python scripts for computing Nuclear Independent Chemical Shifts and buildup functions from Castep data.\n\nThe chemical shift at which a nuclear environment appears in solid-state NMR is dependent not only on the local intramolecular interactions affecting that environment, but also on interactions with longer range features such as ring currents and hydrogen bonding. Utilising DFT GIPAW calculations, it is possible to partition the contributions of these different features to chemical shift. Further, it is possible to observe the spatial effects of these contributions, and the distance at which these contributions arise. These scripts facilitate computing such interactions.", "entities": []}
{"id": 3996, "text": "NMR crystallography visualisation app", "entities": [{"id": 458, "label": "Software", "start_offset": 0, "end_offset": 37}]}
{"id": 3997, "text": "Density functional theory (DFT) is a quantum mechanical simulation method that has become one of the most widely used research tools, with approximately 30,000 papers using it published each year. The CASTEP DFT code is a UK flagship code, specialised for solid materials, and is heavily used on ARCHER (300-400 active users). While support for obtaining the ground-state electronic and atomic configurations is now very good, computing transition states, reaction rates, and exploring free energy barriers with enhanced sampling were all still poorly supported in the CASTEP code before this eCSE was completed, despite their importance for a wide range of chemistry and materials science applications.\n\nIn this eCSE project we have implemented two key new features in the CASTEP code to address these issues: (i) support for the extremely widely used (&gt;12k citations) nudged elastic band (NEB) transition state search tool, augmented by a state-of-the-art robust optimizer; (ii) an interface to the i-PI universal force engine which allows CASTEP to be connected efficiently to a wide range of external codes with enhanced sampling capabilities.\n\nThe new NEB implementation has also been parallelised so that it can be used efficiently on massively parallel computing centres, such as ARCHER2. We used a farm-based MPI parallelization approach where each image along the chain of states representing the reaction path runs on its own set of cores. The farms are loosely coupled, since they only need to exchange information at the end of each electronic minimisation. This leads to perfect weak scaling, validated on a 16-image system with up to 16 farms respectively.\n\nOur new code has been merged into the CASTEP development repository and will be included in the forthcoming 2022 release of the code, after which it will be widely available to ARCHER users. Key beneficients of the project include the CCP-NC, CCP9 and UKCP communities, where the new tools will aid in reconciling experimental observations with atomic-scale behaviour, helping to guide and interpret future experiments.", "entities": [{"id": 658, "label": "Software", "start_offset": 774, "end_offset": 780}, {"id": 659, "label": "Software", "start_offset": 1713, "end_offset": 1719}, {"id": 660, "label": "Software", "start_offset": 1044, "end_offset": 1051}, {"id": 661, "label": "Software", "start_offset": 569, "end_offset": 575}, {"id": 662, "label": "Software", "start_offset": 201, "end_offset": 207}]}
{"id": 3998, "text": "NMR crystallography is a powerful tool with applications in structural characterization and crystal structure verification, to name two. However, applying this tool presents several challenges, especially for industrial users, in terms of consistency, workflow, time consumption, and the requirement for a high level of understanding of experimental solid-state NMR and GIPAW-DFT calculations. Here, we have developed a series of fully parameterized scripts for use in Materials Studio and TopSpin, based on the .magres file format, with a focus on organic molecules (e.g. pharmaceuticals), improving efficiency, robustness, and workflow. We separate these tools into three major categories: performing the DFT calculations, extracting &amp; visualizing the results, and crystallographic modelling. These scripts will rapidly submit fully parameterized CASTEP jobs, extract data from the calculations, assist in visualizing the results, and expedite the process of structural modelling. Accompanied with these tools is a description on their functionality, documentation on how to get started and use the scripts, and links to video tutorials for guiding new users. Through the use of these tools, we hope to facilitate NMR crystallography and to harmonize the process across users.", "entities": [{"id": 889, "label": "Software", "start_offset": 0, "end_offset": 20}]}
{"id": 3999, "text": "CASTEP is a software package for predictive, quantum-mechanical simulations of materials and chemicals. It is based on density functional theory, and can simulate a wide range of materials proprieties including energetics, the structure at the atomic level, vibrational properties and electronic response properties. In particular it has a wide range of spectroscopic features that link directly to experiment, such as infra-red and Raman spectroscopies, NMR, and core level spectra. CASTEP version 20 included many enhancements and optimisations, including improvements to spin-orbit coupling simulations. A range of interface codes are also included, the most recent of which allow calculations of electronic and thermal transport.", "entities": [{"id": 1092, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 1093, "label": "Software", "start_offset": 484, "end_offset": 490}]}
{"id": 4000, "text": "CASTEP is a software package for predictive, quantum-mechanical simulations of materials and chemicals. It is based on density functional theory, and can simulate a wide range of materials proprieties including energetics, the structure at the atomic level, vibrational properties and electronic response properties. In particular it has a wide range of spectroscopic features that link directly to experiment, such as infra-red and Raman spectroscopies, NMR, and core level spectra. The enhancements to CASTEP 21 are particularly useful for modelling heavy elements, especially where spin-orbit coupling or non-collinear magnetism are important.", "entities": [{"id": 1341, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 1342, "label": "Software", "start_offset": 504, "end_offset": 510}]}
{"id": 4001, "text": "CASTEP is a software package for predictive, quantum-mechanical simulations of materials and chemicals. It is based on density functional theory, and can simulate a wide range of materials proprieties including energetics, the structure at the atomic level, vibrational properties and electronic response properties. In particular it has a wide range of spectroscopic features that link directly to experiment, such as infra-red and Raman spectroscopies, NMR, and core level spectra.\n\nCASTEP version 19 included many enhancements and optimisations, including improved performance and the ability to compute electron-phonon coupling (important for electronic transport modelling).", "entities": [{"id": 1541, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 1542, "label": "Software", "start_offset": 485, "end_offset": 491}]}
{"id": 4002, "text": "A generic API to provide an abstract interface to atomistic simulation programs, without needing to know the implementation details of the simulation programs themselves. This enables high-level software frameworks and workflows to switch easily between different simulation packages (for example, to compute forces); similarly, developers of simulation software implement this API in their programs, and immediately have their software be usable in the high-level tools.", "entities": []}
{"id": 4003, "text": "CASTEP is a software package for predictive, quantum-mechanical simulations of materials and chemicals. It is based on density functional theory, and can simulate a wide range of materials proprieties including energetics, the structure at the atomic level, vibrational properties and electronic response properties. In particular, it has a wide range of spectroscopic features that link directly to experiment, such as infra-red and Raman spectroscopies, NMR, and core level spectra. CASTEP version 23 extended a top-level Python layer to enable CASTEP to be embedded within other computational workflows, for example transition-state searches or multiscale modelling.", "entities": [{"id": 655, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 656, "label": "Software", "start_offset": 485, "end_offset": 491}, {"id": 657, "label": "Software", "start_offset": 547, "end_offset": 553}]}
{"id": 4004, "text": "CASTEP is a software package for predictive, quantum-mechanical simulations of materials and chemicals. It is based on density functional theory, and can simulate a wide range of materials proprieties including energetics, the structure at the atomic level, vibrational properties and electronic response properties. In particular, it has a wide range of spectroscopic features that link directly to experiment, such as infra-red and Raman spectroscopies, NMR, and core level spectra. CASTEP version 24 included a new parallel data distribution, which significantly enhanced parallel scaling.", "entities": [{"id": 890, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 891, "label": "Software", "start_offset": 485, "end_offset": 491}]}
{"id": 4005, "text": "CASTEP is a software package for predictive, quantum-mechanical simulations of materials and chemicals. It is based on density functional theory, and can simulate a wide range of materials proprieties including energetics, the structure at the atomic level, vibrational properties and electronic response properties. In particular, it has a wide range of spectroscopic features that link directly to experiment, such as infra-red and Raman spectroscopies, NMR, and core level spectra. CASTEP version 22 included a top-level Python layer to enable CASTEP to be embedded within other computational workflows, for example transition-state searches or multiscale modelling.", "entities": [{"id": 1094, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 1095, "label": "Software", "start_offset": 547, "end_offset": 553}, {"id": 1096, "label": "Software", "start_offset": 485, "end_offset": 491}]}
{"id": 4006, "text": "Uniqueness of the model is in very granular spatial and temporal resolution while considering multi-energy vectors including electricity, heat, transport.", "entities": []}
{"id": 4007, "text": "It is a social media website to help communities save energy", "entities": []}
{"id": 4008, "text": "As part of eViz an Energy Diary has been developed for the iPad that aims to measure energy-related actions during peak times, as well as record peoples beliefs and understanding related to these actions. This tool will be used in future research to measure energy-related behaviours in households.", "entities": [{"id": 459, "label": "Software", "start_offset": 19, "end_offset": 31}]}
{"id": 4009, "text": "A Virtual Reality prototype software tool to visualise the impact of decisions relating to domestic energy usage. The software, which runs under the Unity3D rendering tool, takes the form of an interactive 3D apartment (single floor, single bedroom, shower room, kitchen, living room) which can be viewed exocentrically (&quot;bird's eye) or egocentrically (first-person) and navigated using keyboard or Xbox controller. Energy-expending/energy-influencing features, from windows and lights to cooker hob rings and a central heating thermostat can be interacted with (opened/closed; turned on/off, etc.). Wall and roof insulation materials can be selected, different forms of light bulbs are available and the 3D can be viewed in &quot;normal&quot;, &quot;night vision&quot; and &quot;thermal mode&quot;. The task of the end user is to explore the apartment and modify the dwelling's thermal expenditure qualities. The users' results are displayed at the end of each session. In addition to the &quot;desktop&quot; implementation of the Virtual Apartment (I.e. standard PC/laptop interface), the prototype can be experienced using so-called &quot;immersive&quot; VR techniques, via an Oculus Rift head-mounted display and Xbox controller, or on a Samsung S6 Smartphone, integrated with a Samsung GearVR headset and associated hand controller.", "entities": [{"id": 664, "label": "Software", "start_offset": 2, "end_offset": 41}]}
{"id": 4010, "text": "Custom-made calibration software for the 5.1 cardioid microphone developed as part of the project.", "entities": [{"id": 892, "label": "Software", "start_offset": 0, "end_offset": 33}]}
{"id": 4011, "text": "Python code for analysis of image data to find patterns in datasets", "entities": []}
{"id": 4012, "text": "iRecord soil builds on the iRecord family of apps developed in CEH. These apps are for recording ecological information. iRecord-soil is a test platform for collecting georefreneced soil information that can be linked to soil analysis records from commercial laboratories.", "entities": [{"id": 1343, "label": "Software", "start_offset": 0, "end_offset": 12}, {"id": 1344, "label": "Software", "start_offset": 121, "end_offset": 133}]}
{"id": 4013, "text": "DECoRuM&copy; (Domestic Energy, Carbon counting and carbon Reduction Model) is a GIS-based toolkit for carbon emissions reduction planning with the capability to estimate current energy-related CO2 emissions and effectiveness of mitigation strategies in existing UK dwellings, aggregating the results to a street, district and city level. For the SNACC project DECoRuM was further developed as DECoRuM-Adapt&copy; to rapidly assess the probabilistic impact of climate change on energy use, overheating potential and the effectiveness of adaptation strategies for modelled dwellings and neighbourhoods.", "entities": [{"id": 1543, "label": "Software", "start_offset": 0, "end_offset": 12}, {"id": 1544, "label": "Software", "start_offset": 15, "end_offset": 74}, {"id": 1545, "label": "Software", "start_offset": 394, "end_offset": 412}]}
{"id": 4014, "text": "merpWS and merpData have been created on Github to provide a publicly available resource accessible to all (see https://github.com/MarineEcosystemResearchProgramme/). These packages are accompanied by a basic application making use of CEFAS web services to access temperature data.", "entities": [{"id": 460, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 461, "label": "Software", "start_offset": 11, "end_offset": 20}, {"id": 462, "label": "Software_Url", "start_offset": 112, "end_offset": 164}]}
{"id": 4015, "text": "The Dashboard This tool allows users to access to all open social media feeds (including the Twitter firehose) using a keyword search to identify variation in hate orientated text contained within posts. The dashboard currently allows for the classification of posts containing text that is antagonistic or hateful based on race (anti-black), religion (anti-Muslim), sexual orientation (anti-gay male and female), disability (anti-physical disability), and Jewish identity. Once posts are classified they can be visualised via a suite of tools: a. Real-time and historic modes, allowing end-user to monitor hate speech as it unfolds, and to search back over periods of user data collection for post-hoc analysis b. An interactive hate line chart displaying frequency of tweets, with customisable scale (raw, percentage, log etc). c. An interactive tool for network analysis of hate tweets (where nodes can be selected for further inspection and the production of sub-networks, such as Twitter @mentions, retweets, followers etc.) d. Red/Amber/Green real-time alert system for anomalous spikes in online hate speech above a baseline (defined by user or inferred from average number of hate posts in a given time-frame) e. Tool to identify top N hate hashtags f. Tool to identify top N hate influencers (e.g. top N accounts responsible for N% of hate speech) g. Tool to identify when a top hate user's account is deleted/suspended h. Tool to identify top victim targets (e.g. top N accounts targeted with hate using @mentions) i. Tool to identify Bot accounts with functionality to remove all suspected bots from the analysis and visualization j. Tool to identify links between social media platforms in posts (e.g. frequency of links to far-right open Facebook pages in tweets, far right post on reddit etc.) k. Topic clustering tool, displaying topics detected in posted text and proportion of topics over whole corpus l. Tool to display simple Wordclouds of hate tweets (in addition to topic detection) m. Export tool (sections of dash can be exported) to PDF, image file, bespoke format for end-user n. Demographic estimation of users at an aggregate level (e.g. gender, age) o. Aggregate (e.g. town, city, PFA) geo-location inference plotted on a scalable map (using Lat/Long, user specified location, location name specified in bio etc. - user can specify which are displayed, with all being selectable at once). Individual visualisation tools can be resized and 'toggled' in and out of the view, allowing the user to select the preferred Dashboard set-up for the monitoring task. The suite of tools can also be split over multiple screens to provide the most complete Dashboard set-up.", "entities": [{"id": 665, "label": "Software", "start_offset": 714, "end_offset": 776}, {"id": 667, "label": "Software", "start_offset": 1033, "end_offset": 1071}, {"id": 668, "label": "Software", "start_offset": 1811, "end_offset": 1832}, {"id": 669, "label": "Software", "start_offset": 2105, "end_offset": 2128}, {"id": 670, "label": "Software", "start_offset": 2180, "end_offset": 2236}]}
{"id": 4016, "text": "An automated theorem prover able to construct proofs (or in some cases establish that no proof can be found) for problems in polymorphic first-order logic with theories (arithmetic, arrays, datatypes) and higher-order logic.", "entities": []}
{"id": 4017, "text": "This is our ports of the Unikraft and FlexOS operating systems to the ARM Morello platform, using its hybrid capability mode. This software was developed as part of the research effort that led to this paper:\nJohn Alistair Kressel, Hugo Lefeuvre, and Pierre Olivier, &quot;Software Compartmentalization Trade-Offs with Hardware Capabilities&quot;, Workshop on Programming Languages and Operating Systems (PLOS), 2023\n\nFor more information see the project's website https://olivierpierre.github.io/project-flexcap/", "entities": [{"id": 1097, "label": "Software_Url", "start_offset": 465, "end_offset": 513}]}
{"id": 4018, "text": "This repository contains the main tree of our ConfFuzz proof-of-concept. ConfFuzz is an in-memory fuzzer aimed at detecting interface vulnerabilities in compartmentalized contexts. ConfFuzz is a cooperation between the University of Manchester, University Politehnica of Bucharest, Rice University, and Unikraft.io. It has been accepted to appear in NDSS'23. For more information see the paper Lefeuvre, Hugo, Vlad-Andrei Badoiu, Yi Chien, Felipe Huici, Nathan Dautenhahn, and Pierre Olivier. &quot;Assessing the Impact of Interface Vulnerabilities in Compartmentalized Software.&quot; In Proceedings of 30th Network and Distributed System Security (NDSS'23). Internet Society, 2022.", "entities": [{"id": 1345, "label": "Software", "start_offset": 46, "end_offset": 54}, {"id": 1346, "label": "Software", "start_offset": 73, "end_offset": 81}, {"id": 1347, "label": "Software", "start_offset": 181, "end_offset": 189}]}
{"id": 4019, "text": "FuSeBMC is a test generator for finding security vulnerabilities in C programs. FuSeBMC incrementally injects labels to guide Bounded Model Checking (BMC) and Evolutionary Fuzzing engines to produce test cases for code coverage and bug finding. Additionally, FuSeBMC uses both engines to produce smart seeds. First, the engines run with a short time limit on a lightly instrumented version of the program to generate the seeds. The BMC engine is particularly useful in producing seeds that can pass through complex mathematical guards. Then, FuSeBMC runs its engines with extended time limits using the smart seeds created in the previous round. FuSeBMC manages this process in two main ways using its Tracer subsystem. Firstly, it uses shared memory to record the labels covered by each test case. Secondly, it evaluates test cases, and those of high impact are turned into seeds for subsequent test fuzzing. We evaluated FuSeBMC by participating in Test-Comp 2022 to test the tool's ability in two categories of the competition: code coverage and bug detection. The Test-Comp 2022 results show that we significantly increased our code coverage score from last year, outperforming all tools in all categories. During years (2021 &amp; 2022), FuSeBMC achieved six awards (4 Gold Medals, 1 Silver Medal, 1 Bronze Medal).", "entities": [{"id": 1546, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 1547, "label": "Software", "start_offset": 80, "end_offset": 87}, {"id": 1548, "label": "Software", "start_offset": 259, "end_offset": 266}, {"id": 1549, "label": "Software", "start_offset": 542, "end_offset": 549}, {"id": 1550, "label": "Software", "start_offset": 646, "end_offset": 653}, {"id": 1551, "label": "Software", "start_offset": 923, "end_offset": 930}, {"id": 1552, "label": "Software", "start_offset": 1243, "end_offset": 1250}]}
{"id": 4020, "text": "At design time, modern operating systems are locked in a specific safety and isolation strategy that mixes one or more hardware/software protection mechanisms (e.g. user/kernel separation); revisiting these choices after deployment requires a major refactoring effort. This rigid approach shows its limits given the wide variety of modern applications' safety/performance requirements, when new hardware isolation mechanisms are rolled out, or when existing ones break.\n\nWe present FlexOS, a novel OS allowing users to easily specialize the safety and isolation strategy of an OS at compilation/deployment time instead of design time. This modular LibOS is composed of fine-grained components that can be isolated via a range of hardware protection mechanisms with various data sharing strategies and additional software hardening. The OS ships with an exploration technique helping the user navigate the vast safety/performance design space it unlocks. We implement a prototype of the system and demonstrate, for several applications (Redis/Nginx/SQLite), FlexOS' vast configuration space as well as the efficiency of the exploration technique: we evaluate 80 FlexOS configurations for Redis and show how that space can be probabilistically subset to the 5 safest ones under a given performance budget. We also show that, under equivalent configurations, FlexOS performs similarly or better than several baselines/competitors.", "entities": [{"id": 463, "label": "Software", "start_offset": 482, "end_offset": 488}, {"id": 464, "label": "Software", "start_offset": 1057, "end_offset": 1063}, {"id": 465, "label": "Software", "start_offset": 1161, "end_offset": 1167}, {"id": 466, "label": "Software", "start_offset": 1356, "end_offset": 1362}]}
{"id": 4021, "text": "Functionality to compute the projection median via several algorithms. This package also provides functions to plot different multivariate medians and multivariate quantiles in two-dimensional and three-dimensional data respectively. See Chen, F. and Nason, G.P. (2020) &quot;A new method for computing the projection median, its influence curve and techniques for the production of projected quantile plots.&quot; PLOS One (accepted for publication).", "entities": []}
{"id": 4022, "text": "Freeware R software to carry out tests of global white noise", "entities": []}
{"id": 4023, "text": "Software to model and fit generalized network autoregressive processes. Joint with Kathryn Leeming, Matt Nunes and Marina Knight", "entities": []}
{"id": 4024, "text": "Non-Parametric Bayesian Spectrum Estimation for Multirate Data", "entities": [{"id": 1348, "label": "Software", "start_offset": 0, "end_offset": 43}]}
{"id": 4025, "text": "Software to compute three-dimensional projection pursuit solutions of a multivariate data set.\n\nThis was joint work with Robin Sibson.", "entities": []}
{"id": 4026, "text": "New test of second-order stationarity and confidence intervals for localized autocovariance", "entities": []}
{"id": 4027, "text": "Test Stationarity using Bootstrap Wavelet Packet Tests", "entities": []}
{"id": 4028, "text": "Wavelet Lifting Estimators of the Hurst Exponent for Regularly and Irregularly Sampled Time Series", "entities": [{"id": 893, "label": "Software", "start_offset": 0, "end_offset": 27}]}
{"id": 4029, "text": "The software facilitates the secure linkage and sharing of information derived from social media data in UK birth cohorts.", "entities": []}
{"id": 4030, "text": "Tool for simulating post-disaster-modelling-of-school-infrastructure", "entities": []}
{"id": 4031, "text": "Fully automated software to acquire measurement and diagnostic data from in-situ atmospheric O2 and CO2 measurement systems. Includes fully automated control of measurement system, including control of several hierarchical levels of instrument calibration.", "entities": []}
{"id": 4032, "text": "One-stop-shop for averaging atmospheric time series data, with large array of options. Output file format options include BADC, WMO, EU-ICOS. Averaging options include hourly, daily, weekly, monthly. Various additional columns of statistical information also as options.", "entities": []}
{"id": 4033, "text": "Automated processing and archiving of measurement results from international intercomparison programmes, and automated creation and web display of over 400 graphs of results.", "entities": []}
{"id": 4034, "text": "This tool allows clinical users to design a decision tree for a range of purposes including process management, subtyping or diagnosis. Models can be tested online and used to generate a simple user interface. Models can be cited and shared openly with the community.", "entities": []}
{"id": 4035, "text": "DGLinker is a webserver for the prediction of novel candidate genes for human diseases given a set of known disease genes. DGLinker has a user-friendly interface that allows non-expert users to exploit biomedical information from a wide range of biological and phenotypic databases, and/or to upload their own data, to generate a knowledge-graph and use machine learning to predict new disease-associated genes. The webserver includes tools to explore and interpret the results and generates publication-ready figures. The webserver is free and open to all users without the need for registration.", "entities": [{"id": 1098, "label": "Software", "start_offset": 0, "end_offset": 8}, {"id": 1099, "label": "Software", "start_offset": 123, "end_offset": 131}]}
{"id": 4036, "text": "Extraction of Oral Anticoagulant prescribing from discharge summaries, including negation and various modifiers (e.g. stopped, discontinued)", "entities": []}
{"id": 4037, "text": "This library implements the knowledge graph machine learning method developed in https://www.nature.com/articles/s41598-017-16674-x with faster optimisation and updated to python3.", "entities": []}
{"id": 4038, "text": "The tool provides the results of our survey of UK experts to create a consensus guideline for AML treatment. It also uses other software developed in this award (esyn decision tree tool) to estimate treatment eligibility for research use.", "entities": []}
{"id": 4039, "text": "A package created as part of the DiviVet project for generating network representations for animal movement (and associated) data", "entities": []}
{"id": 4040, "text": "A graphical user interface for the 'movenet' package, facilitating &nbsp;the use of livestock movement data in veterinary public health. The app contains workflows for data processing, pseudonymisation and creation of synthetic data, and network analysis of livestock movement and holding datasets.", "entities": [{"id": 894, "label": "Software", "start_offset": 2, "end_offset": 26}]}
{"id": 4041, "text": "A set of workflows facilitating the dataflow from livestock movement data to social network analysis and disease transmission models. 'movenet' also addresses common data issues such as the diversity of data formats and privacy preservation.", "entities": [{"id": 1100, "label": "Software", "start_offset": 135, "end_offset": 142}]}
{"id": 4042, "text": "Online website", "entities": []}
{"id": 4043, "text": "A digital platform aggregating the newly disclosed collections ( Jaap Kunst Collection, the BBC Soundscapes of Empire and the CNRS ) with access to other digital sound archives in Southeast Asia and Europe.", "entities": []}
{"id": 4044, "text": "Aggregating platform for the CNRS and the DECOSEAS site. The International sound archives of CNRS / Mus&eacute;e de l'Homme encompass field recordings of music and oral traditions from around the world, from 1900 to the present. The establishment of these archives represents a long process begun by the musicologist Andr&eacute; Schaeffner in the 1930s to collect, organize and archive audio recordings such as the Paris Universal Exhibition cylinders (1900). These audio materials were preserved in the newly established Phonoth&egrave;que in the D&eacute;partement d'Ethnologie Musicale of the Mus&eacute;e d'ethnographie du Trocadero in Paris. In 1937, the Mus&eacute;e d'ethnographie became the new Mus&eacute;e de l'Homme. In 2009, the Mus&eacute;e de l'Homme was closed for renovations, and the audiotapes transferred to the French National Library, where the digitizing process has come to an end and put online through the Research Centre for Ethnomusicology (CREM). Today, around 30 000 audio and video files are available online for a wide audience, including ca. 3 500 recordings from Southeast Asia and Austronesian World (Vietnam, Cambodia, Laos, Burma, Philippines, Malaysia, Taiwan, Indonesia, East Timor, Papua), with main collectors being Jose Maceda, Nicole Revel, Georges Condominas, Louis Berthe, Jacques Dournes, Dana Rappoport, etc.", "entities": [{"id": 476, "label": "Software", "start_offset": 0, "end_offset": 55}]}
{"id": 4045, "text": "The digital platform and mobile application is a retooling of a collection of almost extinct ritual music of the Toraja from Sulawesi in Indonesia recorded by Dana Rappoport between 1991 and 2005, shaped into an interactive multimedia website formatted from a now obsolete DVD.\n\nThe platform will showcase a unique online study of the ritual music of the Toraja people in Sulawesi - musical heritage that belongs to Austronesian cultural stratum established in Indonesia around 3000 BCE, now on the brink of extinction. The anthology, published in 2009, gives access to pre-colonial and pre-Christian Torajan music, practiced by only 5% of Toraja people resisting Christian and colonial cultural impositions. It presents an entire ritual cycle: 40 hours of songs and poems, translated into three languages (Indonesian, English, French) and accompanied by extensive documentary material (2000 photographs and 120 minutes of video).", "entities": [{"id": 671, "label": "Software", "start_offset": 4, "end_offset": 42}]}
{"id": 4046, "text": "The consortium partners worked on adding functionalities to the website to create greater engagement with the general public through interlinked blog posts and news stories. After a series of user testing with the partners in South East Asia, we decided to create a way for partners in South East Asia to post news and information on the site.", "entities": []}
{"id": 4047, "text": "A highly customized CMS platform based on Omeka. The customization was a result of debates within the research consortium around metadata models for Sound categories and genres. It has also allowed for the Toraja website (migration of a Flash application to an web open source technology)\n•Migration from flash interface to web site\n•Preparation of 10,000 data files for migration to the EHESS research data repository, Didomena\nhttps://didomena.ehess.fr/?locale=en\n\nWe have also worked with a choice of a logicist reasoning visualization\n \n•Preparation of audio and visual data\n•Creation of specifications for the production of a website\n•Choice of partners (It, Designer, Ux, hosting university)", "entities": [{"id": 1101, "label": "Software", "start_offset": 2, "end_offset": 32}]}
{"id": 4048, "text": "Soundscapes of Empire ( BBC Broadcasts to and About South East Asia) gathered and instigated by Cristina Juan hold a diversity of recorded broadcasts. It includes recordings among others, of broadcasts by the BBC Empire Service to the Far East. Started in 1932, the BBC Empire Service occasionally recorded their broadcasts, often to enable recordings to be broadcast at different times. The audience to which the Empire Service broadcast was extremely diverse and transnational. Radio could be received beyond imperial borders. At the same time, broadcasts were tailored to the social and racial stratifications that featured colonial society, observing strict compartmentalization between colonial settlers, &quot;natives&quot;, and local upper classes, and between languages. Recordings were expensive and only done for practical reasons. The idea that some recordings were important to keep for longer term re-use or historical reasons developed gradually and inconsistently across the BBC. Hence the recorded material is selective, but enables us to listen to voices that might otherwise remain unheard: commercially viable popular music of the time, political rallies, debates, voice inflections and sonic postures that positioned colonial subjects socially and ideologically - ranging from Cantonese opera concerts in Singapore to Indonesian president Sukarno's Independence Speech, and reports on European refugees during WWII in SE Asia f.e. The broadcasts make us hear the formative political events as much as the every-day life of people within and outside the British imperial sphere during late colonialism and early postcolonialism (1930s-1950s). There have been a number of preservation and digitization initiatives as the BBC transitions to an &quot;open archive&quot;.", "entities": []}
{"id": 4049, "text": "The web application is a knwledgebase of The Jaap Kunst collection, located in Amsterdam under the curatorship of Barbara Titus. The Jaap Kunst is an ethnographic sound collection. Jaap Kunst (1891-1960) recorded a wealth of music and sound from the Dutch East Indies between 1919 and 1934 of more than 400 of wax cylinders. His collecting methods adhered to colonial stratifications of society and the scientific (archeological and botanical) classification norms of the time. His collection contains anonymized sound specimens representing distinct and timeless cultures. Collecting and classifying the peoples that inhabited the empire was intended to bolster the notion of it as empire. These methods were seminal to the development of a new scholarly practice (ethnomusicology) that is currently established as an academic discipline throughout the world, and of which Kunst is widely considered to be a &quot;founding father&quot;.\n\nHis sound archive has been digitized in the Phonogrammarchiv in Berlin, but was not available online. Since Kunst recorded music from the entire archipelago under Dutch rule, the collection has raised the interest of national Indonesian institutions (Museum Nasional [AP]) and government (Ministry of Culture and Education) since it is considered representative for the current Indonesian nation state whose borders coincide with those of the Dutch East Indies.\n\nThe digital platform seeks to make the Jaap Kunst sound collection discoverable but also enriched through the creation of correlating links to Jaap Kunst letters and photos related to the individual sound recordings.", "entities": []}
{"id": 4050, "text": "The web application tool is an informational hub that gives details on the initiatives and research outputs of the project.", "entities": []}
{"id": 4051, "text": "Vampire is the first order theorem prover. It has been World Champion in first-order theorem proving in various divisions 34 times. In 2015 it has won 5 out of 8 divisions, in 4 of them solving more problems than all other systems together. In the main division Vampire has not been beaten since 2002.", "entities": [{"id": 672, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4052, "text": "The Advanced Ensemble electron density [Ne] Assimilation System (AENeAS) is a state-of-the-art physics-based data assimilation model of the upper atmosphere.", "entities": [{"id": 896, "label": "Software", "start_offset": 4, "end_offset": 63}, {"id": 897, "label": "Software", "start_offset": 65, "end_offset": 71}]}
{"id": 4053, "text": "Relative Abundance of Transcripts (rats)\nDescription\nWho it is for\n\nAnyone working in transcriptomics, analysing gene expression and transcript abundances.\nWhat it does\n\n It provides a method to detect changes in the abundance ratios of transcript isoforms of a gene. This is called Differential Transcript Usage (DTU).\n\n RATs is workflow-agnostic. Quantification quality details are left to the quantification tools; RATs uses only the transcript abundances, which you can obtain using any tool you like. This makes it suitable for use with alignment-free quantification tools like Kallisto or Salmon.\n\n RATs is able to take advantage of the bootstrapped quantifications provided by the alignment-free tools. These bootstrapped data are used by RATs to assess how much the technical variability of the heuristic quantifications affects differential transcript usage and thus provide a measure of confidence in the DTU calls.\n\nWhat it needs\n\n This is an R source package, and will run on any platform with a reasonably up-to-date R environment. A few third-party R packages are also required (see below).\n\n As input, RATs requires transcript abundance estimates with or without bootstrapping. The format either way is tables with the samples as columns and the transcripts as rows. An extra column holds the transcript IDs. Some functionality to create these from Salmon or Kallisto quantification files is provided by RATs.\n\n RATs also requires a look-up table matching the transcript identifiers to the respective gene identifiers. This can be obtained through various means, one of them being extracting this info from a GTF file using functionality provided by RATs.", "entities": [{"id": 1102, "label": "Software", "start_offset": 0, "end_offset": 33}, {"id": 1104, "label": "Software", "start_offset": 35, "end_offset": 39}, {"id": 1105, "label": "Software", "start_offset": 322, "end_offset": 326}, {"id": 1106, "label": "Software", "start_offset": 418, "end_offset": 422}, {"id": 1107, "label": "Software", "start_offset": 604, "end_offset": 609}, {"id": 1108, "label": "Software", "start_offset": 746, "end_offset": 750}, {"id": 1109, "label": "Software", "start_offset": 1117, "end_offset": 1121}, {"id": 1110, "label": "Software", "start_offset": 1419, "end_offset": 1423}, {"id": 1111, "label": "Software", "start_offset": 1427, "end_offset": 1431}, {"id": 1112, "label": "Software", "start_offset": 1665, "end_offset": 1669}]}
{"id": 4054, "text": "Who it is for\n\nAnyone working in transcriptomics, analysing gene expression and transcript abundances.\nWhat it does\n\n It provides a method to detect changes in the abundance ratios of transcript isoforms of a gene. This is called Differential Transcript Usage (DTU).\n\n RATs is workflow-agnostic. Quantification quality details are left to the quantification tools; RATs uses only the transcript abundances. This makes it suitable for use with alignment-free quantification tools like Kallisto or Salmon. It is also compatible with DTE output from Sleuth.\n\n RATs is able to take advantage of the bootstrapped quantifications provided by the alignment-free tools. These bootstrapped data are used by `RATs to assess how much the technical variability of the heuristic quantifications affects differential transcript usage and thus provide a measure of confidence in the DTU calls.\n\nWhat it needs\n\n This is an R source package, and will run on any platform with a reasonably up-to-date R environment.\n\n As input, RATs requires transcript abundance estimates with or without bootstrapping. For convenience, these can also be extracted directly from the output of Sleuth.\n\n RATs also requires a look-up table matching transcript identifiers to respective gene identifiers. This can be obtained through various means, one of them being extracting this info from a GTF file.\n\n RATs makes use of the data.table and matrixStats packages, as well as ggplot2 and shiny for visualisations. All these are available from CRAN.", "entities": [{"id": 1349, "label": "Software", "start_offset": 269, "end_offset": 273}, {"id": 1350, "label": "Software", "start_offset": 365, "end_offset": 369}, {"id": 1351, "label": "Software", "start_offset": 557, "end_offset": 561}, {"id": 1352, "label": "Software", "start_offset": 699, "end_offset": 703}, {"id": 1353, "label": "Software", "start_offset": 1010, "end_offset": 1014}, {"id": 1354, "label": "Software", "start_offset": 1169, "end_offset": 1173}, {"id": 1355, "label": "Software", "start_offset": 1370, "end_offset": 1374}]}
{"id": 4055, "text": "RoSA: a tool for the Removal of Spurious Antisense\n\nIn stranded RNA-Seq experiments we have the opportunity to detect and measure antisense transcription, important since antisense transcripts impact gene transcription in several different ways. Stranded RNA-Seq determines the strand from which an RNA fragment originates, and so can be used to identify where antisense transcription may be implicated in gene regulation.\n\nHowever, spurious antisense reads are often present in experiments, and can manifest at levels greater than 1% of sense transcript levels. This is enough to disrupt analyses by causing false antisense counts to dominate the set of genes with high antisense transcription levels.\n\nThe RoSA (Removal of Spurious Antisense) tool detects the presence of high levels of spurious antisense transcripts, by:\n\n analysing ERCC spike-in data to find the ratio of antisense:sense transcripts in the spike-ins; or\n using antisense and sense counts around splice sites to provide a set of gene-specific estimates; or\n both.\n\nOnce RoSA has an estimate of the spurious antisense, expressed as a ratio of antisense:sense counts, RoSA will calculate a correction to the antisense counts based on the ratio. Where a gene-specific estimate is available for a gene, it will be used in preference to the global estimate obtained from either spike-ins or spliced reads.", "entities": [{"id": 1553, "label": "Software", "start_offset": 0, "end_offset": 4}, {"id": 1554, "label": "Software", "start_offset": 708, "end_offset": 712}, {"id": 1555, "label": "Software", "start_offset": 714, "end_offset": 743}, {"id": 1556, "label": "Software", "start_offset": 1041, "end_offset": 1045}, {"id": 1557, "label": "Software", "start_offset": 1137, "end_offset": 1141}]}
{"id": 4056, "text": "Description\nWho it is for\n\nAnyone working in transcriptomics, analysing gene expression and transcript abundances.\nWhat it does\n\n It provides a method to detect changes in the abundance ratios of transcript isoforms of a gene. This is called Differential Transcript Usage (DTU).\n\n RATs is workflow-agnostic. Quantification quality details are left to the quantification tools; RATs uses only the transcript abundances, which you can obtain using any tool you like. This makes it suitable for use with alignment-free quantification tools like Kallisto or Salmon.\n\n RATs is able to take advantage of the bootstrapped quantifications provided by the alignment-free tools. These bootstrapped data are used by RATs to assess how much the technical variability of the heuristic quantifications affects differential transcript usage and thus provide a measure of confidence in the DTU calls.\n\nWhat it needs\n\n This is an R source package, and will run on any platform with a reasonably up-to-date R environment. A few third-party R packages are also required (see below).\n\n As input, RATs requires transcript abundance estimates with or without bootstrapping. The format either way is tables with the samples as columns and the transcripts as rows. An extra column holds the transcript IDs. Some functionality to create these from Salmon or Kallisto quantification files is provided by RATs.\n\n RATs also requires a look-up table matching the transcript identifiers to the respective gene identifiers. This can be obtained through various means, one of them being extracting this info from a GTF file using functionality provided by RATs.", "entities": [{"id": 467, "label": "Software", "start_offset": 242, "end_offset": 272}, {"id": 468, "label": "Software", "start_offset": 273, "end_offset": 276}, {"id": 469, "label": "Software", "start_offset": 280, "end_offset": 285}, {"id": 470, "label": "Software", "start_offset": 377, "end_offset": 381}, {"id": 471, "label": "Software", "start_offset": 564, "end_offset": 568}, {"id": 472, "label": "Software", "start_offset": 705, "end_offset": 709}, {"id": 473, "label": "Software", "start_offset": 1076, "end_offset": 1080}, {"id": 474, "label": "Software", "start_offset": 1377, "end_offset": 1382}, {"id": 475, "label": "Software", "start_offset": 1386, "end_offset": 1391}]}
{"id": 4057, "text": "profDGE48 is the code that has been used to understand the relationship between replication and power in RNA-seq analysis. The code also allows the comparison of different methods of calling differential gene expression (DGE) by RNA-seq. This code was central to the high-impact work on RNA-seq published in the journal RNA (Schurch et al).\n\nThis version includes bug fixes and updates to the work from 2015.", "entities": [{"id": 673, "label": "Software", "start_offset": 0, "end_offset": 9}]}
{"id": 4058, "text": "In stranded RNA-Seq experiments we have the opportunity to detect and measure antisense transcription, important since antisense transcripts impact gene transcription in several different ways. Stranded RNA-Seq determines the strand from which an RNA fragment originates, and so can be used to identify where antisense transcription may be implicated in gene regulation.\n\nHowever, spurious antisense reads are often present in experiments, and can manifest at levels greater than 1% of sense transcript levels. This is enough to disrupt analyses by causing false antisense counts to dominate the set of genes with high antisense transcription levels.\n\nThe RoSA (Removal of Spurious Antisense) tool detects the presence of high levels of spurious antisense transcripts, by:\n\n analysing ERCC spike-in data to find the ratio of antisense:sense transcripts in the spike-ins; or\n using antisense and sense counts around splice sites to provide a set of gene-specific estimates; or\n both.\n\nOnce RoSA has an estimate of the spurious antisense, expressed as a ratio of antisense:sense counts, RoSA will calculate a correction to the antisense counts based on the ratio. Where a gene-specific estimate is available for a gene, it will be used in preference to the global estimate obtained from either spike-ins or spliced reads.", "entities": [{"id": 898, "label": "Software", "start_offset": 655, "end_offset": 660}, {"id": 899, "label": "Software", "start_offset": 662, "end_offset": 691}, {"id": 900, "label": "Software", "start_offset": 989, "end_offset": 993}, {"id": 901, "label": "Software", "start_offset": 1085, "end_offset": 1089}]}
{"id": 4059, "text": "The SCEPTICS tool allows Industrial Control System Asset Owners to be able to assess the security characteristics of their system architectures and identify potential sources for exploitation. The tool also allows the asset owner to test strategies for improving the holistic security of their architectures.", "entities": [{"id": 1113, "label": "Software", "start_offset": 4, "end_offset": 12}]}
{"id": 4060, "text": "The attached data files underpin the publication &quot;Raman scattering with strongly coupled vibron-polaritons&quot;. The following file types and formats are included: - cavity-raman-figures: .nb (this file contains all the figures and graphs oblained in this work; can be opened with Mathematica 10)", "entities": []}
{"id": 4061, "text": "a counting device that allows bar coded next generation deep sequencing data to use probabilistic approach to select and identify consensus motifs in sequence lists", "entities": []}
{"id": 4062, "text": "In this project, we are developing a domain-specific language (DSL) approach for lattice Boltzmann modelling. The purpose is to hide the implementation details from either an end-user or an application developer so that the users can focus on the algorithm and application. \n\nThe project is split into two phases. In the first phase, we have developed function sequence that will enable the user to combine the provided lattice Boltzmann models (e.g., provided equilibrium functions, boundary conditions and forces terms) to simulate a scientific problem. In the second phase we have proposed and implemented a few key templated objects that can help researchers to write the so-called user-defined function (UDF) and develop their applications easily as well as an experimental python translator for the same purpose. \n\nThe proposed abstract is released at https://gitlab.com/jpmeng/hilemms, whilst two backend codes (i.e., OPS based and AMReX based) are released at https://github.com/jpmeng/MPLB by DL and https://github.com/otbrown/LAMBReX by EPCC.", "entities": [{"id": 477, "label": "Software", "start_offset": 37, "end_offset": 76}, {"id": 478, "label": "Software_Url", "start_offset": 857, "end_offset": 891}, {"id": 479, "label": "Software_Url", "start_offset": 968, "end_offset": 998}, {"id": 480, "label": "Software_Url", "start_offset": 1009, "end_offset": 1043}]}
{"id": 4063, "text": "This code implements Support Tensor Regression (STR) as presented in Weiwei Guo, Irene Kotsia and Ioannis Patras, &quot;Tensor Learning for Regression&quot;, in IEEE Transactions on Image Processing, 2011.", "entities": []}
{"id": 4064, "text": "This code implements the paper Max-Margin Semi-NMF (MNMF) as presented in Vijay Kumar, Irene Kotsia and Ioannis Patras, &quot;Max-Margin Semi-NMF&quot;, in BMVC 2011.", "entities": []}
{"id": 4065, "text": "This code implements Support Tucker Machines (STuMs) and Sw-STuMs, as presented in Irene Kotsia and Ioannis Patras, &quot;Support Tucker Machines&quot;, in CVPR 2011, 2011.", "entities": [{"id": 1114, "label": "Software", "start_offset": 21, "end_offset": 45}, {"id": 1115, "label": "Software", "start_offset": 46, "end_offset": 51}, {"id": 1116, "label": "Software", "start_offset": 57, "end_offset": 65}]}
{"id": 4066, "text": "FINESSE is a fast and easy to use interferometer simulation to design and debug laser interferometers. We wanted to be able to simulate many different user-defined optical setups and we would like to playfully teach and learn more about laser optics. FINESSE has a long pedigree and has benefited from years of real-life employment by the optics groups of gravitational wave detectors.", "entities": [{"id": 1356, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 1357, "label": "Software", "start_offset": 251, "end_offset": 258}]}
{"id": 4067, "text": "Machine learning software that predicts weekly incidence of respiratory disease at and localised death forecasts at local authority resolutions across the UK, using demographic, geographic, ONS and importantly over-the-counter medication sales data. Transferred from the CIVIC project as part of the NHS-X internship program.", "entities": []}
{"id": 4068, "text": "The software provides a fusion algorithm that combines a sensor measurement of the robot's pose with the mathematical model of a Flexible robot to estimate its overall shape. \n\nPython implementation of the shape estimation methodology presented in the following paper: &quot;Shape Estimation of Concentric Tube Robots Using Single Point Position Measurement&quot;. E. Mackute, B. Thamo, K. Dhaliwal, M.Khadem. 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS).", "entities": []}
{"id": 4069, "text": "Repo for modelling and simulation of Concentric Tube Robots in ROS. It implements the methodology presented in the following paper: &quot;Data-driven Steering of Concentric Tube Robots in Unknown Environments via Dynamic Mode Decomposition &quot;. Balint Thamo, David Hanley Kevin Dhaliwal, Mohsen Khadem. IEEE Robotics and Automation Letters, 2022.\n\nThis repo uses C++ in ROS Melodic environment to simulate a CTR and includes a data-driven steering algorithm via the Dynamic Mode Decomposition method. You need to copy the folders into the src folder in your workspace. Then you can run it by the following command: roslaunch ctr_main ctr_main.launch", "entities": []}
{"id": 4070, "text": "The Cool Farm Tool is an industry-led environmental decision-support tool used by members of the Cool Farm Alliance (www.coolfarmtool.org). The current focus is to develop a suite of tools according to the elements of farm-scale sustainability performance assessment identified by the Sustainable Agriculture Initiative Platform (http://www.saiplatform.org/). With additional support from a BESS Programme Knowledge Exchange grant (NE/M000206/1), we have developed a biodiversity module for the Cool Farm Tool. It uses a scoring system for farms to rapidly assess their overall management of biodiversity, based on rigorous, unbiased assessment of evidence for the effectiveness of specific actions (Crowther et al. (in prep for Environmental Modelling and Software). \nThe tool has been integrated into the online Cool Farm Tool by the software company Anthesis Group, funded directly by the Cool Farm Alliance.\nAs part of the SUFICA project (BB/R016429/1) a new module in the Biodiversity metric was created, for farms in the Mediterranean and Semi-Arid environments. This was designed and tested in partnership with farmers from Spain and Chile.", "entities": [{"id": 902, "label": "Software", "start_offset": 3, "end_offset": 18}, {"id": 903, "label": "Software", "start_offset": 813, "end_offset": 828}]}
{"id": 4071, "text": "Software Infrastructure that is capable of monitoring and capturing messages from Twitter.", "entities": []}
{"id": 4072, "text": "Java API Framework designed to be extended for domain-specific quality assessment.", "entities": []}
{"id": 4073, "text": "A mobile app for managing crowdsourced disruption reports", "entities": []}
{"id": 4074, "text": "POWkist is an open-source digital archive, which can not only preserve the archive sustainably but also visualise it in an attractive and efficient way. POWkist will build upon the expertise, methodologies, use cases, and open-source software developed during the CURIOS and CURIOS Mobile project in dot.rural.", "entities": [{"id": 481, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 482, "label": "Software", "start_offset": 153, "end_offset": 160}]}
{"id": 4075, "text": "The FITS Platform is a passenger-centric virtual marketplace that considers the eligibility criteria of transport providers, vehicle availability, and passengers' requirements and preferences in identifying possible transport options.", "entities": [{"id": 675, "label": "Software", "start_offset": 0, "end_offset": 17}]}
{"id": 4076, "text": "Beta app allows consumers to access further digital content describing the process and materials used to produce the product they have purchased", "entities": [{"id": 904, "label": "Software", "start_offset": 0, "end_offset": 8}]}
{"id": 4077, "text": "A loadable kernel module which can be incorporated with Linux OS to implement the newCWV algorithm to enhance bursty application performance", "entities": []}
{"id": 4078, "text": "Android native wrapper of IITB Life web application", "entities": []}
{"id": 4079, "text": "CURIOS Mobile Demo, including a RESTful API wrapper for the Hebridean Connections dataset and a simple Android App GUI", "entities": [{"id": 1558, "label": "Software", "start_offset": 0, "end_offset": 18}]}
{"id": 4080, "text": "RDForm templates used for CrowdData project", "entities": [{"id": 483, "label": "Software", "start_offset": 0, "end_offset": 16}]}
{"id": 4081, "text": "Bespoke CMS to enable WoodWorks participants and workshop organisers to load content into the app via a web-based interface", "entities": [{"id": 677, "label": "Software", "start_offset": 0, "end_offset": 11}]}
{"id": 4082, "text": "Web-based dashboard to generate and update traceability information about food products", "entities": []}
{"id": 4083, "text": "User interface developed for administering the Twitter Monitoring Infrastucture.", "entities": []}
{"id": 4084, "text": "A bundle of software modules built by PAWS reserchers to imlement LBE service on OpenWRT router firmware", "entities": []}
{"id": 4085, "text": "MinTad is a prototype system for intention mining from social media, which can be applied to business intelligence applications.", "entities": [{"id": 1559, "label": "Software", "start_offset": 0, "end_offset": 6}]}
{"id": 4086, "text": "Structured textual data in XML, RDF, and OWL", "entities": []}
{"id": 4087, "text": "iOS app that can be used by consumers to query information about a food product in our system usign a QR code", "entities": []}
{"id": 4088, "text": "A PhP and PEARL based log analyser system.", "entities": []}
{"id": 4089, "text": "This is a java jar file that takes an English sentence as input and outputs its intention type of 'purchase', 'inform' or 'other'. For purchase intention, the agent and object are also analysed. License: CC BY 4.0", "entities": []}
{"id": 4090, "text": "Classification of different types of travel disruptions in OWL format", "entities": []}
{"id": 4091, "text": "The Transport Disruption ontology is a formal framework for modelling events related to travel and transport that may disrupt the travel plans of an agent. Such events typically disrupt the supply or cost of transport, can affect single or multiple transport links in an area, and cause greater disruption to an agent's travel plans than they would typically experience due to everyday travel variability.", "entities": [{"id": 1560, "label": "Software", "start_offset": 4, "end_offset": 33}]}
{"id": 4092, "text": "Maven archetype for services developed as part of the Informed Rural Passenger project's intelligent information infrastructure.", "entities": [{"id": 484, "label": "Software", "start_offset": 0, "end_offset": 16}]}
{"id": 4093, "text": "iOS app designed to capture location and carrier information during the delivery of a food product.", "entities": []}
{"id": 4094, "text": "Ontologies defined for CrowdData project", "entities": []}
{"id": 4095, "text": "Libraries for generating bus service and timetable related RDF datasets developed for the Informed Rural Passenger project.", "entities": []}
{"id": 4096, "text": "Classification of different types of travel disruptions in OWL format", "entities": []}
{"id": 4097, "text": "Ontologies developed during the Social Journeys project", "entities": []}
{"id": 4098, "text": "RESTful API providing methods to store and retrevie information bout Object Memoried. This is designed to provide back-end support for all of the SMiLE food traceability applications", "entities": [{"id": 486, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 4099, "text": "Multipath Dissemination Protocol Daemon. - Linux implementation to share multipath connectivity information and configure devices.", "entities": [{"id": 678, "label": "Software", "start_offset": 0, "end_offset": 39}]}
{"id": 4100, "text": "Service developed as part of the Informed Rural Passenger project for managing data described using the Semantic Sensor Network ontology.", "entities": []}
{"id": 4101, "text": "The server implemention supporting the IITB-Life webapp", "entities": []}
{"id": 4102, "text": "AMIL Bus Fare Model: A distance based bus fare estimation model which is sensitive to location (i.e. Local Authority area) and bus operator.", "entities": [{"id": 1358, "label": "Software", "start_offset": 0, "end_offset": 19}]}
{"id": 4103, "text": "Digital portal for a community - focussing on wellbeing and community cohesion", "entities": []}
{"id": 4104, "text": "Classification of different types of travel disruptions in OWL format", "entities": []}
{"id": 4105, "text": "The core components of the ecosystem developed for the Informed Rural Passenger project. This library provides compoents and APIs for supporting the development and functioning of services within the ecosystem.", "entities": []}
{"id": 4106, "text": "The transport related services, associated SPARQL queries, and domain model classes developed for the Informed Rural Passenger project.", "entities": []}
{"id": 4107, "text": "A computational framework that can detect anomalous patterns from river time series", "entities": []}
{"id": 4108, "text": "Web service that uses the OntoText KIM platform to identify transport related entities mentioned messages from social media and annotate those messages.", "entities": []}
{"id": 4109, "text": "Parsers for extracting data from various open data sources to make them available as linked data for the Social Journeys system", "entities": []}
{"id": 4110, "text": "system including software design of separate camera nodes for autonomous monitoring", "entities": []}
{"id": 4111, "text": "Website for community - where stories and other content will be added and annotated to a map of the region", "entities": []}
{"id": 4112, "text": "Java API for using the SPIN RDF reasoner.", "entities": []}
{"id": 4113, "text": "Website for the GetThere smartphone app developed during the Informed Rural Passenger project. The website provides details about the app, help, FAQ, the app Terms and Conditions, and press release materials. The website is available at http://homepages.abdn.ac.uk/getthere/", "entities": [{"id": 1117, "label": "Software", "start_offset": 15, "end_offset": 24}, {"id": 1118, "label": "Software_Url", "start_offset": 237, "end_offset": 274}]}
{"id": 4114, "text": "The IITB-Life webapp", "entities": [{"id": 1360, "label": "Software", "start_offset": 4, "end_offset": 20}]}
{"id": 4115, "text": "Software developed for the social journeys project that both monitiors social media for details of transport disruption and provides users with travel information via social media.", "entities": []}
{"id": 4116, "text": "AMIL Postcode Generator: an element that finds postcodes in a radius (up to 30 miles) around a given site and filters these based on a half mile grid.", "entities": [{"id": 487, "label": "Software", "start_offset": 0, "end_offset": 23}]}
{"id": 4117, "text": "Software is to support a first responder at medical emergencies. It runs on mobile devices and links with some of the latest wireless medical sensors", "entities": []}
{"id": 4118, "text": "Customized release of the rdforms system originall downloaded from bitbucket", "entities": [{"id": 905, "label": "Software", "start_offset": 26, "end_offset": 40}]}
{"id": 4119, "text": "Series of OWL ontologies developed by the Informed Rural Passenger project; available in the following GitHub repository: https://github.com/dcorsar/irp-ontologies", "entities": [{"id": 1119, "label": "Software", "start_offset": 10, "end_offset": 24}, {"id": 1120, "label": "Software_Url", "start_offset": 122, "end_offset": 163}]}
{"id": 4120, "text": "Source Code for RFC 7661 mechanisms has been placed in the public domain as contributions to the Linux 3.8.2 and BSD developer communities, and is available from these communities. A kernel loadable module for Linux is available", "entities": []}
{"id": 4121, "text": "AMIL mapping Software: Software that takes myPTP data and converts it to contour maps showing accesssibility", "entities": [{"id": 1561, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 4122, "text": "Libraries for generating and maintaining RDF provenance graphs described using the W3C Prov-O ontology.", "entities": []}
{"id": 4123, "text": "Software developed to generate natural language messages to be sent via Twitter to users of the social journeys app software.", "entities": []}
{"id": 4124, "text": "Quality assessment framework designed to work with the ecosystem developed by the Informed Rural Passenger project providing quality assessment for the GetThere app.", "entities": [{"id": 906, "label": "Software", "start_offset": 0, "end_offset": 29}]}
{"id": 4125, "text": "The BetterBasket browser extension is an extension to Google Chrome and Mozilla Firefox aimed at improving the healthiness of food purchasing by giving point-of-purchase cues. Once activated it provides users with an augmented user experience when they visit one of six online supermarkets (Tesco, Sainsbury's, Morrisons, Asda, Ocado and Waitrose). Users receive traffic light label information on all of the food and drink products that they view and can see a running total of the nutritional quality of the foods that they have placed in their basket. A beta version of the browser extension will be launched in 2021 to collect user feedback. The software relies on up-to-date information on all food and drink products available in these supermarkets, which is collected using foodDB - a software platform described in the paper Harrington RA, Adhikari V, Rayner M, Scarborough P. Nutrient composition databases in the age of big data: foodDB, a comprehensive, real-time database infrastructure. BMJ Open, 2019 http://dx.doi.org/10.1136/bmjopen-2018-026652", "entities": [{"id": 1121, "label": "Software", "start_offset": 4, "end_offset": 34}]}
{"id": 4126, "text": "The BetterBasket web portal, developed by partners Global Initiative, is a website that users can log into and monitor their online supermarket purchases. The web portal is a behaviour change intervention, aimed at improving the healthiness of food purchasing behaviour. It uses the following mechanisms: self-monitoring; tailored feedback; goal setting; modelling of behaviour. The pilot version was completed in 2020 and an updated version completed in Feb 2021. User feedback is being collected in March 2021.", "entities": [{"id": 1361, "label": "Software", "start_offset": 4, "end_offset": 27}]}
{"id": 4127, "text": "Next generation sequence analysis software", "entities": [{"id": 1562, "label": "Software", "start_offset": 0, "end_offset": 42}]}
{"id": 4128, "text": "Development of a method - implemented in Excel and Matlab - to analyse genetic diversity in next generation sequencing datasets", "entities": []}
{"id": 4129, "text": "The HMB3 CFD solver has been extended and validated for stall flutter flows. This is a new application area for out in-house CFD solver. Apart from the validation and extension of the tool to cover this particular type of fluid-structure interaction, additional documentation has been produced for HMB3 and additional test cases were added to its validation database.", "entities": [{"id": 679, "label": "Software", "start_offset": 3, "end_offset": 20}]}
{"id": 4130, "text": "An augmented reality piece/tour of the New Town, called 'Fruitmarket Gallery: Janet Cardiff and George Bures Miller's Night Walk for Edinburgh', premiered as a sell out at the 2019 Edinburgh International Festival. The Fruitmarket Gallery approached Creative Informatics during lockdown as they were keen to enable a socially distanced COVID-19 secure version of the experience using participants' own devices. There were a number of significant challenges here. For the experience to compare with th", "entities": [{"id": 908, "label": "Software", "start_offset": 57, "end_offset": 76}]}
{"id": 4131, "text": "The Talbot Rice Gallery audience flow app emerged from the challenge of safely managing audiences during social distancing. The challenge was explored as part of UNA.TEN 'Transform Emergency Now!' - a ten-day UNA.EUROPA COVID-19 response hackathon (April/May 2020) resulting in an initial concept and design. In Summer 2020, Design Informatics colleagues and student interns (supported by Creative Informatics) worked together to develop this into a simple effective pilot web app for tracking visitor flow in real time. \n\nThis app has been tested and demonstrated to other galleries by the Talbot Rice Gallery, and, due to interest in this work, Creative Informatics launched the self-service version, 'Flow Ctrl'. This work has also been presented to the Scottish Society for Art History, with their members encouraged to explore and test the app in their own galleries and museums.", "entities": [{"id": 1122, "label": "Software", "start_offset": 4, "end_offset": 41}, {"id": 1123, "label": "Software", "start_offset": 704, "end_offset": 713}]}
{"id": 4132, "text": "Polycanvas is new software developed by Dara Etefaghi and Sigrid Schmeisser (Peak 15 Design) in order to create the Creative Informatics Data Driven Poster. The CI Data Driven Poster uses a mixture of human curated data, design elements and a data feed from a public API (currently GitHub commits) to generate automated digital posters for events with elements on the page placed and animated according to live data streams.", "entities": [{"id": 1362, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 4133, "text": "This software achieves more accurate results from optical music recognition software by combining the outputs from several recognition engines and several sources. The software includes components to pre-process scans of musical scores, to submit those to multiple optical-music-recognition engines, and to combine the resulting MusicXML files to produce a single, more accurate, result.", "entities": []}
{"id": 4134, "text": "Our prototype software for project global view. This is the very earliest example of a working dashboard. We used this software development task as an exercise in investigating what end-users might want.", "entities": []}
{"id": 4135, "text": "AlphaSuite of software for data science, genetics, and breeding available from https://github.com/AlphaGenes\n\nThe major tools include:\n* AlphaSimR for simulation of breeding programmes https://github.com/AlphaGenes/AlphaSimR\n* AlphaBayes for estimation of SNP effects on phenotype https://github.com/AlphaGenes/AlphaBayes\n* AlphaAssign for finding progeny-parent (pedigree) relationships https://github.com/AlphaGenes/AlphaAssign\n* AlphaPhase for phasing and imputation of SNP array genotype data https://github.com/AlphaGenes/AlphaPhase\n* AlphaImpute for phasing and imputation of SNP array genotype data https://github.com/AlphaGenes/AlphaImpute\n* AlphaImpute2 for phasing and imputation of SNP array genotype data (version 2) https://github.com/AlphaGenes/AlphaImpute2\n* AlphaPeel for genotype calling, phasing, and imputation in pedigreed populations https://github.com/AlphaGenes/AlphaPeel\n* AlphaFamImpute for genotype calling, phasing, and imputation in families https://github.com/AlphaGenes/AlphaFamImpute\n* AlphaPlantImpute for phasing and imputation in plant populations (version 2) https://github.com/AlphaGenes/AlphaPlantImpute\n* AlphaPlantImpute2 for phasing and imputation in plant populations (version 2) https://github.com/AlphaGenes/AlphaPlantImpute2\n* AlphaMate for balancing selection and management of genetic diversity in breeding programmes https://github.com/AlphaGenes/AlphaMate\n* AlphaPart for analysing trend in genetic means and variances https://github.com/AlphaGenes/AlphaPart", "entities": [{"id": 680, "label": "Software", "start_offset": 0, "end_offset": 10}, {"id": 681, "label": "Software", "start_offset": 137, "end_offset": 146}, {"id": 682, "label": "Software", "start_offset": 227, "end_offset": 237}, {"id": 683, "label": "Software", "start_offset": 324, "end_offset": 335}, {"id": 684, "label": "Software", "start_offset": 432, "end_offset": 442}, {"id": 686, "label": "Software", "start_offset": 540, "end_offset": 551}, {"id": 687, "label": "Software", "start_offset": 650, "end_offset": 662}, {"id": 688, "label": "Software", "start_offset": 773, "end_offset": 783}, {"id": 689, "label": "Software", "start_offset": 896, "end_offset": 911}, {"id": 690, "label": "Software", "start_offset": 1017, "end_offset": 1033}, {"id": 691, "label": "Software", "start_offset": 1143, "end_offset": 1160}, {"id": 692, "label": "Software", "start_offset": 1271, "end_offset": 1280}, {"id": 693, "label": "Software", "start_offset": 1406, "end_offset": 1415}, {"id": 694, "label": "Software_Url", "start_offset": 79, "end_offset": 108}, {"id": 695, "label": "Software_Url", "start_offset": 184, "end_offset": 224}, {"id": 698, "label": "Software_Url", "start_offset": 281, "end_offset": 321}, {"id": 699, "label": "Software_Url", "start_offset": 388, "end_offset": 429}, {"id": 700, "label": "Software_Url", "start_offset": 497, "end_offset": 537}, {"id": 701, "label": "Software_Url", "start_offset": 606, "end_offset": 647}, {"id": 702, "label": "Software_Url", "start_offset": 855, "end_offset": 894}, {"id": 703, "label": "Software_Url", "start_offset": 729, "end_offset": 771}, {"id": 704, "label": "Software_Url", "start_offset": 970, "end_offset": 1014}, {"id": 705, "label": "Software_Url", "start_offset": 1094, "end_offset": 1140}, {"id": 706, "label": "Software_Url", "start_offset": 1221, "end_offset": 1268}, {"id": 707, "label": "Software_Url", "start_offset": 1364, "end_offset": 1403}]}
{"id": 4136, "text": "The original AHRC funding for 'Transforming Digital Music: Investigating Interactive Playback' developed an iOS app system called variPlay which was piloted there. The app facilitated interactive and algorithmic music playback; see the summary page.\n\nThis project took that code framework and deployed it as a number of commercial releases; see Artistic and Creative Products section.", "entities": [{"id": 909, "label": "Software", "start_offset": 130, "end_offset": 138}]}
{"id": 4137, "text": "4DModeller is a spatio-temporal modelling package that can be applied to problems at any scale from micro to processes that operate at a global scale. It includes data visualization tools, finite element mesh building tools, Bayesian hierarchical modelling based on Bayesian inference packages INLA and inlabru, and model evaluation and assessment tools.", "entities": [{"id": 1124, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 4138, "text": "Modular SMART on FHIR app", "entities": [{"id": 1363, "label": "Software", "start_offset": 17, "end_offset": 25}]}
{"id": 4139, "text": "This release contains the code used for the analyses in Talenti el al. A cattle graph genome incorporating global breed diversity.", "entities": []}
{"id": 4140, "text": "BOmA is a genome browser tailored for viewing cattle omic data, including that being generated alongside or as part of this award. Data currently on the browser spans both water buffalo and cattle and for example includes genotypes from 420 global cattle breeds and optical mapping, ATAC-seq, RNA-seq and RRBS data for various breeds. The first version of the browser is available here https://www.bomabrowser.com/ and we are currently in the process of updating it to support visualising graph genomes", "entities": [{"id": 488, "label": "Software", "start_offset": 0, "end_offset": 5}, {"id": 489, "label": "Software_Url", "start_offset": 386, "end_offset": 414}]}
{"id": 4141, "text": "An updated webserver for the improved SDM, used for predicting the effects of mutations on protein stability. We have updated the environment-specific amino-acid substitution tables based on the current expanded PDB (a 5 fold increases in information), and introduced new residue conformations and interaction parameters, including packing density and residue depth.", "entities": []}
{"id": 4142, "text": "Machine learning approach to predicting the impacts of mutations on protein stability and interactions with other proteins, nucleic acids, and small molecule ligands.", "entities": []}
{"id": 4143, "text": "The algorithms resulting from this project have been implemented into the open source simulation package, called Spinach, maintained by Kuprov group (http://spindynamics.org).", "entities": [{"id": 1125, "label": "Software", "start_offset": 113, "end_offset": 120}, {"id": 1126, "label": "Software_Url", "start_offset": 150, "end_offset": 173}]}
{"id": 4144, "text": "Cosmological random field simulations", "entities": [{"id": 1364, "label": "Software", "start_offset": 0, "end_offset": 37}]}
{"id": 4145, "text": "code based on random fields to produce simulated weak lensing catalogues with known underlying signal, which can be used to verify performance of codes that generate weak lensing data products", "entities": []}
{"id": 4146, "text": "A simple interface to allow electrostatic embedding of machine learning potentials using an ORCA-like interface. An example sander (AmberTools) implementation is provided. This works by reusing the existing interface between sander and ORCA, meaning that no modifications to sander are needed.\nemle-engine supports electrostatic, non-polarisable, and MM embedding. Here non-polarisable emedding uses the EMLE model to predict charges for the QM region, but ignores the induced component of the potential. MM embedding allows the user to specify fixed MM charges for the QM atoms, with induction once again disabled. The use of different embedding schemes provides a useful reference for determining the benefit of using electrostatic embedding for a given system.", "entities": [{"id": 490, "label": "Software", "start_offset": 132, "end_offset": 142}]}
{"id": 4147, "text": "An app to make annotation of audio recordings and transcripts more efficient", "entities": []}
{"id": 4148, "text": "OPTiMAL code in support of:\n Eley, Y. L., Thompson, W., Greene, S. E., Mandel, I., Edgar, K., Bendle, J. A., and Dunkley Jones, T.: OPTiMAL: A new machine learning approach for GDGT-based palaeothermometry, Clim. Past Discuss., https://doi.org/10.5194/cp-2019-60, in review, 2019.", "entities": [{"id": 910, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4149, "text": "Large set of Mathematica packages for analyzing, simulating, and understanding NMR experiments.", "entities": [{"id": 1127, "label": "Software", "start_offset": 13, "end_offset": 25}]}
{"id": 4150, "text": "Novel deep learning cloud masking algorithm written in Python. Designed for use on Landsat 8 dataset, with scripts for experiments as conducted in the related paper: https://doi.org/10.3390/rs11192312", "entities": [{"id": 1365, "label": "Software", "start_offset": 0, "end_offset": 43}]}
{"id": 4151, "text": "A map of the UK split into regions, disaggregated by constituencies, with data on 150+ variables. The display can be searched in multiple ways, data can be downloaded, and the display can be embedded in others' websites. Changes in political parties between 2010 and 2105 can be displayed dynamically.", "entities": []}
{"id": 4152, "text": "One of the fundamental questions in populations dynamic is assessing how changes in the current structure and environment affect the structure composition in both the short and long-term. Plant and animal breeding programs benefits from having a tool to evaluate the potential of different selection strategies or new emerging technologies to improve population performance. Empirical datasets to assess the effect of different factors on one population are difficult to collect, since they require substantial financial and time investments and are subject to noise and error. Simulation is a key tool for both researchers and breeders to assess the impact of different factors given a known historical and current population structure prior to implementation within a real-life setting. AlphaSim is a fast and flexible software tool that enables researchers and breeders to do this. Unlike other simulation tools, AlphaSim has the functionality to manipulate fine details of the population structure in order to simulate realistic scenarios and provides detailed outputs for use in downstream analyses.", "entities": [{"id": 491, "label": "Software", "start_offset": 789, "end_offset": 797}, {"id": 492, "label": "Software", "start_offset": 916, "end_offset": 924}]}
{"id": 4153, "text": "The use of phased sequencing data has been shown to significantly increase the accuracy of imputation. AlphaPhase has been used as part of an imputation pipeline. Existing programs for phasing, have generally scaled poorly to large datasets with long and expensive burden in the computational resources available. Additionally, the increasing production of large sequencing data bundles and its heterogeneity complicate the phasing process. The current version of AlhaPhase implements methods to determine phase using an extended Long Range Phasing and Haplotype Library Imputation.", "entities": [{"id": 708, "label": "Software", "start_offset": 103, "end_offset": 114}, {"id": 709, "label": "Software", "start_offset": 464, "end_offset": 473}]}
{"id": 4154, "text": "R package written to simulate populations and the techniques for control of genetic variance as an aid for teaching.", "entities": []}
{"id": 4155, "text": "With improving technologies and decreasing costs, it is now possible and much more informative to collect genomic data by whole genome sequencing. However, sequencing all individuals at high coverage in a large population is not feasible. Instead, we can harness the fact that individuals within a population are related and thus share sections of the genome. If we can identify and sequence individuals that share more of their genome with a large number of individuals in the population then we can pass on the generated sequence data to other individuals that share the same regions of the genome as the sequenced individual, a process known as imputation. AlphaSeqOpt is a software tool that enables researchers and breeders to define a minimal set of individuals that share more of their genomes with a large number of individuals in the population. AlphaSeqOpt also provides the sequencing investment required for a key individual in order to generate accurate and high quality sequence data that can be used to impute sequence for other individuals in the population.", "entities": [{"id": 1128, "label": "Software", "start_offset": 660, "end_offset": 671}, {"id": 1129, "label": "Software", "start_offset": 855, "end_offset": 866}]}
{"id": 4156, "text": "In an effort to improve the accessibility and usability of our AlphaSim software, we have developed a graphical user interface (GUI), which uses the Java runtime environment (JRE). By increasing the usability of our software, we hope that the impact of these programs will be even greater, especially for people where available resources are at a premium. Tthe AlphaSim GUI is freely available on the AlphaGenes webpage, and includes video tutorials, practical exercises and support.", "entities": [{"id": 1366, "label": "Software", "start_offset": 63, "end_offset": 71}, {"id": 1367, "label": "Software", "start_offset": 361, "end_offset": 369}, {"id": 1368, "label": "Software", "start_offset": 401, "end_offset": 411}]}
{"id": 4157, "text": "This allows the users to annotate a protein sequence with InterPro entries.", "entities": []}
{"id": 4158, "text": "statistical analysis for electrophysiological data (MEEG)", "entities": []}
{"id": 4159, "text": "The data presented in this portal shows hydrological model estimates of projected future changes in river flows (m3s-1) across Peninsular Malaysia.\nThe hydrological model is HMF-Malaysia, which provides grid-based and spatially-consistent simulations of river flows at a 0.008333&deg; &times; 0.008333&deg; grid (approximate grid of 1 km &times; 1 km) resolution across Malaysia.\nChanges in river flows are calculated between historical (1976-2005) and projected future (2006-2099) time periods using CORDEX-SEA climate model data.\nThese data are also available to download from the EIDC (Rameshwaran et al., 2022).", "entities": [{"id": 710, "label": "Software", "start_offset": 174, "end_offset": 186}]}
{"id": 4160, "text": "This software is developed by PI Aaron Einbond for immersive audio applications with the CResCa project. While there are plans to release the software with an open source license through GitHub, it is currently still private while it is under development.", "entities": []}
{"id": 4161, "text": "Fashion company Awaytomars is using Artificial Intelligence (AI) to radically transform the design process. In 2015 the company developed an innovative collaboration platform to prove the concept of crowd participation and co-creation in the design and innovation process. The platform enables users to contribute toward the design process and currently involves a global community of over 15,000 members. By 2019 Awaytomars was keen to take the business to the next level. This required a more sophisticated co-creation tool inside the platform that would allow users to participate in design requests in a more user-friendly and transparent way. The aim was to enable designers from across the globe to share ideas, co-create, track the development of their ideas, and get paid in a more transparent way, tracked by blockchain technology. The main challenge was how to create the structure of this new co-creation tool.", "entities": []}
{"id": 4162, "text": "The Sustainable Supplier Marketplace (SSM) aims to be a solution for both retailers and suppliers. A standardized and detailed profile covering production capabilities and capacity, alongside sustainability certifications, will be completed by a supplier. This can then be used by a retailer to shortlist and select appropriate suppliers according to the retailer's specific requirements", "entities": [{"id": 1369, "label": "Software", "start_offset": 4, "end_offset": 36}, {"id": 1370, "label": "Software", "start_offset": 38, "end_offset": 41}]}
{"id": 4163, "text": "The Conversational AI module of the solution is being developed on Amazon Web Services (AWS). The AWS tool being used include Amazon Elastic Computing Cloud (EC2), Transcribe, Polly, Lambda, Dynamo, API Gateway and Simple Storage Service (S3). JavaScript technology s being used to develop the front end of the application. To facilitate interaction with 3D models, Autodesk BIM360 Documents and Forge API developer tools are being used.", "entities": [{"id": 1563, "label": "Software", "start_offset": 4, "end_offset": 28}]}
{"id": 4164, "text": "First release", "entities": []}
{"id": 4165, "text": "The VazaZika application is available online at&nbsp;http://www.vazazika.com.br \n\nIt has been developed in cooperation with&nbsp;health professionals&nbsp;&nbsp;from the Municipal Health Secretariat of Macei&oacute;\n\nAn initial version of the platform is available and is in experimental use by a group of PG students in 4 partner universities in Brazil and by health professionals.\n\nThis is a new, very much re-worked version of the application for the mobile phones. It supports a number of gamification strategies for involving users.", "entities": [{"id": 711, "label": "Software", "start_offset": 4, "end_offset": 24}, {"id": 712, "label": "Software_Url", "start_offset": 53, "end_offset": 80}]}
{"id": 4166, "text": "The system consists of a web portal and a mobile app.\n\nThe portal collects the twits, categorized them and ranks the Twitter users to identify the social sensors. The users of the portal can see on the map the uptodate information about the relevant twits, their location, hitmaps, etc.\n\nThe portal is connected to the apps that collect the information provided by the users about dengue focuses and pass it it the portal, and allow the users to see on the map the uptodate information about the relevant twits, their location, hitmaps, etc. \n\nThe portal and the apps are used to engage the social sensors identified.\n\nWe developed a web portal and a mobile app for Android and iOS. The app is distributed as open source and open distribution with the GPL licence.", "entities": []}
{"id": 4167, "text": "A new telecoms framework was developed for efficiently controlling a large population of distributed energy resources (DERs) using low cost commodity hardware and any available telecoms delivery technology. The framework is centred around the MQTT messaging system, but design for resilience, reliability, scalability, and the needs of Transmission System Operators (TSOs) as well as appliance vendors and the consumer have led to heavy customisation. A demonstrator system has been created and shown to relevant stakeholders.", "entities": [{"id": 1130, "label": "Software", "start_offset": 6, "end_offset": 24}, {"id": 1131, "label": "Software", "start_offset": 454, "end_offset": 474}]}
{"id": 4168, "text": "The Dylos GUI software has been developed as part of the AFRESH project. It provides a much simpler user interface to download data from Dylos air quality instruments and to present this for use in smoke-free home interventions. The software automatically produces a graph with some quantitative data about the level of second-hand smoke measured in the home.", "entities": [{"id": 1371, "label": "Software", "start_offset": 4, "end_offset": 13}]}
{"id": 4169, "text": "Bespoke analysis tool to perform the latest analyses on the largest UK datasets available.", "entities": [{"id": 1564, "label": "Software", "start_offset": 0, "end_offset": 21}]}
{"id": 4170, "text": "Used to select cohorts of interest, and to put a research proposal to them for feedback under the DPUK research protocol.", "entities": []}
{"id": 4171, "text": "2012.1 release of Sire molecular simulation framework. Main enhancement was the creation of code to simplify the running of waterswap\nabsolute binding free energy calculations. This included new algorithms for automatically generating z-matrices\nof molecules, automatically loading the molecular structure and parameters from Amber format topology/coordinate\nfiles, and the development and inclusion of new algorithms for speeding up the calculation (reflection sphere,\ngrid-based electrostatics etc.)", "entities": [{"id": 713, "label": "Software", "start_offset": 18, "end_offset": 53}]}
{"id": 4172, "text": "FESetup\n\nFESetup is a tool to automate the setup of (relative) alchemical free energy simulations like thermodynamic integration (TI) and free energy perturbation (FEP) as well as post-processing methods like MM-PBSA and LIE. FESetup can also be used for general simulation setup (&quot;equilibration&quot;) through an abstract MD engine. The latest releases are available from the project web page.", "entities": [{"id": 911, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 912, "label": "Software", "start_offset": 9, "end_offset": 16}]}
{"id": 4173, "text": "A significant update to the initial Interview Assistance app based on scenario-based interview transcripts, user input and expert input. Breadth and depth of Topics, as well as Topic accuracy have been improved. Speech interface has been rationalised.", "entities": [{"id": 1132, "label": "Software", "start_offset": 36, "end_offset": 60}]}
{"id": 4174, "text": "The system suggests deeper lines of questioning to an interviewer in real-time, based on initial snippets of information e.g. home address.", "entities": []}
{"id": 4175, "text": "Incisiv has been developing a creative game environment that will identify problems in the way the human brain controls balance. The VR content is key to the product that will ultimately combine hardware, software and scientifically validated analytics to detect, monitor and rehabilitate sports players who have suffered a concussion or traumatic brain injury (TBI). \nThis new product uses the power of immersive, interactive VR to identify problems in the way the human brain works. It will generate value for immersive technology products in market segments currently underexploited by VR (sport/healthcare), which in turn will drive economic growth. \nCurrent concussion protocols that measure a person's ability to control their balance are not implemented in a robust, standardised way. They are too reliant on human observation meaning the subtle changes in behaviour caused by an injury to the brain are often missed. Undiagnosed concussions can lead to serious permanent health problems later in life, or worse still, death. There is an urgent need to improve the detection, monitoring and treatment of concussion. This project will use the power of immersive, interactive virtual reality to create a serious balance game to measure the effects of concussion on the brain. The design of the game content (visual imagery and auditory feedback) will be key to determining the extent to which brain disturbances caused by concussion can be detected and monitored. The game presented through a VR headset will be used to control what the player's brain sees while VR motion sensors attached to the body will very precisely measure how the brain responds. This data generated through this real-time gaming interaction will be analysed to provide an objective measure of how the effects of concussion are affecting brain function.\nThe product is already being tested by BT and it is in use by a number of premiership soccer players.", "entities": []}
{"id": 4176, "text": "Using augmented reality and available on everyone's smartphone, Yellow Design has developed the Rovar AR pods that allow citizens, consumers and visitors to explore places with increased confidence, providing wayfinding directions, time and distance to multiple destinations. The pods work by dynamically surrounding the user with augmented suggestions based on their preferences, recommending places to eat, drink and visit, based on their GPS and proximity as they go about their day.", "entities": [{"id": 493, "label": "Software", "start_offset": 96, "end_offset": 109}]}
{"id": 4177, "text": "TapSOS Ltd are developing technologies to address categorised needs such as Physical, Developmental, Behavioural/Emotional and Sensory. Technology is meant for everyone, and TapSOS Ltd recognise the opportunity to develop specialised service design to enhance a user's experience when interacting with 999. Our solution has been tailored and expertly designed in response to user needs under extreme stress. TapSOS won the 2021 Health Tech Award at the Digileaders Awards and are presently in discussions with a number of international health agencies Wirth a view to having the product available as part of their public service.\nTapSOS Ltd are creating products to:\nReduce costs for emergency services and Government. \nReduce time of reporting for users and reduce overall strain on Government safeguarding and well- being. \nProtect the lives of vulnerable and those at risk. \nPromote inclusion, access and empowerment.", "entities": []}
{"id": 4178, "text": "Ulster Touring Opera (UTO) is a registered charity with a mission to increase access to opera across the nine counties of Ulster and beyond, through live performance and ground-braking immersive technology experiences. As well as the potential demographic reach of augmented reality (AR), UTO is interested in the implications of bringing opera into this medium, as it raises important questions about viewership explored in Walter Benjamin's essay The Work of Art in the Age of Mechanical Reproduction.", "entities": [{"id": 913, "label": "Software", "start_offset": 0, "end_offset": 20}, {"id": 914, "label": "Software", "start_offset": 22, "end_offset": 25}]}
{"id": 4179, "text": "Retinize in partnership with Future Screens NI have produced real time digital humanoids that are multi-faceted. The techniques applied combine a high resolution hyper realistic photo scan of a performer alongside a motion capture suit and high end smartphone. The motion capture suit will allow for accurate recording of body movements, while the high end smartphone will allow for highly precise facial capture for a relatively low cost (in comparison to existing facial capture methodologies and technologies). This allows an almost true to life capture to be undertaken rapidly but at a vastly reduced cost when compared to current high end options currently on offer, such as pure volumetric capture. This methodology will also help to improve on some of the limitations of these systems, especially facial recordings.", "entities": [{"id": 1133, "label": "Software", "start_offset": 61, "end_offset": 88}]}
{"id": 4180, "text": "We are producing a R package to include our main methods and analytic processes in terms of the analysis of regression discontinuity design, particularly under a Bayesian approach.", "entities": []}
{"id": 4181, "text": "One Minute is an app that museum visitors can use to access information about museum collections on their own device. It offers a platform for forms of storytelling in the museum that would be difficult to achieve with object labels or other traditional forms of exhibit-level interpretation. One Minute provides an additional experience in its own right - like a trail or cross-gallery intervention -- with the clear preference of most visitors to use it as a tool that augments the trajectory of their planned visit. The app adds to the visitor experience and creating a canvas for bringing richer and more diverse voices to the stories we tell in our galleries. The One Minute app was developed by the IT University of Copenhagen as part of the EU-funded Gift project. Royal Pavilion &amp; Museums was a partner in this project and hosted the first test of the app in Brighton Museum in 2019. The Gift project completed in early 2020 and the code for the component parts of One Minute were made available as open source.Given the positive public response to the first test of the app, RPM staff worked with the original project team at ITU Copenhagen to set up our own installation. The final installation of the app and CMS were completed by Mnemoscene, using funding from the AHRC funded DigiPiCH project, to enhance the 'Bring your own device' offer of the Museum.", "entities": [{"id": 1566, "label": "Software", "start_offset": 669, "end_offset": 683}, {"id": 1567, "label": "Software", "start_offset": 977, "end_offset": 987}]}
{"id": 4182, "text": "An interactive web-based software which was tailored for use by the DeLaWarr Pavilion audiences specifically.", "entities": []}
{"id": 4183, "text": "The Peale Center has used for some time an IoS app, the BeHere Stories app, that was accessible via Ios/mac devices only. DigiPich commissioned a web based version which is accessible via android devices also.", "entities": [{"id": 714, "label": "Software", "start_offset": 56, "end_offset": 74}]}
{"id": 4184, "text": "OpenCOSSAN is a tool for uncertainty quantification and management. It represents the core of COSSAN software under continuous development at the Institute for Risk and Uncertainty,University of Liverpool, UK. All the algorithms and methods have been coded in a Matlab toolbox allowing numerical analysis, reliability analysis, simulation, sensitivity, optimization, robust design. \n\nOpenCossan is coded exploiting the object-oriented Matlab programming environment, where it is possible to define specialized solution sequences, which include reliability methods, sensitivity analysis, optimization strategies, surrogate models and parallel computing strategies. The computational framework is organized in packages. A package is a namespace for organizing classes and interfaces in a logical manner, which makes large software project OpenCossan easier to manage. A class describes a set of objects with common characteristics such as data structures and methods. Objects, that are instances of classes can be aggregated forming more complex objects and proving solutions for practical problem in a compact, organized and manageable format. The structure of the software allows for extensive modularity and efficient code re-utilization. Objects (instances of a class) can be aggregated forming more complex objects with methods providing solutions for practical problem in a compact, organized and manageable format.", "entities": [{"id": 915, "label": "Software", "start_offset": 0, "end_offset": 10}, {"id": 916, "label": "Software", "start_offset": 384, "end_offset": 394}]}
{"id": 4185, "text": "We have developed a free to access ThingLink webtool to share the results of primary research, scientific analysis, engagement workshops and site visits conducted throughout the Eternal Connections project. This is published online and meets accessibility criteria. The ThingLink can be accessed and explored here: https://www.thinglink.com/card/1604051920832430081", "entities": [{"id": 1134, "label": "Software", "start_offset": 35, "end_offset": 52}, {"id": 1135, "label": "Software_Url", "start_offset": 315, "end_offset": 365}]}
{"id": 4186, "text": "Next-generation radio interferometric imaging", "entities": []}
{"id": 4187, "text": "Sparse optimisation", "entities": [{"id": 1568, "label": "Software", "start_offset": 0, "end_offset": 6}]}
{"id": 4188, "text": "j-Wave is a library of simulators for acoustic applications. Is heavily inspired by k-Wave (a big portion of j-Wave is a port of k-Wave in JAX), and its intended to be used as a collection of modular blocks that can be easily included into any machine learning pipeline. Following the philosophy of JAX, j-Wave is developed with the following principles in mind: to be differentiable, to be fast via jit compilation, easy to run on GPUs, easy to customize.", "entities": [{"id": 494, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 495, "label": "Software", "start_offset": 84, "end_offset": 90}, {"id": 496, "label": "Software", "start_offset": 304, "end_offset": 310}]}
{"id": 4189, "text": "jaxdf is a JAX-based package defining a coding framework for writing differentiable numerical simulators with arbitrary discretizations. The intended use is to build numerical models of physical systems, such as wave propagation, or the numerical solution of partial differential equations, that are easy to customize to the user's research needs. Such models are pure functions that can be included into arbitrary differentiable programs written in JAX: for example, they can be used as layers of neural networks, or to build a physics loss function.", "entities": [{"id": 715, "label": "Software", "start_offset": 0, "end_offset": 5}]}
{"id": 4190, "text": "All of the data from the paper, as well as an easy python module or creating domain wall encodings. Marked as software, even though it also does contain the datasets.", "entities": []}
{"id": 4191, "text": "It is the workflow to process an HDR Cohort Discovery tool query", "entities": []}
{"id": 4192, "text": "It allows compatibility between the work of TRE-FX, the HDR Programme (Cohort Discovery) and BC Platforms software", "entities": []}
{"id": 4193, "text": "The &quot;Photomap&quot; mobile app supported users in the capture (using the phones camera) and geo-referencing (using the phone's built in GPS) of You-Are-Here map signage. The initial &quot;Photomap&quot; mobile app application only ran only Nokia Symbian devices (e.g. Nokia N95) but an Andoird version was later developed and released during the EXTRAMS project.", "entities": [{"id": 1569, "label": "Software", "start_offset": 10, "end_offset": 18}, {"id": 1570, "label": "Software", "start_offset": 193, "end_offset": 201}]}
{"id": 4194, "text": "CHAMP is a high performances computing (HPC) and metadata portal which provides an easy to use workflow for FAIR (Findable, Accessible, Interoperable and Reusable) data generation and publication", "entities": [{"id": 497, "label": "Software", "start_offset": 0, "end_offset": 5}]}
{"id": 4195, "text": "The software is an open-access online decision-support tool, which utilises the data gathered on drivers underlying use of antimicrobials and key risk factors for emergence and transmission of AMR. An underlying metric calculates AMR risk at the community level based on a number of key factors within the data, including social and behavioural aspects of access to and use of antibiotics. It allows users to make adjustments to each element of the metric to reduce this risk, giving policy-makers the ability to formulate predictive, rather than reactive, AMR policies. The tool (available at www.amrtool.com) gives policy makers access to the project dataset and also allows users to upload their own data into the tool to apply the metric to other locations and contexts. The overall aim is to enable policy makers and planners to identify and better understand the critical behavioural factors underpinning the potential emergence of AMR at the community level.", "entities": [{"id": 716, "label": "Software", "start_offset": 19, "end_offset": 59}]}
{"id": 4196, "text": "A project website was created and has been live since July 2020 at https://theinnovateproject.co.uk/. The website is our gateway to public engagement and developing impact. In each of the sections of the website, original material emerging from the project work can already be found. For example, on the page 'All About Innovation' https://theinnovateproject.co.uk/all-about-innovation/ visitors to the website can listen to an hour long podcast which talks through key issues that the project is dealing with, e.g. how the social care sector uses a range of (sometimes divergent) definitions of innovation; how and where innovation in social care is similar to or different from innovation as defined by other areas or disciplines; how innovation overlaps with, and diverges from, service or practice improvement?. The page on Trauma-informed Practice https://theinnovateproject.co.uk/trauma-informed-practice/ has a video setting out the key tenets of this innovative approach and links to an online resource on Trauma-informed Practice developed by Co-Investigator Hickle https://padlet.com/k_hickle/TIpractice. There is also a blog which sets out our thinking-in-progress https://theinnovateproject.co.uk/blog/. All our emergent findings will be directed to the social care sector, policymakers and academic users through this website. Those interested are able to sign up for our regular email updates. We are currently setting up a Learning and Development Network of social care organisations and leaders and will be surveying them regularly on how their use of these resources is changing their practices. This will enable us to identify impact arising from our research.\n\nThe findings from our research have immediate salience for the social care sector and our website enables our resources to reach a wide audience rapidly. This means that those involved in the commissioning, design and development of new social care models and practice systems will gain the knowledge they need to inform not only new approaches to addressing the extra-familial risks and harms that affect young people, but also to understand more widely how to facilitate social innovation in order to make best use of public investment.", "entities": [{"id": 918, "label": "Software", "start_offset": 310, "end_offset": 330}, {"id": 919, "label": "Software_Url", "start_offset": 332, "end_offset": 387}, {"id": 920, "label": "Software", "start_offset": 828, "end_offset": 852}, {"id": 921, "label": "Software_Url", "start_offset": 853, "end_offset": 912}, {"id": 922, "label": "Software", "start_offset": 1014, "end_offset": 1039}, {"id": 923, "label": "Software_Url", "start_offset": 1075, "end_offset": 1113}, {"id": 924, "label": "Software_Url", "start_offset": 1176, "end_offset": 1214}, {"id": 925, "label": "Software", "start_offset": 1131, "end_offset": 1136}, {"id": 926, "label": "Software_Url", "start_offset": 66, "end_offset": 100}]}
{"id": 4197, "text": "For the analysis of the SWATH-MS data, we constructed a reanalysis pipeline with Nextflow. This choice allows the data processing to be executed in single-computer mode, on HPC clusters, and on cloud computing platforms. The pipeline steps can be broken down into raw data conversion, Quality Control and SWATH window processing, OpenSWATH target generation and data analysis, FDR analysis and multi-run alignment with PyProphet and TRIC, and finally statistical analysis with MSstat and upload to Expression Atlas via custom submission scripts. All analysis software is containerised either from available software release of built-for-purpose to ensure a well-defined compute environment and software compatibility. The pipeline is available at https://github.com/PRIDE-reanalysis/DIA-reanalysis.", "entities": [{"id": 1136, "label": "Software", "start_offset": 56, "end_offset": 89}, {"id": 1137, "label": "Software_Url", "start_offset": 747, "end_offset": 797}, {"id": 1138, "label": "Software", "start_offset": 330, "end_offset": 339}, {"id": 1139, "label": "Software", "start_offset": 419, "end_offset": 428}, {"id": 1140, "label": "Software", "start_offset": 433, "end_offset": 437}, {"id": 1141, "label": "Software", "start_offset": 477, "end_offset": 483}, {"id": 1142, "label": "Software", "start_offset": 498, "end_offset": 514}]}
{"id": 4198, "text": "MaxDIA is a software platform for analyzing data-independent acquisition (DIA) proteomics data within the MaxQuant software environment. Using spectral libraries, MaxDIA achieves deep proteome coverage with substantially better coefficients of variation in protein quantification than other software. MaxDIA is equipped with accurate false discovery rate (FDR) estimates on both library-to-DIA match and protein levels, including when using whole-proteome predicted spectral libraries. This is the foundation of discovery DIA-hypothesis-free analysis of DIA samples without library and with reliable FDR control. MaxDIA performs three- or four-dimensional feature detection of fragment data, and scoring of matches is augmented by machine learning on the features of an identification. MaxDIA's bootstrap DIA workflow performs multiple rounds of matching with increasing quality of recalibration and stringency of matching to the library. Combining MaxDIA with two new technologies-BoxCar acquisition and trapped ion mobility spectrometry-both lead to deep and accurate proteome quantification. Our contribution in this software was to help integration of the output of the tool into PRIDE.", "entities": [{"id": 1373, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 1374, "label": "Software", "start_offset": 163, "end_offset": 169}, {"id": 1375, "label": "Software", "start_offset": 301, "end_offset": 307}, {"id": 1376, "label": "Software", "start_offset": 613, "end_offset": 619}, {"id": 1377, "label": "Software", "start_offset": 786, "end_offset": 792}, {"id": 1378, "label": "Software", "start_offset": 949, "end_offset": 955}]}
{"id": 4199, "text": "The laboratory continues to develop and refine software/hardware tools for data acquisition and analysis relevant to electrophysiology, single-cell imaging and analysis. These activities are long-standing and open-ended, and develop in line with the current research activities and needs of the laboratory. All software and related packages are made freely available to the research community through the laboratory website at psrg.org.uk", "entities": [{"id": 1571, "label": "Software_Url", "start_offset": 427, "end_offset": 438}]}
{"id": 4200, "text": "Co-investigator and co-author of a new online tool to help policymakers, practitioners and members of the public make sense of health research", "entities": []}
{"id": 4201, "text": "The open source platform and app ecosystem code is on our developing repository on GitHub. The Databox platform is an open-source personal networked device, augmented by cloud-hosted services, that collates, curates, and mediates access to an individual's personal data by verified and audited third-party applications and services. The Databox will form the heart of an individual's personal data processing ecosystem, providing a platform for managing secure access to data and enabling authorised third parties to provide the owner with authenticated services, including services that may be accessed while roaming outside the home environment.", "entities": [{"id": 717, "label": "Software", "start_offset": 95, "end_offset": 111}, {"id": 718, "label": "Software", "start_offset": 337, "end_offset": 344}]}
{"id": 4202, "text": "Collection of utility daemons and orchestration layers for control of ARPES equipment, interfacing with proprietary spectrometer control systems", "entities": []}
{"id": 4203, "text": "Software which considers variant calling files generated from Clockwork pipeline and the genetics resistance calling catalogue and provides a predicted phenotype output for 13 different drugs.", "entities": []}
{"id": 4204, "text": "ChemBuild is a program to generate, modify and convert molecular topology descriptions used for (bio)molecular simulations. It allows the users to adjust the templates in an interactive fashion.", "entities": [{"id": 1379, "label": "Software", "start_offset": 0, "end_offset": 9}]}
{"id": 4205, "text": "Premier biomolecular NMR software package with unique capabilities for NMR-based screening data analysis.", "entities": [{"id": 1572, "label": "Software", "start_offset": 0, "end_offset": 41}]}
{"id": 4206, "text": "Premier software package with unique capabilities for NMR-based screening data analysis.", "entities": []}
{"id": 4207, "text": "CcpNmr Analysis version 2.4 with enhanced assignment tools, new restraint calibration tool, new summary tool and new CYANA integration tool.", "entities": [{"id": 719, "label": "Software", "start_offset": 0, "end_offset": 15}, {"id": 720, "label": "Software", "start_offset": 64, "end_offset": 90}, {"id": 721, "label": "Software", "start_offset": 96, "end_offset": 108}, {"id": 722, "label": "Software", "start_offset": 117, "end_offset": 139}]}
{"id": 4208, "text": "The NMR Exchange Format (NEF) has been developed in a collaboration between the CCPN, the BioMagResBank, the RCSB, and the main developers of macromolecular NMR software (Peter Guntert (CYANA), Charles Schwieters (XPLOR-NIH), Michael Nilges (ARIA), Torsten Herrmann (UNIO), David Wishart, David Case (AMBER), Guy Montelione (AutoAssign, ASDP)). It covers sequence, chemical shifts, spectra, peak lists, and restraints. The format specification is controlled by consensus of the partners, and all developers have committed to supporting the format as an input/output exchange format. Version 1.0 of the format specification is now stable and fully supported by CCPN, and will be supported by the upcoming release of NMR-STAR (version 3.2.0.1).", "entities": [{"id": 927, "label": "Software", "start_offset": 3, "end_offset": 24}, {"id": 928, "label": "Software", "start_offset": 25, "end_offset": 27}]}
{"id": 4209, "text": "Premier software package with unique capabilities for NMR-based metabolomics data analysis.", "entities": []}
{"id": 4210, "text": "Legacy programme; new windows version released.", "entities": []}
{"id": 4211, "text": "Premier software package with unique capabilities for liquid-state and solid-state NMR data analysis.", "entities": []}
{"id": 4212, "text": "Premier software package with unique capabilities for liquid-state and solid-state NMR data analysis.", "entities": []}
{"id": 4213, "text": "We released CcpNmr AnalysisAssign version-3, the latest software release from the Collaborative Computational Project for NMR, for all aspects of NMR data analysis, including liquid- and solid-state NMR data. We include workflow for backbone assignment as an example of the flexibility and simplicity of implementing workflows, as well as the toolkit used to create the necessary graphics for this workflow. The package can be downloaded from www.ccpn.ac.uk/v3-software/downloads and is freely available to all non-profit organisations.", "entities": [{"id": 723, "label": "Software", "start_offset": 12, "end_offset": 33}, {"id": 724, "label": "Software_Url", "start_offset": 443, "end_offset": 479}]}
{"id": 4214, "text": "The CcpNmr Analysis package is a program for interactive analysis, data tracking and management, of marcomolecular NMR data, and for integration with other programs in the field, such as data acquisition amd structure gneration engines,", "entities": [{"id": 929, "label": "Software", "start_offset": 4, "end_offset": 27}]}
{"id": 4215, "text": "Groundhog Desktop (Beta Version) has been released for free (UK Open Government License) 1000+ downloads so far have occurred from range of sectors . A Exploitation plan is in development to include professionalization and commercialisation. Intended primarily as a vehicle for delivering paid-for data products and services to professional end-users and to bring in consultancy work (both systems and geological work). Strong interest from industry (Atkins, AECOM, CH2M, Surveys - GTK (€100k customization proposal over 2 years is in preparation in the RMS.) and Universities (Newcastle) has been expressed.", "entities": [{"id": 1143, "label": "Software", "start_offset": 0, "end_offset": 17}]}
{"id": 4216, "text": "BGS Civils is a suite of national maps of engineering properties based on geological data and the digital 1:50 000 scale geological map - BGS Geology 50k. \n\nThe primary goal of the product is to provide the key engineering characteristics of the geology of Great Britain to professional users who need simple and rapid access to such information. You might be planning pipeline routes avoiding difficult ground conditions, calculating tender costs for trench excavation or you might need knowledge of ground properties in order to plan your daily activities.\n\nThe data is provided as GIS shapefiles and are available to licence individually or as a bundle to meet your own requirements.", "entities": [{"id": 1380, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 4217, "text": "BGS Open Geoscience has a wide range of datasets and wants to increase access to these by publishing as many as possible under OpenGeoscience. OpenGeoscience is a free service where you can view maps, download data, scans, photos and other information. The services available under OpenGeoscience are listed below, and include:\nview geology data through the Geology of Britain map window and as WMS\naccess to over a million borehole scans\nsearch and download photos from the GeoScenic geological photo archive\nview our published paper maps and sections from 1832 to 2014 and publications from 1835 to the present", "entities": [{"id": 1574, "label": "Software", "start_offset": 127, "end_offset": 141}, {"id": 1575, "label": "Software", "start_offset": 143, "end_offset": 157}, {"id": 1576, "label": "Software", "start_offset": 282, "end_offset": 296}]}
{"id": 4218, "text": "The Radon data: radon potential dataset is the definitive map of Radon Affected Areas in Northern Ireland, created jointly by Public Health England* (PHE) and the BGS using long-term radon measurements made in over 23,000 homes across Northern Ireland (without affecting householders' confidentiality), combined with geological map data.\n\nThe dataset includes a built in 75 m 'buffer', made up of 50 m to allow for the margin of error in the geological lines, and 25 m to represent the average extent of a home.\n\nPHE recommends that radon levels should be reduced in homes where the annual average is at or above 200 becquerels per cubic metre (200 Bq m-3) - this is termed the Radon Action Level.\n\nPHE defines Radon Affected Areas as those with one per cent chance or more of a house having a radon concentration at or above the Action Level of 200 Bq m-3.", "entities": []}
{"id": 4219, "text": "This is a webtool for creating CD spectra from multiple protein atomic structure files. Its main use is for researchers who generate multiple structures (from techniques such as Molecular Dynamics Simulations) where the aim is to compare the generated spectra with those obtained experimentally.", "entities": []}
{"id": 4220, "text": "Graphical User Interface designed to enable a simple investigation into the similarities and differences between two protein structures", "entities": [{"id": 930, "label": "Software", "start_offset": 0, "end_offset": 23}]}
{"id": 4221, "text": "Software includes a Jupyter notebook (Notebook_Three_com_model_WMO3901531.ipynb) designed to illustrate how the a three community phytoplankton model, is fitted to vertical profiles of chlorophyll-a and particle backscatter data.", "entities": []}
{"id": 4222, "text": "Code to fit a two community phytoplankton model to a vertical profile of Chlorophyll-a concentration and particulate backscatter.", "entities": []}
{"id": 4223, "text": "This GitHub repository show an example of how to compute the Secchi depth and Forel Ule colour using Level 2 (NASA processed) SeaHAWK imagery. It contains a Jupyter notebook showing an example of processing a SeaHawk image (provided in the notebook) and estimating Secchi depth and the Forel Ule colour, using standard algroithms of Lee et al. (2015; https://doi.org/10.1016/j.rse.2015.08.002) and Pitarch et al. (2019; https://doi.org/10.1016/j.rse.2019.111249).", "entities": []}
{"id": 4224, "text": "The code is used to illustrate and compare three-component models developed by Sun, Brewin et al. (2023), that quantifies the relationship between total Chl-a and Chl-a associated with the three PSCs (pico-, nano- and microplankton).", "entities": []}
{"id": 4225, "text": "Python code for an updated/new method to fit a conceptual model of two vertically distinct phytoplankton communities to profiles of Chlorophyll-a/Fluoresence and Particulate Organic Carbon (POC) or backscattering.", "entities": []}
{"id": 4226, "text": "This GitHub repository accompanies the manuscript of Maniaci et al. titled &quot;Concentration and distribution of phytoplankton nitrogen and carbon in the Northwest Atlantic and Indian Ocean: A simple model with applications in satellite remote sensing&quot;. It is designed to illustrate how the in situ data were processed and how the model is fitted to the data.", "entities": []}
{"id": 4227, "text": "Lagtraj is a novel framework for the calculation of atmospheric trajectories and the input files for Lagrangian simulations along these trajectories based on reanalysis data. The simulations can be either Single Column Model simulations or Large-Eddy simulations. Lagtraj aims to streamline the workflow that is required to perform these simulations and perform sensitivity studies, and to ensure simulations are set up in a traceable fashion. Lagtraj has been developed to serve as a community tool that can be further extended with different input and output formats.", "entities": [{"id": 1145, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 1146, "label": "Software", "start_offset": 264, "end_offset": 271}, {"id": 1147, "label": "Software", "start_offset": 444, "end_offset": 451}]}
{"id": 4228, "text": "PreFiT (written by Garba and Roach) was designed to provide labour saving automation of the time-consuming processes used in poly-CINS. Using PreFiT, a user may view and compare experimental and theoretical neutron scattering data, perform edge detection, build fitting files for use in GULP and many other powerful and time-saving activities (including edge detection, signal processing and intensity filtering functionality). Months of manual analysis can now be accomplished in hours - all packaged in a user friendly and intuitive visual interface.", "entities": [{"id": 1381, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 1382, "label": "Software", "start_offset": 142, "end_offset": 148}]}
{"id": 4229, "text": "A fully automated Digital Terrain Modelling software based around an open source core called the NASA Ames Stereo Pipeline has been developed called CASP-GO", "entities": [{"id": 1577, "label": "Software", "start_offset": 8, "end_offset": 52}]}
{"id": 4230, "text": "Updated version of software used as a hub for communicating between the simulation software and the HMI rendering platform. It additionally enables data logging and output of relevant metrics captured from both the simulator and external devices, such as cameras or other monitoring devices. \n\nMost relevant changes in 4.0 include the possibility to request a certain number of ADAS features to be engaged via the HMI. These requests are handled using SymEyeLog's internal logic and applied to the simulated output, while reporting back the status of each feature to the HMI platform.", "entities": [{"id": 498, "label": "Software", "start_offset": 452, "end_offset": 461}]}
{"id": 4231, "text": "This software acts as a central hub for facilitating communication between Simulation software and the HMI rendering platform. The updated version enables the use of LEDs for studies that require light cue. These LEDs can be triggered through prototypes or from the SimEyeLog GUI as well. It also collects the touch input of multiple Android devices via UDP.", "entities": []}
{"id": 4232, "text": "This software acts as a central hub for facilitating communication between Simulation software and the HMI rendering platform. Moreover. it enables data logging and output all the metrics captured from Simulator and other external devices. \nThe update for this version was the addition of Multicast capability, basically making the simulator capable of communicating with the android based devices.", "entities": []}
{"id": 4233, "text": "This software acts as a central hub for facilitating communication between Simulation software, Eye tracking software and the HMI rendering platform. The update for this version includes complete communication between the Simulator and Android devices, along with the latest backend and API to send/receive CANBUS data to iMotions system.", "entities": []}
{"id": 4234, "text": "The software takes a series of videos of the face of a driver as an input, converts this to gaze attribute data, carries out a gaze region prediction and then allows a human to step through the video frame by frame to check that the prediction is accurately reflecting where the driver has looked. We have been able to analyse gaze behaviour of drivers much quicker and cheaper than ever before. The accuracy of electronic automated eye-tracking systems is not at the level of accuracy required to be used for accurate testing. However, machine learning methods can be used to make predictions of where the driver is looking based upon a training data set. This software takes a series of raw video files and a calibration files, and uses the calibration file to predict the gaze direction of users in a vehicle. This saves a huge amount of time compared to just manual coding, and whilst isn't as fast as autmatically coding does provide a nice compromise over the time taken and the robustness of the data.", "entities": []}
{"id": 4235, "text": "Gaze Annotate 2.0 is a Updated Version of the original Gaze Annotate originally created by Lee Skrypchuk. 2.0 has the possibilities to track new metrics that can be used for further data analysis.", "entities": [{"id": 1578, "label": "Software", "start_offset": 0, "end_offset": 13}, {"id": 1579, "label": "Software", "start_offset": 55, "end_offset": 68}]}
{"id": 4236, "text": "This software acts as a central hub for facilitating communication between Simulation software and the HMI rendering platform. The update for this version includes the integration of Smart Eye system and enables data logging for eye tracking and gaze behaviour. We have developed a live attention monitoring graph that is displayed on the GUI interface.", "entities": [{"id": 499, "label": "Software", "start_offset": 282, "end_offset": 313}]}
{"id": 4237, "text": "Software available in limited form on Github", "entities": []}
{"id": 4238, "text": "Rational agent-based decision making system for an unmanned aircraft system.", "entities": [{"id": 931, "label": "Software", "start_offset": 0, "end_offset": 44}]}
{"id": 4239, "text": "Software for letting a rational agent connect to other parts of an autonomous system based in MATLAB. Uses the Robot Operating System (ROS).", "entities": []}
{"id": 4240, "text": "The software integrates Doppler Velocity Log (DVL) data and stereo camera images into a state-of-the-art algorithm for Simultaneous Localisation and Mapping (SLAM).\n\nThis work was done in collaboration with Raluca Scona, Research Associate (Sep. 2019 - Mar. 2020).", "entities": []}
{"id": 4241, "text": "Based on our research outcomes, we have developed a mission planner for endusers using unmanned aerial vehicles for agriclture remote sensing. It is able to take specific requirements for a mission including weathger conditons, geometric information of the field to be covered, sensor or instrumentation charaters, and misison requirements such as resolusions. It is not in the trial stage as a web tool and free available. Anyone who is interseted in using it could upload misison specifiacaitons and will return an optimal flight plan for UAV operation.", "entities": [{"id": 1581, "label": "Software", "start_offset": 52, "end_offset": 67}]}
{"id": 4242, "text": "An open-source library for ultrasound modelling and tomography that provides flexibility and scalability together with production-grade performance.", "entities": []}
{"id": 4243, "text": "The attached Matlab scripts were used to produce the figures that appear in a submission to Geoscientific Model Development entitled &quot;Evaluating the physical and biogeochemical state of the global ocean component of UKESM1 in CMIP6 Historical simulation&quot; by Yool et al. The reference number for the GMD manuscript is gmd-2020-333. The scripts are provided as is, and make use of local files that are not included here. The intention is to record the output processing and plotting methods used in the production of the manuscript.", "entities": []}
{"id": 4244, "text": "The attached Matlab scripts were used to perform analysis and produce the figures that appear in an accepted submission to Geoscientific Model Development: Yool, A., Palmi&eacute;ri, J., Jones, C. G., de Mora, L., Kuhlbrodt, T., Popova, E. E., Nurser, A. J. G., Hirschi, J., Blaker, A. T., Coward, A. C., Blockley, E. W., and Sellar, A. A.: Evaluating the physical and biogeochemical state of the global ocean component of UKESM1 in CMIP6 Historical simulations, Geosci. Model Dev. Discuss. [preprint], https://doi.org/10.5194/gmd-2020-333, in review, 2020. The reference number for the GMD manuscript is gmd-2020-333. A README.txt file accompanies the scripts to explain what each is responsible for in the context of this manuscript. Note that this record also includes a dataset provided by Samar Khatiwala (U. Oxford) from an analysis presented in a 2009 paper (Khatiwala, S., Primeau, F. &amp; Hall, T. Reconstruction of the history of anthropogenic CO2 concentrations in the ocean. Nature 462, 346-349, 2009, https://doi.org/10.1038/nature08526). The scripts are provided as is, and make use of local files that are not included here. The intention is to record the output processing and plotting methods used in the production of the manuscript.", "entities": []}
{"id": 4245, "text": "The attached Matlab scripts were used to produce the figures that appear in a submission to Geoscientific Model Development entitled &quot;Evaluating the physical and biogeochemical state of the global ocean component of UKESM1 in CMIP6 Historical simulation&quot; by Yool et al. The reference number for the GMD manuscript is gmd-2020-333. The scripts are provided as is, and make use of local files that are not included here. The intention is to record the output processing and plotting methods used in the production of the manuscript.", "entities": []}
{"id": 4246, "text": "Software takes a fits image containing a cross-dispersed spectrum and extracts the spectral orders regardless of separation and curvature, applies wavelength correction and other standard data reduction procedures.", "entities": []}
{"id": 4247, "text": "power calculator based on simulations of a two-arm non-inferiority trial with a binary outcome and time-fixed treatment accounting for non-adherence.\nSee also linked publication https://wellcomeopenresearch.org/articles/4-207", "entities": [{"id": 1582, "label": "Software", "start_offset": 0, "end_offset": 16}, {"id": 1583, "label": "Software_Url", "start_offset": 178, "end_offset": 225}]}
{"id": 4248, "text": "To use prediction scores for lack of susceptibility to the default empiric antibiotic as part of a\ndecision support system, a threshold score is needed above which a different antibiotic is\nrecommended. A natural approach is to choose this threshold to maximize overall utility.\nThis web-app provides illustrative interactive calculations to show how this can be done.", "entities": []}
{"id": 4249, "text": "Theoretical model for understanding epidemiological interactions between resistant and sensitive bacteria in hospitals and the community, and how hospital interventions impact on these.", "entities": [{"id": 726, "label": "Software", "start_offset": 0, "end_offset": 18}]}
{"id": 4250, "text": "A training and information website was development for staff and family members of residents in nursing homes. The product aims to increase understanding of advance care planning (ACP) in a COVID-19 outbreak. The website provides 6 training units for staff: 1) introduction to ACP; 2) key components of ACP; 3) How to complete an ACP; 4) Recording and sharing ACP; 5) finding the right words: tips for having discussions; 6) caring for yourself. Information for family members of residents was also included in 6 sections: 1) what is ACP; 2) why is ACP important; 3) what might be included in an ACP; 4) who takes part in ACP; 5) how do I take part in ACP; 6) how do I care for myself.", "entities": []}
{"id": 4251, "text": "bone measurement software", "entities": [{"id": 1148, "label": "Software", "start_offset": 0, "end_offset": 25}]}
{"id": 4252, "text": "Update of GWmodel - Open source R code for spatial statistics", "entities": [{"id": 1383, "label": "Software", "start_offset": 10, "end_offset": 18}]}
{"id": 4253, "text": "A suite of spatial statistical modelling tools\nSee https://www.jstatsoft.org/article/view/v063i17", "entities": [{"id": 1584, "label": "Software", "start_offset": 11, "end_offset": 46}, {"id": 1585, "label": "Software_Url", "start_offset": 51, "end_offset": 97}]}
{"id": 4254, "text": "R package", "entities": []}
{"id": 4255, "text": "Varying Parameter Models", "entities": [{"id": 727, "label": "Software", "start_offset": 0, "end_offset": 24}]}
{"id": 4256, "text": "EARS allow the identification of regulatory sequences within the promoters of plant genes, based on their evolutionary conservation.", "entities": [{"id": 932, "label": "Software", "start_offset": 0, "end_offset": 4}]}
{"id": 4257, "text": "Dana Thomson was the technical advisor to our SUE project, the novel sampling methods that she worked on during SUE were part of a range of her research activities, including her own PhD studies, that contributed to the development of a web tool for developing a sample for a survey using population estimates derived from multiple data sets. See this website for further details:\nhttps://danathomson.com/2021/01/13/gridsample/", "entities": []}
{"id": 4258, "text": "This software supports running litmus tests for micro-processors that use the ARM architecture. A litmus test is a tiny parallel program designed to determine what kinds of concurrent behaviours a processor can exhibit. There are several hundred of these, and the ability to effectively determine the answers to them underpins all research into the semantics and correctness of concurrent/parallel programs running on modern micro-processors.\n\nLitmus testing is challenging because each test might have several outcomes, and the more interesting ones might happen fleetingly rarely, and it is important to establish with some confidence that un-observed results are in fact impossible (although it is impossible to actually prove that). This software aims to solve this problem by making it easy to drive the processor (and memory bus) into various &quot;bad&quot; configurations that make the interesting results more likely to happen.", "entities": []}
{"id": 4259, "text": "Ab initio Random Structure Searching (AIRSS) is a very simple, yet powerful and highly parallel, approach to structure prediction. The concept was introduced in 2006 and its philosophy more extensively discussed in 2011.\n\nRandom structures - or more precisely, random &quot;sensible&quot; structures - are generated and then relaxed to nearby local energy minima. Particular success has been found using density functional theory (DFT) for the energies, hence the focus on &quot;ab initio&quot; random structure searching. The sensible random structures are constructed so that they have reasonable densities, and atomic separations. Additionally they may embody crystallographic, chemical or prior experimental/computational knowledge. Beyond these explicit constraints the emphasis is on a broad, uniform, sampling of structure space.\n\nAIRSS has been used in a number of landmark studies in structure prediction, from the structure of SiH4 under pressure to providing the theoretical structures which are used to understand dense hydrogen (and anticipating the mixed Phase IV), incommensurate phases in aluminium under terapascal pressures, and ionic phases of ammonia.\n\nThe approach naturally extends to the prediction clusters/molecules, defects in solids, interfaces and surfaces (interfaces with vacuum).\n\nThe AIRSS package is tightly integrated with the CASTEP first principles total energy code. However, it is relatively straightforward to modify the scripts to use alternative codes to obtain the core functionality, and examples are provided.\n\nThe AIRSS package is released under the GPL2 licence.", "entities": [{"id": 1587, "label": "Software", "start_offset": 0, "end_offset": 36}, {"id": 1588, "label": "Software", "start_offset": 38, "end_offset": 43}, {"id": 1589, "label": "Software", "start_offset": 838, "end_offset": 843}, {"id": 1590, "label": "Software", "start_offset": 1316, "end_offset": 1321}, {"id": 1591, "label": "Software", "start_offset": 1559, "end_offset": 1564}]}
{"id": 4260, "text": "Software developed under a collaboration agreement with Zeeko Ltd, which enables existing Zeeko tool-path generating software to output tool-paths to an industrial robot, rather than a CNC polishing machine. Supports fabuc and ABB robots.", "entities": []}
{"id": 4261, "text": "Common LS and EA frameworks (acting either metaheuristically or hyper-heuristically), demonstrating how to adapt ad hoc metaheuristics into an org.mitlware compatible format.", "entities": [{"id": 728, "label": "Software", "start_offset": 0, "end_offset": 27}]}
{"id": 4262, "text": "This project provides several implementations for commit untagling and proposes a new representation of git patches by projecting the patch onto a PDG.", "entities": []}
{"id": 4263, "text": "A generic framework for generative hyper-heuristics.", "entities": []}
{"id": 4264, "text": "Problem domain library in which domains are described polymorphically via org.mitlware interfaces", "entities": [{"id": 1384, "label": "Software", "start_offset": 0, "end_offset": 22}]}
{"id": 4265, "text": "Sapienz is an approach to Android testing that uses multi-objective search-based testing to automatically explore and optimise test sequences, minimising length, while simultaneously maximising coverage and fault revelation. Sapienz combines random fuzzing, systematic and search-based exploration, exploiting seeding and multi-level instrumentation. Sapienz significantly outperforms (with large effect size) both the state-of-the-art technique Dynodroid and the widely-used tool, Android Monkey, in 7/10 experiments for coverage, 7/10 for fault detection and 10/10 for fault-revealing sequence length. When applied to the top 1,000 Google Play apps, Sapienz found 558 unique, previously unknown crashes. So far we have managed to make contact with the developers of 27 crashing apps. Of these, 14 have confirmed that the crashes are caused by real faults. Of those 14, six already have developer-confirmed fixes.", "entities": [{"id": 1592, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 1593, "label": "Software", "start_offset": 225, "end_offset": 232}, {"id": 1594, "label": "Software", "start_offset": 351, "end_offset": 358}, {"id": 1595, "label": "Software", "start_offset": 652, "end_offset": 659}]}
{"id": 4266, "text": "Clone detection finds application to many software engineering activities such as comprehension and refactoring. However, the confounding configuration choice problem poses a widely-acknowledged threat to the validity of previous empirical analyses. We introduce a search based solution, EvaClone, that finds suitable configurations for empirical studies.", "entities": [{"id": 500, "label": "Software", "start_offset": 288, "end_offset": 296}]}
{"id": 4267, "text": "Ubiquitous solution representations (bitvector,permutation,roots of polynomials).", "entities": []}
{"id": 4268, "text": "Picassevo is a meeting of art and science: It uses intelligent optimising evolutionary algorithms to evolve pictures from a set of arbitrary polygons (many side shapes) with different colours and opacities. The algorithm, which is inspired by Darwinian evolution, simultaneously explores two conflicting objectives when deciding on the desirability of each picture: 1) Does it capture the essence of your portrait and 2) Is it artistically abstract? The algorithm seeks a trade-off between retaining the likeness and increasing the abstraction at the same time.\nYue Jia developed this app.", "entities": [{"id": 938, "label": "Software", "start_offset": 0, "end_offset": 9}]}
{"id": 4269, "text": "This a project to simultaneously provide language ID tags and Part-Of-Speech or compiler tags (which are taken from CLANG compilations of C and C++ code).\n\nThe corpus is either code with comments annotated with CLANG compiler information and universal PoS tags for English, or StackOverflow. For StackOverflow we start from the data dump (which can be found here), and use a frequency based heuristic to annotate code snippets. The frequency data is made available under ./data/corpora/SO/frequency_map.json. To generate training data from StackOverflow, please use the scripts under ./src/preprocessor together with the Posts.xml file from the data dump linked above.\n\nOur model is a BiLSTM neural network with a Linear CRF and Viterbi decode to go from LSTM state to tags or language IDs. We use the same LSTM network and change only the CRF on top for the two tasks. We linearly combine the two objectives in the loss with a slightly smaller weight given to language IDs. We do not condition Tag output on language IDs in this version of the model.", "entities": []}
{"id": 4270, "text": "Basic utilities library for methods common to metaheuristics (e..g. proportional selection, cross-validation, reservoir sampling).", "entities": [{"id": 1385, "label": "Software", "start_offset": 0, "end_offset": 23}]}
{"id": 4271, "text": "Core interfaces for metaheuristic interoperability.", "entities": []}
{"id": 4272, "text": "The prototype pipeline is now publicly available. This was a key aim of the project, to move it from Manchester to EBI, where is will be made publicly available and where the necessary compute support is deployed. We have conducted testing already and it replicates results generated on the version in Manchester, and we deployed and evaluate", "entities": []}
{"id": 4273, "text": "TransitFit fits exoplanetary transit light-curves for transmission spectroscopy studies. The code uses nested sampling for efficient and robust multi-epoch, multi-wavelength fitting of transit data obtained from one or more telescopes. TransitFit allows per-telescope detrending to be performed simultaneously with parameter fitting, including the use of user-supplied detrending alogorithms. Host limb darkening can be fitted either independently (&quot;uncoupled&quot;) for each filter or combined (&quot;coupled&quot;) using prior conditioning from the PHOENIX stellar atmosphere models. For this, TransitFit uses the Limb Darkening Toolkit (ascl:1510.003) together with filter profiles, including user-supplied filter profiles.", "entities": [{"id": 729, "label": "Software", "start_offset": 0, "end_offset": 10}, {"id": 730, "label": "Software", "start_offset": 236, "end_offset": 246}, {"id": 731, "label": "Software", "start_offset": 601, "end_offset": 611}]}
{"id": 4274, "text": "Official release of data and code repository for the paper: McKenna C. M., A. C. Maycock, P. M. Forster, C. J. Smith, K. B. Tokarska, Stringent mitigation substantially reduces risk of unprecedented near-term warming rates, Nature Climate Change (2020); https://doi.org/10.1038/s41558-020-00957-9.", "entities": []}
{"id": 4275, "text": "Official release of data and code repository for the paper: McKenna C. M., A. C. Maycock, P. M. Forster, C. J. Smith, K. B. Tokarska, Stringent mitigation substantially reduces risk of unprecedented near-term warming rates, Nature Climate Change (2020); https://doi.org/10.1038/s41558-020-00957-9.", "entities": []}
{"id": 4276, "text": "First stable release of the SATRE specification. This release is the output of 8 months of work with the Trusted Research Community and represents a baseline for the community to review and contribute to. Please see our contributing guide. This release includes evaluations against the SATRE standard of TREs deployed at the Alan Turing Institute and the Health Informatics Centre at the University of Dundee and we would especially welcome other organisations contributing evaluations for their own TRE deployments.\n\nRead the blog post for this release for more information.", "entities": [{"id": 1386, "label": "Software", "start_offset": 28, "end_offset": 47}]}
{"id": 4277, "text": "First official release of Driftfusion. The recent application of lead-halide perovskites as an active layer material in thin film semiconductor devices including solar cells, light emitting diodes (LEDs), and memristors has motivated the development of several new drift-diffusion models that can include the effects of both mobile electronic and ionic charge carriers. Here, we present Driftfusion, a versatile simulation tool built for simulating one-dimensional ordered semiconductor devices with mixed ionic-electronic conducting layers. Driftfusion enables users to simulate devices with virtually any number of layers and with up to four charge carrier species (electrons and holes by default plus up to two ionic species). The time-dependent carrier continuity equations are fully-coupled to Poisson's equation enabling transient optoelectronic device measurement protocols to be simulated. In addition to the material parameters, users have direct access to adapt carrier transport, recombination and generation models as well as the system boundary conditions. Furthermore, a graded-interface approach circumvents the requirement for boundary conditions at material interfaces and enables interface-specific properties, such as high rates of interfacial recombination, to be introduced.", "entities": [{"id": 1596, "label": "Software", "start_offset": 26, "end_offset": 37}, {"id": 1597, "label": "Software", "start_offset": 387, "end_offset": 398}, {"id": 1598, "label": "Software", "start_offset": 542, "end_offset": 553}]}
{"id": 4278, "text": "First official release of Driftfusion. The recent application of lead-halide perovskites as an active layer material in thin film semiconductor devices including solar cells, light emitting diodes (LEDs), and memristors has motivated the development of several new drift-diffusion models that can include the effects of both mobile electronic and ionic charge carriers. Here, we present Driftfusion, a versatile simulation tool built for simulating one-dimensional ordered semiconductor devices with mixed ionic-electronic conducting layers. Driftfusion enables users to simulate devices with virtually any number of layers and with up to four charge carrier species (electrons and holes by default plus up to two ionic species). The time-dependent carrier continuity equations are fully-coupled to Poisson's equation enabling transient optoelectronic device measurement protocols to be simulated. In addition to the material parameters, users have direct access to adapt carrier transport, recombination and generation models as well as the system boundary conditions. Furthermore, a graded-interface approach circumvents the requirement for boundary conditions at material interfaces and enables interface-specific properties, such as high rates of interfacial recombination, to be introduced.", "entities": [{"id": 501, "label": "Software", "start_offset": 26, "end_offset": 37}, {"id": 502, "label": "Software", "start_offset": 387, "end_offset": 398}, {"id": 503, "label": "Software", "start_offset": 542, "end_offset": 553}]}
{"id": 4279, "text": "Web app making available the DECIDE project outputs - showing places of highest recording potential for willdlife, based on the value of records for research and biodiversity monitoring.", "entities": []}
{"id": 4280, "text": "Personalised emails sent to 850 people to provide information about the value of their wildlife recording.", "entities": []}
{"id": 4281, "text": "Panel surface of CAD model in standard format of commercial software is selected and visualized by pin-tool designers with new interface software. 3D coordinates of reconfigurable pin-tools are automatically generated for computer control unit of pin-tools as well as FEA modelling and simulation of sheet forming process.", "entities": []}
{"id": 4282, "text": "Any issues in design and coding that cause incorrect results are considered software bugs. In a software development life cycle, tracking bugs is one of the most important aspects. Where a user has encountered an issue and submitted it via the Help Desk, but the team could not resolve it immediately, then it is reported as a bug using the COSMOS Bug tracker.", "entities": [{"id": 1388, "label": "Software", "start_offset": 341, "end_offset": 359}]}
{"id": 4283, "text": "Users are able to request to download COSMOS application, and instead of administrator has to manually approve the download request and send link to latest version to the user to download, this process has been automated by building a CRON job and PHP script to handle the email received by the user and store it into google drive document and send out a welcome email with the link to download COSMOS.", "entities": [{"id": 1599, "label": "Software", "start_offset": 38, "end_offset": 56}, {"id": 1600, "label": "Software", "start_offset": 395, "end_offset": 401}]}
{"id": 4284, "text": "Flexible Unit Structure Engine (FUSE), for the generation of approximate 'probe structures' to predict regions of composition space where compounds can be experimentally realised.", "entities": [{"id": 504, "label": "Software", "start_offset": 0, "end_offset": 30}, {"id": 505, "label": "Software", "start_offset": 32, "end_offset": 36}]}
{"id": 4285, "text": "MC-EMMA combines modules and stacking rules identified from the known chemistry of the studied elements to generate new feasible crystal structures.", "entities": [{"id": 732, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4286, "text": "We have developed a library of subroutines/programs that solve linear and semilinear PDEs to high accuracy.", "entities": []}
{"id": 4287, "text": "A Gausian process toolbox using tensorflow", "entities": [{"id": 1149, "label": "Software", "start_offset": 2, "end_offset": 25}]}
{"id": 4288, "text": "A Gaussian Process framework in python", "entities": [{"id": 1389, "label": "Software", "start_offset": 2, "end_offset": 28}]}
{"id": 4289, "text": "We have developed software to control the real-time presentation and collection of neuroimaging data, including EEG and NIRS. This will be available once we have finished demonstrating its potential to the community.", "entities": []}
{"id": 4290, "text": "App for geolocated tour of Florence in the Renaissance period - contains content written by the PI and developed with Calvium Ltd.\nUpdate of the app was published in December 2016.\n\nPlease note that as a result of the AHRC 2018 award this app has been entirely rebuilt with much new content. Relaunches Spring 2019", "entities": []}
{"id": 4291, "text": "Code for the machine learning component of Shaw, Rihn, Mollentze, et al. (2021) &quot;The 'antiviral state' has shaped the CpG composition of the vertebrate interferome&quot;.", "entities": []}
{"id": 4292, "text": "CEX2.5 is a tool for computing three types of logical differences between two acyclic ELHr terminologies, i.e. EL terminologies with additional domain restrictions, range restrictions, and (simple) role inclusions. The types of differences that can be analysed are differences w.r.t. concept inclusions, answers to instance queries, and answers to conjunctive queries formulated over a specified signature, which are logically entailed by a given terminology T1 but not by a second terminology T2.\n\nCEX2.5 uses the reasoner CB internally. The theoretical background behind CEX is described in the paper The Logical Diff for the Lightweight Description Logic EL by Boris Konev, Michel Ludwig, Dirk Walther and Frank Wolter.", "entities": [{"id": 939, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 940, "label": "Software", "start_offset": 499, "end_offset": 505}]}
{"id": 4293, "text": "Mathematical routines for epidemic modelling and inference in structured populations.", "entities": []}
{"id": 4294, "text": "Software for working with subcritical disease outbreaks including Ebola.", "entities": []}
{"id": 4295, "text": "SUEWS - Surface Urban Energy and Water Balance Scheme", "entities": [{"id": 1601, "label": "Software", "start_offset": 0, "end_offset": 5}, {"id": 1602, "label": "Software", "start_offset": 8, "end_offset": 53}]}
{"id": 4296, "text": "Compiler and multicore run-time system for the occam-pi concurrent programming language.", "entities": []}
{"id": 4297, "text": "We are developing an app usable by Android/Apple users to guide the Common Line experience. The design of this is led by project partner Controlled Frenzy", "entities": []}
{"id": 4298, "text": "As part of our work we have designed an interactive map of the Common Line, available to the public via our webpage. This has been primarily achieved by the Project Co-I Steven Palmer. It is still a work in progress, with a set of future features planned", "entities": []}
{"id": 4299, "text": "A VR interface was developed to interface with the ankle exoskeleton so that users can perform ankle rehabilitation exercises while interacting with the VR games. The games are designed with different levels of difficulties for rehabilitation", "entities": []}
{"id": 4300, "text": "The demonstrator showcases the provenance-based explanations that are generated for the two scenarios investigated by PLEAD: credit card application and school allocation.\nA user can play the role of a consumer going through the process of applying for a credit card, or a parent applying for a school place for their child. In either case, the user will receive a simulated decision at the end of the process with legally-driven explanations generated by the PLEAD Explanation Assistant for the decision built from its provenance.\nWe also expose the provenance recorded for each of the decisions to show the data that underlies the explanations presented to the users.", "entities": [{"id": 1390, "label": "Software", "start_offset": 460, "end_offset": 487}]}
{"id": 4301, "text": "Software to detect (head-to-head) gene pairs (tandems) in a genome.", "entities": []}
{"id": 4302, "text": "This software allows effect prediction of single nucleotide polymorphisms without a reference annotation.", "entities": []}
{"id": 4303, "text": "Galaxy implementation of integrated domain fusion detection pipeline (cf. Sarris et al, 2016 BMC Biology)", "entities": []}
{"id": 4304, "text": "Royal dragen is a software developed by Dr. Rob King (Rothamsted Research) and Dr. Christian Schudoma (Earlham Institute). The software allows to perform variant filtering on Dragen-generated variant calls. The software was designed to mimic the behaviour of MAPS in wheat tilling experiments (cf. Krasileva et al., PNAS 2017).", "entities": [{"id": 941, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 4305, "text": "Pipeline for processing of GlutenSeq data.", "entities": []}
{"id": 4306, "text": "First release. Basic functionality of loading the files and performing PCA are working.", "entities": []}
{"id": 4307, "text": "This is an initial release, with minimal capabilities.", "entities": []}
{"id": 4308, "text": "The Y-Check screening tool app is being used in the Y-Check study in Zimbabwe to screen adolescents for health conditions and risk behaviours. The app facilitates data collection and the identification of adolescents who need further treatment, counselling and/or referral.", "entities": [{"id": 506, "label": "Software", "start_offset": 4, "end_offset": 31}]}
{"id": 4309, "text": "https://itunes.apple.com/gb/app/artcasting/id1043020610?mt=8\n\nVisiting the Robert Mapplethorpe: The Magic in the Muse (Bowes Museum, Co. Durham, UK) or the ARTIST ROOMS: Roy Lichtenstein (Scottish National Gallery of Modern Art, Edinburgh, UK) exhibitions? Artcasting works with these exhibitions to invite you to think about your responses to the art in new ways.", "entities": [{"id": 733, "label": "Software_Url", "start_offset": 0, "end_offset": 60}]}
{"id": 4310, "text": "Mobile application for gallery visitors to engage with concepts of place and movement in relation to artworks.", "entities": []}
{"id": 4311, "text": "This is a statistical package for clustering time series RNA-seq data on the basis of the functional map between time series datasets. This can help with identifying groups of genes that are regulated in the same way as a result of environmental perturbation and help with experimental design.", "entities": []}
{"id": 4312, "text": "Allows the user to search through and visualise a gene network that was describes how genes are regulated in the early morning. Several edges of the network have already been experimentally validated.", "entities": []}
{"id": 4313, "text": "This tool helps analyse high resolution time series and selects time points for follow-up experiments. It released to CRAN now.", "entities": []}
{"id": 4314, "text": "Summarises biological gene networks in a format that makes it easier to interpret and develop new biological hypotheses", "entities": [{"id": 507, "label": "Software", "start_offset": 0, "end_offset": 35}]}
{"id": 4315, "text": "This is a new release of the pipeline which processes LOFAR data at high resolution. The pipeline now uses a more robust self-calibration algorithm, which improves the results.", "entities": []}
{"id": 4316, "text": "First release of this public code.", "entities": []}
{"id": 4317, "text": "The Low-Frequency Array Very Long Baseline Interferometry (LOFAR-VLBI) pipeline is a calibration and imaging pipeline that includes all of LOFAR's international stations. It looks and solves for delays using an in-field calibrator within the field of view of the pointing. The pipeline provides: solution tables written in a file in the hierarchical data format (version 5), referred to as an h5parm, a self-calibrated, corrected dataset for the in-field calibrator. The delay solutions are applied back to the original data. From there the pipeline can split out smaller datasets in the desired target direction(s) within the field of view.", "entities": [{"id": 1150, "label": "Software", "start_offset": 4, "end_offset": 57}, {"id": 1151, "label": "Software", "start_offset": 59, "end_offset": 69}]}
{"id": 4318, "text": "Current research on systems and synthetic biology relies heavily on mathematical models of the systems under study. The usefulness of such models depends on the quantity and quality of biological data, and on the availability of appropriate modelling formalisms that can gather and accommodate such data so that they can be exploited properly. Given our incomplete knowledge of biological systems and the fact that they consist of many subsystems, biological data are usually uncertain and heterogeneous. These facts hinder the use of mathematical models and computational methods. In the scope of dynamic biological systems, e.g. metabolic networks, this difficulty can be overcome by the novel modelling formalism of flexible nets (FNs). We show that an FN can combine, in a natural way, a stoichiometric model and a kinetic model. Moreover, the resulting net admits nonlinear dynamics and can be analysed in both transient and steady states.", "entities": [{"id": 1391, "label": "Software", "start_offset": 719, "end_offset": 732}, {"id": 1392, "label": "Software", "start_offset": 734, "end_offset": 737}, {"id": 1393, "label": "Software", "start_offset": 756, "end_offset": 758}]}
{"id": 4319, "text": "Current research on systems and synthetic biology relies heavily on mathematical models of the systems under study. The usefulness of such models depends on the quantity and quality of biological data, and on the availability of appropriate modelling formalisms that can gather and accommodate such data so that they can be exploited properly. Given our incomplete knowledge of biological systems and the fact that they consist of many subsystems, biological data are usually uncertain and heterogeneous. These facts hinder the use of mathematical models and computational methods. In the scope of dynamic biological systems, e.g. metabolic networks, this difficulty can be overcome by the novel modelling formalism of flexible nets (FNs). We show that an FN can combine, in a natural way, a stoichiometric model and a kinetic model. Moreover, the resulting net admits nonlinear dynamics and can be analysed in both transient and steady states.", "entities": [{"id": 1603, "label": "Software", "start_offset": 719, "end_offset": 732}, {"id": 1604, "label": "Software", "start_offset": 734, "end_offset": 737}, {"id": 1605, "label": "Software", "start_offset": 756, "end_offset": 758}]}
{"id": 4320, "text": "Current research on systems and synthetic biology relies heavily on mathematical models of the systems under study. The usefulness of such models depends on the quantity and quality of biological data, and on the availability of appropriate modelling formalisms that can gather and accommodate such data so that they can be exploited properly. Given our incomplete knowledge of biological systems and the fact that they consist of many subsystems, biological data are usually uncertain and heterogeneous. These facts hinder the use of mathematical models and computational methods. In the scope of dynamic biological systems, e.g. metabolic networks, this difficulty can be overcome by the novel modelling formalism of flexible nets (FNs). We show that an FN can combine, in a natural way, a stoichiometric model and a kinetic model. Moreover, the resulting net admits nonlinear dynamics and can be analysed in both transient and steady states.", "entities": [{"id": 508, "label": "Software", "start_offset": 719, "end_offset": 733}, {"id": 509, "label": "Software", "start_offset": 734, "end_offset": 737}, {"id": 510, "label": "Software", "start_offset": 756, "end_offset": 758}]}
{"id": 4321, "text": "Current research on systems and synthetic biology relies heavily on mathematical models of the systems under study. The usefulness of such models depends on the quantity and quality of biological data, and on the availability of appropriate modelling formalisms that can gather and accommodate such data so that they can be exploited properly. Given our incomplete knowledge of biological systems and the fact that they consist of many subsystems, biological data are usually uncertain and heterogeneous. These facts hinder the use of mathematical models and computational methods. In the scope of dynamic biological systems, e.g. metabolic networks, this difficulty can be overcome by the novel modelling formalism of flexible nets (FNs). We show that an FN can combine, in a natural way, a stoichiometric model and a kinetic model. Moreover, the resulting net admits nonlinear dynamics and can be analysed in both transient and steady states.", "entities": [{"id": 734, "label": "Software", "start_offset": 718, "end_offset": 732}, {"id": 735, "label": "Software", "start_offset": 734, "end_offset": 737}, {"id": 736, "label": "Software", "start_offset": 756, "end_offset": 759}]}
{"id": 4322, "text": "Current research on systems and synthetic biology relies heavily on mathematical models of the systems under study. The usefulness of such models depends on the quantity and quality of biological data, and on the availability of appropriate modelling formalisms that can gather and accommodate such data so that they can be exploited properly. Given our incomplete knowledge of biological systems and the fact that they consist of many subsystems, biological data are usually uncertain and heterogeneous. These facts hinder the use of mathematical models and computational methods. In the scope of dynamic biological systems, e.g. metabolic networks, this difficulty can be overcome by the novel modelling formalism of flexible nets (FNs). We show that an FN can combine, in a natural way, a stoichiometric model and a kinetic model. Moreover, the resulting net admits nonlinear dynamics and can be analysed in both transient and steady states.", "entities": [{"id": 942, "label": "Software", "start_offset": 719, "end_offset": 732}, {"id": 943, "label": "Software", "start_offset": 734, "end_offset": 737}, {"id": 944, "label": "Software", "start_offset": 756, "end_offset": 758}]}
{"id": 4323, "text": "Current research on systems and synthetic biology relies heavily on mathematical models of the systems under study. The usefulness of such models depends on the quantity and quality of biological data, and on the availability of appropriate modelling formalisms that can gather and accommodate such data so that they can be exploited properly. Given our incomplete knowledge of biological systems and the fact that they consist of many subsystems, biological data are usually uncertain and heterogeneous. These facts hinder the use of mathematical models and computational methods. In the scope of dynamic biological systems, e.g. metabolic networks, this difficulty can be overcome by the novel modelling formalism of flexible nets (FNs). We show that an FN can combine, in a natural way, a stoichiometric model and a kinetic model. Moreover, the resulting net admits nonlinear dynamics and can be analysed in both transient and steady states.", "entities": [{"id": 1152, "label": "Software", "start_offset": 718, "end_offset": 732}, {"id": 1153, "label": "Software", "start_offset": 734, "end_offset": 737}, {"id": 1154, "label": "Software", "start_offset": 756, "end_offset": 758}]}
{"id": 4324, "text": "Current research on systems and synthetic biology relies heavily on mathematical models of the systems under study. The usefulness of such models depends on the quantity and quality of biological data, and on the availability of appropriate modelling formalisms that can gather and accommodate such data so that they can be exploited properly. Given our incomplete knowledge of biological systems and the fact that they consist of many subsystems, biological data are usually uncertain and heterogeneous. These facts hinder the use of mathematical models and computational methods. In the scope of dynamic biological systems, e.g. metabolic networks, this difficulty can be overcome by the novel modelling formalism of flexible nets (FNs). We show that an FN can combine, in a natural way, a stoichiometric model and a kinetic model. Moreover, the resulting net admits nonlinear dynamics and can be analysed in both transient and steady states.", "entities": [{"id": 1394, "label": "Software", "start_offset": 719, "end_offset": 732}, {"id": 1395, "label": "Software", "start_offset": 734, "end_offset": 737}, {"id": 1396, "label": "Software", "start_offset": 756, "end_offset": 758}]}
{"id": 4325, "text": "Current research on systems and synthetic biology relies heavily on mathematical models of the systems under study. The usefulness of such models depends on the quantity and quality of biological data, and on the availability of appropriate modelling formalisms that can gather and accommodate such data so that they can be exploited properly. Given our incomplete knowledge of biological systems and the fact that they consist of many subsystems, biological data are usually uncertain and heterogeneous. These facts hinder the use of mathematical models and computational methods. In the scope of dynamic biological systems, e.g. metabolic networks, this difficulty can be overcome by the novel modelling formalism of flexible nets (FNs). We show that an FN can combine, in a natural way, a stoichiometric model and a kinetic model. Moreover, the resulting net admits nonlinear dynamics and can be analysed in both transient and steady states.", "entities": [{"id": 1606, "label": "Software", "start_offset": 719, "end_offset": 732}, {"id": 1607, "label": "Software", "start_offset": 734, "end_offset": 737}, {"id": 1608, "label": "Software", "start_offset": 756, "end_offset": 758}]}
{"id": 4326, "text": "Current research on systems and synthetic biology relies heavily on mathematical models of the systems under study. The usefulness of such models depends on the quantity and quality of biological data, and on the availability of appropriate modelling formalisms that can gather and accommodate such data so that they can be exploited properly. Given our incomplete knowledge of biological systems and the fact that they consist of many subsystems, biological data are usually uncertain and heterogeneous. These facts hinder the use of mathematical models and computational methods. In the scope of dynamic biological systems, e.g. metabolic networks, this difficulty can be overcome by the novel modelling formalism of flexible nets (FNs). We show that an FN can combine, in a natural way, a stoichiometric model and a kinetic model. Moreover, the resulting net admits nonlinear dynamics and can be analysed in both transient and steady states.", "entities": [{"id": 511, "label": "Software", "start_offset": 719, "end_offset": 732}, {"id": 512, "label": "Software", "start_offset": 756, "end_offset": 758}, {"id": 513, "label": "Software", "start_offset": 734, "end_offset": 737}]}
{"id": 4327, "text": "Current research on systems and synthetic biology relies heavily on mathematical models of the systems under study. The usefulness of such models depends on the quantity and quality of biological data, and on the availability of appropriate modelling formalisms that can gather and accommodate such data so that they can be exploited properly. Given our incomplete knowledge of biological systems and the fact that they consist of many subsystems, biological data are usually uncertain and heterogeneous. These facts hinder the use of mathematical models and computational methods. In the scope of dynamic biological systems, e.g. metabolic networks, this difficulty can be overcome by the novel modelling formalism of flexible nets (FNs). We show that an FN can combine, in a natural way, a stoichiometric model and a kinetic model. Moreover, the resulting net admits nonlinear dynamics and can be analysed in both transient and steady states.", "entities": [{"id": 737, "label": "Software", "start_offset": 719, "end_offset": 732}, {"id": 738, "label": "Software", "start_offset": 734, "end_offset": 737}, {"id": 739, "label": "Software", "start_offset": 756, "end_offset": 758}]}
{"id": 4328, "text": "The BSD 2-Clause License", "entities": []}
{"id": 4329, "text": "Academic license", "entities": []}
{"id": 4330, "text": "Integrability with a third party open source library for metadynamics methodology", "entities": []}
{"id": 4331, "text": "We created a physical pod that feeds from a wireless connection to a electricity sensor in the home. The pod houses a phne and runs software created in co-design with teenagers. The system includes an arduino board to drive ambient lighting", "entities": []}
{"id": 4332, "text": "Modelled on the Top Gear Product. The cool wall was developed to better understand cool with teenagers. It was deployed in schools in a kiosk installation.", "entities": []}
{"id": 4333, "text": "The project team created a website which gives an overview of the Foresight Future Flooding project in the Taihu Basin, China. There are subpages on background and aims, people and institutions, project implementation, research outcomes and contact details.", "entities": []}
{"id": 4334, "text": "This work utilises large numbers of Agent Based Simulations (ABS) to quantify the collision rate between unconstrained aircraft agents moving between stochastically generated endpoints in straight lines. Each ABS run is used as a sample for a Monte Carlo estimator of the collision rate for a given traffic density with quantified uncertainty.", "entities": []}
{"id": 4335, "text": "UAV mission planning using GIS maps to identify hazards, no fly zones, safety locations and control zones.", "entities": []}
{"id": 4336, "text": "An aerodynamics and vehicle guidance and control toolkit for use in real-time environments such as engineering simulations, games and virtual experiences developed in the Unity environment. Core library is portable to other applications such as Matlab.", "entities": [{"id": 1397, "label": "Software", "start_offset": 134, "end_offset": 153}, {"id": 1399, "label": "Software", "start_offset": 99, "end_offset": 129}]}
{"id": 4337, "text": "This work aims to test correlations between the 3D locations of Near Mid Air Collisions and the traffic conditions in the same area in order to identify future hazardous regions where NMACs are more likely to occur. This provides avenues to improve airspace design for fewer such events.", "entities": []}
{"id": 4338, "text": "The library provides a flexible framework for coding autonomous goal-driven behaviours for drones. It extends an existing behaviour tree library to interface with standard attributes and controls of a drone, via the open-source MAVlink protocol used by numerous open-source autopilots and ground control systems. Available at https://github.com/arthurrichards77/drone_trees", "entities": [{"id": 514, "label": "Software_Url", "start_offset": 325, "end_offset": 373}]}
{"id": 4339, "text": "ADRpy is a free library of aircraft design and performance analysis tools suitable for rapid sizing calculations. The models implemented in ADRpy are largely analytical, enabling fast explorations of large design spaces. Most of the methods can already be used in the earliest phases of the design process, even before a geometry model is built. In fact, ADRpy can serve as the basis of sensitivity analyses and uncertainty quantification (UQ) exercises as part of the analysis of the feasibility of the design requirements.", "entities": [{"id": 740, "label": "Software", "start_offset": 0, "end_offset": 5}, {"id": 741, "label": "Software", "start_offset": 140, "end_offset": 145}, {"id": 742, "label": "Software", "start_offset": 355, "end_offset": 360}]}
{"id": 4340, "text": "This explores the relationships between variables involved in the visual separation aerial environment (AKA See and Avoid). This is a cooperative principle that the vast majority of General Aviation uses in uncontrolled airspace to maintain separation.", "entities": []}
{"id": 4341, "text": "JOSS paper release. Installer carried forward from 0.15.0 as no changes to GUI. What's Changed Updated documentation and fixed wiki links Improved Linux support by @AustinTSchaffer in https://github.com/aliaksei135/seedpod_ground_risk/pull/102 Edits to JOSS paper by @danielskatz in https://github.com/aliaksei135/seedpod_ground_risk/pull/107 New Contributors @AustinTSchaffer made their first contribution in https://github.com/aliaksei135/seedpod_ground_risk/pull/102 @danielskatz made their first contribution in https://github.com/aliaksei135/seedpod_ground_risk/pull/107", "entities": []}
{"id": 4342, "text": "Autoflpy (AUTOmated Flight Log in Python) is an open source code designed to allow the rapid creation of customisable flight test reports. This represents a key element of progress on the 'Agility' dimension of CASCADE, as it is a very useful tool for speeding up the flight test process of a new unmanned aircraft platform.", "entities": [{"id": 1400, "label": "Software", "start_offset": 0, "end_offset": 8}]}
{"id": 4343, "text": "OpenFOAM is a free, open source computational fluid dynamics (CFD) software package released by the OpenFOAM Foundation. It has a large user base across most areas of engineering and science, from both commercial and academic organisations. In this GitHub repository we include codes developed (as an extension to OpenFOAM) for simulating non-continuum fluid dynamics (e.g. mdFoam and dsmcFoam).\n\nThe Micro &amp; Nano Flows (MNF) Group are the original authors of the mdFoam and dsmcFoam applications. This repository provides up to date versions of these applications (name mdFOAM and dsmcFOAM), with the groups most recent developments included along with documentation and new tutorial cases.", "entities": [{"id": 1609, "label": "Software", "start_offset": 0, "end_offset": 8}, {"id": 1610, "label": "Software", "start_offset": 100, "end_offset": 108}, {"id": 1611, "label": "Software", "start_offset": 314, "end_offset": 322}, {"id": 1612, "label": "Software", "start_offset": 575, "end_offset": 581}, {"id": 1613, "label": "Software", "start_offset": 586, "end_offset": 594}, {"id": 1614, "label": "Software", "start_offset": 374, "end_offset": 380}, {"id": 1615, "label": "Software", "start_offset": 385, "end_offset": 393}]}
{"id": 4344, "text": "This package is dedicated to simplifying the cleaning and standardisation of linelist data. Considering a case linelist data.frame, it aims to:\n\n- standardise the variables names, replacing all non-ascii characters with their closest latin equivalent, removing blank spaces and other separators, enforcing lower case capitalisation, and using a single separator between words\n- standardise the labels used in all variables of type character and factor, as above\n- set POSIXct and POSIXlt to Date objects\n- extract dates from a messy variable, automatically detecting formats, allowing inconsistent formats, and dates flanked by other text\n- support data dictionary: linelist objects can store meta-data indicating which columns correspond to standard epidemiological variables, usually found in linelists such as a unique identifier, gender, or dates of onset", "entities": []}
{"id": 4345, "text": "trendeval aims to provide a coherent interface for evaluating models fit with the trending package. Whilst it is useful in an interactive context, it's main focus is to provide an intuitive interface on which other packages can be developed", "entities": [{"id": 743, "label": "Software", "start_offset": 0, "end_offset": 9}]}
{"id": 4346, "text": "{reportfactory} is a R package which facilitates workflows for handling multiple .Rmd reports, compiling one or several reports in one go, and storing outputs in well-organised, timestamped folders.", "entities": [{"id": 945, "label": "Software", "start_offset": 1, "end_offset": 14}]}
{"id": 4347, "text": "The trendbreaker package implements tools for detecting changes in temporal trends of a single response variable. It implements the Automatic Selection of Models and Outlier Detection for Epidemmics (ASMODEE), an algorithm originally designed for detecting changes in COVID-19 case incidence.", "entities": [{"id": 1155, "label": "Software", "start_offset": 4, "end_offset": 16}]}
{"id": 4348, "text": "Save the Children, thanks to RECAP funds, was able to contribute to the running costs of its Dioptra tool, a web-based software that enables staff at humanitarian and development organizations to rapidly estimate the cost-efficiency of their programs, using existing accounting and monitoring data.\n\nDioptra enables staff at humanitarian and development organizations to rapidly estimate the cost-efficiency of their programs, using existing accounting and monitoring data. Having cost-efficiency data, and comparative efficiency data from similar projects can help staff identify opportunities to reach more people and have greater impact with limited resources.", "entities": [{"id": 1401, "label": "Software", "start_offset": 300, "end_offset": 307}]}
{"id": 4349, "text": "incidence2 refocusses the scope of the original incidence package. The aim is to provide a &quot;tidy&quot; interface for users to work with whilst at the same time simplifying the underlying implementation. To this end, incidence2 concentrates only on the initial data handling, calculation and graphing of incidence objects. The &quot;fitting&quot; and &quot;peak estimation&quot; functions of incidence (e.g. incidence::fit and incidence::estimate_peak) are being implemented in an accompanying package called i2extras. Here they will have a more consistent interface, better choice of underlying models, and tidier outputs.", "entities": [{"id": 1616, "label": "Software", "start_offset": 0, "end_offset": 10}, {"id": 1617, "label": "Software", "start_offset": 48, "end_offset": 57}, {"id": 1618, "label": "Software", "start_offset": 221, "end_offset": 231}, {"id": 1619, "label": "Software", "start_offset": 396, "end_offset": 405}, {"id": 1620, "label": "Software", "start_offset": 412, "end_offset": 421}]}
{"id": 4350, "text": "i2extras adds additional functionality to the incidence2 package.", "entities": [{"id": 515, "label": "Software", "start_offset": 0, "end_offset": 8}]}
{"id": 4351, "text": "trending aims to provides a coherent interface to several modelling tools. Whilst it is useful in an interactive context, it's main focus is to provide an intuitive interface on which other packages can be developed", "entities": [{"id": 744, "label": "Software", "start_offset": 0, "end_offset": 8}]}
{"id": 4352, "text": "The VIA suite of tools and List Annotator (LISA) tools are being used for manual annotation of several sign language video datasets.", "entities": [{"id": 946, "label": "Software", "start_offset": 4, "end_offset": 22}, {"id": 947, "label": "Software", "start_offset": 27, "end_offset": 54}]}
{"id": 4353, "text": "The focus of this work is sign spotting-given a video of an isolated sign, our task is to identify whether and where it has been signed in a continuous, co-articulated sign language video. To achieve this sign spotting task, we train a model using multiple types of available supervision by: (1) watching existing sparsely labelled footage; (2) reading associated subtitles (readily available translations of the signed content) which provide additional weak-supervision; (3) looking up words (for which no co-articulated labelled examples are available) in visual sign language dictionaries to enable novel sign spotting.", "entities": []}
{"id": 4354, "text": "Practical Skills for Teaching Inclusive History: CARGO Classroom\nExplore ways to improve the representation of people of African and African diaspora heritage drawing on 5,000 years of history.", "entities": [{"id": 1402, "label": "Software", "start_offset": 49, "end_offset": 64}]}
{"id": 4355, "text": "Instagram account to which is regularly updated", "entities": []}
{"id": 4356, "text": "Bophana Centre has developed an application to educate school students on past violence of the Khmer Rouge History. This project will enable the centre to add videos and train teachers.", "entities": []}
{"id": 4357, "text": "Storytelling application that allows for collaborative storytelling with text pictures and sounds", "entities": [{"id": 745, "label": "Software", "start_offset": 0, "end_offset": 24}]}
{"id": 4358, "text": "Turn based tactics video game released on the Steam platform", "entities": []}
{"id": 4359, "text": "Built upon the BBC SMIL open source framework and object based audio, the android app allows a user to customise their podcast listening experience. This is achieved via an accessibility slider which the user can adjust to select the narrative importance of the audio content. At one end of the scale, all back music, media indents etc will not be played, delivering only important auditory components essential to the narrative (such as voice).", "entities": []}
{"id": 4360, "text": "Allows the authoring of Object-Based Media production, focusing on interactive narratives embodied through recorded video and audio, such as film, TV, radio and podcasts.", "entities": []}
{"id": 4361, "text": "Off-line Matlab model code to automatically detect ocean gyres in the barotropic flow. The code is generic and can be used with netcdf data input stored on NEMO or geographical grids (author Stefanie Rynders).", "entities": []}
{"id": 4362, "text": "A fully coupled global ocean-sea ice-waves model has been developed for the model configuration NEMOv3.6-CICE5-WW3. 2022. Code author: Dr Stefanie Rynders.", "entities": [{"id": 516, "label": "Software", "start_offset": 16, "end_offset": 49}]}
{"id": 4363, "text": "SI3 regional configuration of the Arctic This is a configuration of the NEMO community ocean model based on the ORCA2_SAS_ICE reference configuration. The NEMO code is available from https://forge.nemo-ocean.eu/nemo/nemo. This configuration has a resolution of 1/36 degree and is a cut-out of the global 1/36 configuration: https://github.com/immerse-project/ORCA36-demonstrator. The code base is a pre-4.2.0 NEMO version, the model source code can be found in the file src_tar. Model setup Follow the instructions on https://sites.nemo-ocean.io/user-guide/index.html to download and install the NEMO model version 4.2.0. Swap the src directory for the one in the tar file src_tar. Compile the ORCA2_SAS_ICE reference configuration. Put the rest of the files in this zenodo archive in the EXP00 directory, except the namelist_cfg_for_DOMAINcfg file which goes into tools/DOMAINcfg along with the grid files to be downloaded later. The files provided include example configuration namelist files namelist_cfg and namelist_ice_cfg. The atmospheric forcing used is the Drakkar forcing set (DFS) version 5.2, year 2008. The atmospheric forcing is interpolated on-the-fly, using the weights files. The weights were calculated using the nemo WEIGHTS tool. For the ocean (bottom) boundary the World Ocean Atlas 2018 multidecadal monthly averages are used. The data is already interpolated onto the ARC36 grid. Interpolation was done using the SOSIE tool. Files provided are monthly averages of sea surface salinity and temperature. Finally, the model grid domain_cfg.nc needs to be created. Download the ORCA36 files from ftp://ftp.mercator-ocean.fr/download/users/cbricaud/BENCH-ORCA36-INPUT.tar.gz, see the ORCA36 demonstrator github page. The necessary files are the coordinates and bathymetry files. To cut out the Arctic domain use ncks -F -d y,7000,,1 in.nc out.nc. Put in tools/DOMAINcfg and use the DOMAINcfg NEMO tool to create the domain_cfg.nc file using the file namelist_cfg_for_DOMAINcfg as namelist_cfg. The resulting file is large (122GB) therefore executing in parallel mode is required. The individual processor files need to be merged into one, use the REBUILD_NEMO tool. Put the resulting domain_cfg.nc file into EXP00 and run NEMO following the instructions. The ARC36 configuration was set up and run on ARCHER2 using 594 NEMO processors and 12 XIOS processors.", "entities": [{"id": 748, "label": "Software", "start_offset": 154, "end_offset": 159}, {"id": 749, "label": "Software", "start_offset": 72, "end_offset": 76}, {"id": 750, "label": "Software_Url", "start_offset": 183, "end_offset": 220}, {"id": 751, "label": "Software", "start_offset": 0, "end_offset": 41}, {"id": 752, "label": "Software_Url", "start_offset": 518, "end_offset": 567}, {"id": 754, "label": "Software", "start_offset": 1236, "end_offset": 1248}, {"id": 755, "label": "Software", "start_offset": 871, "end_offset": 880}, {"id": 756, "label": "Software", "start_offset": 2165, "end_offset": 2182}, {"id": 757, "label": "Software", "start_offset": 2240, "end_offset": 2244}]}
{"id": 4364, "text": "Off-line Matlab model code to calculate critical loads and safety limits to navigate in sea ice has been developed in the framework of the new coupled ocean-sea ice-waves NEMO-CICE-WW3 model by Drs Stefanie Rynders and Yevgeny Aksenov (NOC). The model uses inputs from the coupled ocean-sea ice-waves model and applies newly developed dynamical and static ice loads calculations, along with the safety ice navigation limits for different ship classes and critical loads from combined effects from currents and waves. The model is generic and can use netcdf input from any ocean-sea ice-wave models. The model produces timeseries and spatial maps of the loads and maps safety areas for marine operations, including ships navigation and fixed off-shore structures exploitation.", "entities": []}
{"id": 4365, "text": "Python and Matlab diagnostics software to detect polynyas and different ice provinces (Marginal Ice Zone, pack ice, interior open water, etc.) in the model output and satellite data. The detection algorithm takes into account sea ice concentration, thickness and proximity to the coast and position/clustering of information grid cells inside ice zone. \n\nCode authors: Stefanie Rynders and Ben Barton (NOC).", "entities": []}
{"id": 4366, "text": "Ocean mixing modules for the NEMO system model v3.6 and 4.0. distributed under the CeCILL FREE SOFTWARE LICENSE AGREEMENT.", "entities": [{"id": 1403, "label": "Software", "start_offset": 29, "end_offset": 33}]}
{"id": 4367, "text": "2. Off-line pan-Arctic Matlab model code to calculate wave heights, sea ice total area and sea ice extent and coastal erosion by Arctic geographical sectors (Western, Canadian, west Siberian and East Siberian) and in the specified locations. The code is generic and can be used with netcdf data input from wave-ocean models (authors Yevgeny Aksenov and Stefanie Rynders).", "entities": []}
{"id": 4368, "text": "Fortran90 model code to account for the impacts of sea ice fragmentation by waves on sea ice rheology and dynamics. The model has been developed at the National Oceanography Centre by Drs Stefanie Rynders and Yevgeny Aksenov and has been included in the coupled and forced ocean-sea ice-waves NEMO(v3.6/v4.0+)-CICE5-ECMWF-WAM/WW3 configurations.", "entities": [{"id": 517, "label": "Software", "start_offset": 0, "end_offset": 16}]}
{"id": 4369, "text": "Matlab model code and scripts to analyse reversibility of the Arctic and Antarctic sea ice cover in the IPCC CMIP models. The model code has been successfully applied to the CMIP6 set of models ran under the CDR-MIP scenarios with different CO2 emission pathways. The code is generic and can be used with netcdf data input stored on NEMO or geographical grids (author Stefanie Rynders).", "entities": []}
{"id": 4370, "text": "SI3 regional configuration of the Arctic This is a configuration of the NEMO community ocean model based on the ORCA2_SAS_ICE reference configuration. The NEMO code is available from https://forge.nemo-ocean.eu/nemo/nemo. This configuration has a resolution of 1/36 degree and is a cut-out of the global 1/36 configuration: https://github.com/immerse-project/ORCA36-demonstrator. The code base is a pre-4.2.0 NEMO version, the model source code can be found in the file src_tar. Model setup Follow the instructions on https://sites.nemo-ocean.io/user-guide/index.html to download and install the NEMO model version 4.2.0. Swap the src directory for the one in the tar file src_tar. Compile the ORCA2_SAS_ICE reference configuration. Put the rest of the files in this zenodo archive in the EXP00 directory, except the namelist_cfg_for_DOMAINcfg file which goes into tools/DOMAINcfg along with the grid files to be downloaded later. The files provided include example configuration namelist files namelist_cfg and namelist_ice_cfg. The atmospheric forcing used is the Drakkar forcing set (DFS) version 5.2, year 2008. The atmospheric forcing is interpolated on-the-fly, using the weights files. The weights were calculated using the nemo WEIGHTS tool. For the ocean (bottom) boundary the World Ocean Atlas 2018 multidecadal monthly averages are used. The data is already interpolated onto the ARC36 grid. Interpolation was done using the SOSIE tool. Files provided are monthly averages of sea surface salinity and temperature. Finally, the model grid domain_cfg.nc needs to be created. Download the ORCA36 files from ftp://ftp.mercator-ocean.fr/download/users/cbricaud/BENCH-ORCA36-INPUT.tar.gz, see the ORCA36 demonstrator github page. The necessary files are the coordinates and bathymetry files. To cut out the Arctic domain use ncks -F -d y,7000,,1 in.nc out.nc. Put in tools/DOMAINcfg and use the DOMAINcfg NEMO tool to create the domain_cfg.nc file using the file namelist_cfg_for_DOMAINcfg as namelist_cfg. The resulting file is large (122GB) therefore executing in parallel mode is required. The individual processor files need to be merged into one, use the REBUILD_NEMO tool. Put the resulting domain_cfg.nc file into EXP00 and run NEMO following the instructions. The ARC36 configuration was set up and run on ARCHER2 using 594 NEMO processors and 12 XIOS processors. Animation The animation has been created from daily average of sea ice fraction from the 1/36&deg; Arctic NEMO-SI3 model integrations with the EAP rheology. The animation has started on the 00:00 of the 1st January 2008 and carried out through the January. It shows a limited area of the model domain north of Fram Strait. The lower concentrations correspond to the opening leads, with &quot;blurred&quot; leads and some multiple signatures due to ice displacement and data averaging over 1-day periods. Acknowledgements: EU IMMERSE (Grant agreement ID: 821926), NERC APEAR project (NE/R012865/1, NE/R012865/2, #03V01461), part of the Changing Arctic Ocean programme; EU H2020 COMFORT (no. 820989); NERC PRE-MELT (NE/T000546/1), and LTS-S CLASS (NE/R015953/1). ARCHER UK National Supercomputing and JASMIN facilities.", "entities": [{"id": 948, "label": "Software", "start_offset": 72, "end_offset": 76}, {"id": 949, "label": "Software", "start_offset": 155, "end_offset": 159}, {"id": 950, "label": "Software_Url", "start_offset": 183, "end_offset": 220}, {"id": 951, "label": "Software_Url", "start_offset": 324, "end_offset": 378}, {"id": 952, "label": "Software", "start_offset": 409, "end_offset": 414}, {"id": 953, "label": "Software", "start_offset": 596, "end_offset": 600}, {"id": 954, "label": "Software", "start_offset": 834, "end_offset": 843}, {"id": 955, "label": "Software", "start_offset": 2337, "end_offset": 2341}, {"id": 956, "label": "Software", "start_offset": 2240, "end_offset": 2244}, {"id": 957, "label": "Software", "start_offset": 2164, "end_offset": 2177}, {"id": 958, "label": "Software", "start_offset": 1985, "end_offset": 1994}, {"id": 959, "label": "Software", "start_offset": 1878, "end_offset": 1887}, {"id": 960, "label": "Software", "start_offset": 1900, "end_offset": 1919}, {"id": 961, "label": "Software", "start_offset": 1436, "end_offset": 1441}, {"id": 962, "label": "Software", "start_offset": 871, "end_offset": 881}]}
{"id": 4371, "text": "Off-line pan-Arctic Matlab model code of the coastal permafrost erosion has been developed for the framework of the new coupled ocean-sea ice-waves NEMO-CICE-WW3 model at the National Oceanography Centre by Dr Stefanie Rynders. The code is generic and can be used with netcdf data input from wave-ocean models.", "entities": []}
{"id": 4372, "text": "This is a virtual salon training tool. It takes about 30-45 minutes to complete and is designed like a game. It is aimed at hairdressers and they click on different items in the salon such as lights products, taps etc. and each time it will come up with the most sustainable options e.g. ecoheads to reduce water use, LED lights to reduce energy use etc. As they browse they also come across key sustainability concepts and what they mean such as 'carbon footprint'. After each section they are presented with some questions to check they have understood. Once completed, they are emailed a sustainable stylist certificate. Once each salon has had their stylists certified, they are eligible for a sustainable salon certificate.It is a virtual online salon to be used as an online training tool to educate hairdressers and trainees about sustainable hairdressing practices - will form part of sustainable stylist certificate.", "entities": [{"id": 1404, "label": "Software", "start_offset": 10, "end_offset": 37}]}
{"id": 4373, "text": "Web app making available the DECIDE project outputs - showing places of highest recording potential for willdlife, based on the value of records for research and biodiversity monitoring.", "entities": []}
{"id": 4374, "text": "Personalised emails sent to 850 people to provide information about the value of their wildlife recording.", "entities": []}
{"id": 4375, "text": "Linear-scaling density-functional theory code for understanding and predicting the properties of materials from first-principles quantum mechanics.", "entities": [{"id": 758, "label": "Software", "start_offset": 0, "end_offset": 45}]}
{"id": 4376, "text": "The rapid accumulation of continuous paleomagnetic and rock magnetic records acquired from pass-through measurements on superconducting rock magnetometers (SRM) has greatly contributed to our understanding of the paleomagnetic field and paleo-environment. Pass-through measurements are inevitably smoothed and altered by the convolution effect of SRM sensor response, and deconvolution is needed to restore high-resolution paleomagnetic and environmental signals. Although various deconvolution algorithms have been developed, the lack of easy-to-use software has hindered the practical application of deconvolution. Here, we present standalone graphical software UDECON as a convenient tool to perform optimized deconvolution for pass-through paleomagnetic measurements using the algorithm recently developed by Oda and Xuan (Geochem Geophys Geosyst 15:3907-3924, 2014). With the preparation of a format file, UDECON can directly read pass-through paleomagnetic measurement files collected at different laboratories. After the SRM sensor response is determined and loaded to the software, optimized deconvolution can be conducted using two different approaches (i.e., &quot;Grid search&quot; and &quot;Simplex method&quot;) with adjustable initial values or ranges for smoothness, corrections of sample length, and shifts in measurement position. UDECON provides a suite of tools to view conveniently and check various types of original measurement and deconvolution data. Multiple steps of measurement and/or deconvolution data can be compared simultaneously to check the consistency and to guide further deconvolution optimization. Deconvolved data together with the loaded original measurement and SRM sensor response data can be saved and reloaded for further treatment in UDECON. Users can also export the optimized deconvolution data to a text file for analysis in other software.", "entities": [{"id": 963, "label": "Software", "start_offset": 664, "end_offset": 670}, {"id": 964, "label": "Software", "start_offset": 911, "end_offset": 917}, {"id": 965, "label": "Software", "start_offset": 1348, "end_offset": 1354}, {"id": 966, "label": "Software", "start_offset": 1778, "end_offset": 1784}]}
{"id": 4377, "text": "Editor for representation system theory", "entities": []}
{"id": 4378, "text": "web app for building cognitive models", "entities": []}
{"id": 4379, "text": "This R package contains code needed to build species distribution models using ERCCIS species record data: \n\n* including processing environmental data\n* evaluating species records and detecting spatial sampling biases\n* building ensembles of species distribution models\n* mapping results", "entities": []}
{"id": 4380, "text": "An R package for modelling the distribution of marine mammals using Seaquest SouthWest monitoring data. The package contains functions for downloading and processing environmental data and uses a calibrated random forest modelling algorithm to model species encounter rate accounting for covariates that affect species detectability (e.g. sea state, glare, wind strength).", "entities": []}
{"id": 4381, "text": "An online methods course focused on multimodal methodologies for digital and data environments. The MODE VLE will introduce multimodal methods for analysing communication and learning with digital technologies.\n\nThere will be five units of self-supported study that introduce four theoretical perspectives: social action; moving image and film; design, genre and interactivity; and embodied cognition.\n\nIt is recommended that the course is started by completing the induction unit. This section will provide a tutorial on how to navigate the course structure and access the course contents. The introductory unit is optional and recommended for those who are new to multimodal methods or would like a refresher on key concepts and issues. Any of the other units can be selected to further explore topics related to research interests. \n\nUnits 1-5 are organised thematically but can also be explored chronologically for those interested in a full course. Each unit is comprised of key readings, guides, case studies and research resources. See the outline below for further details. \n\nMODE VLE Programme Outline:\nUnit 1: An introduction to multimodal methodologies\nUnit 2: Analysing video recorded face-to-face interaction\nUnit 3: Analysing embodied cognition and interaction with tangible and mobile devices\nUnit 4: Analysing digital text making in digital and online environments\nUnit 5: Analysing moving image and digital film production\n\nEach unit will provide readings, learning resources, key concepts and activities to offer both conceptual and applied understanding of the multimodal methods outlined and the theoretical perspectives explored. Case studies and examples drawn from MODE research will also be available for guided instruction of research conducted in different environments, including hospitals, schools, galleries and online platforms. The technologies we explore include digital video devices, Web 2.0 technologies, and mobile and tangible devices.\n\nParticipants enrolled in this online course have the option to explore all units as an introductory overview or may opt to focus on one or two of the units for more in-depth study of the particular approaches detailed. Videos, visual timelines, transcription banks and glossaries are among the embedded resources in the unit lessons.", "entities": [{"id": 759, "label": "Software", "start_offset": 100, "end_offset": 109}, {"id": 760, "label": "Software", "start_offset": 1084, "end_offset": 1093}]}
{"id": 4382, "text": "Online survey tool, providing opportunity to collate large datasets crucial to understanding public impressions of archaeology.", "entities": []}
{"id": 4383, "text": "Py-ChemShell is the python-based version of the ChemShell multiscale computational chemistry environment, a leading package for combined quantum mechanical/molecular mechanical simulations.", "entities": [{"id": 1156, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 4384, "text": "Py-ChemShell is the python-based version of the ChemShell multiscale computational chemistry environment, a leading package for combined quantum mechanical/molecular mechanical simulations.", "entities": [{"id": 1405, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 4385, "text": "Py-ChemShell is the python-based version of the ChemShell multiscale computational chemistry environment, a leading package for combined quantum mechanical/molecular mechanical simulations.", "entities": [{"id": 1622, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 4386, "text": "Py-ChemShell is the python-based version of the ChemShell multiscale computational chemistry environment, a leading package for combined quantum mechanical/molecular mechanical simulations.", "entities": [{"id": 518, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 4387, "text": "Matlab code related to the article &quot;Weighted network estimation by the use of topological graph metrics&quot; by L. Spyrou &amp; J. Escudero, IEEE Transactions on Network Science and Engineering. Topological metrics of graphs provide a natural way to describe the prominent features of various types of networks. Graph metrics describe the structure and interplay of graph edges and have found applications in many scientific fields. In this work, the use of graph metrics is employed in network estimation by developing optimisation methods that incorporate prior knowledge of a network's topology. The derivatives of graph metrics are used in gradient descent schemes for weighted undirected network denoising, network completion, and network decomposition. The successful performance of our methodology is shown in a number of toy examples and real-world datasets. Most notably, our work establishes a new link between graph theory, network science and optimisation.", "entities": []}
{"id": 4388, "text": "A new app was developed in the form of a game, to investigate whether auditory imagery (hearing music 'in your head') could be trained. Participants had to imagine familiar songs and compare the pitches of two named syllables. The game included three levels of difficulty manipulated by the position of the target syllables in the song. A control task was also developed, which involved a logic game.", "entities": []}
{"id": 4389, "text": "HSIM3 is a major update for HSIM - the simulation software for the Extremely Large Telescope's first light integral field spectrograph HARMONI. HSIM3 is built around a &quot;follow-the-photons&quot; philosophy, so that the various &quot;impacts&quot; of the observation are applied to the input cube in the order in which they would occur in a real observation. For example, atmospheric transmission and atmospheric differential refraction would be applied before the telescope point spread function and both would be applied before the instrument's spectral line spread function. As a result, HSIM3 is more accurate in its simulations (and also more efficient). In addition, HSIM3 incorporates the ability to include detector systematic effects.", "entities": [{"id": 1157, "label": "Software", "start_offset": 0, "end_offset": 5}, {"id": 1158, "label": "Software", "start_offset": 28, "end_offset": 32}, {"id": 1159, "label": "Software", "start_offset": 144, "end_offset": 149}, {"id": 1160, "label": "Software", "start_offset": 594, "end_offset": 599}, {"id": 1161, "label": "Software", "start_offset": 676, "end_offset": 681}]}
{"id": 4390, "text": "This is a Javascript library, written using the Web Audio Framework to enable OpenAir audio data from our online website (www.openairlib.net) to be used more freely in third party applications. The application receives commands from the client-side classes, performs queries on the OpenAIR internal database, formats the data and returns it to the client classes. Ultimately this library enables OpenAIR acoustic data to be easily integrated into other online applications that use the Web Audio Framework.", "entities": []}
{"id": 4391, "text": "Using the Shiny an R package, an online interactive web-based app was created in order to evaluate the level of competence of a participant.", "entities": [{"id": 1623, "label": "Software", "start_offset": 10, "end_offset": 15}]}
{"id": 4392, "text": "Our CCmI tool is available under open-source licence from the CCmI website, and the EPSRC SoundSoftware repository.\nhttp://ccmi.eecs.qmul.ac.uk/downloads\nhttps://code.soundsoftware.ac.uk/projects/ccmieditor/repository", "entities": [{"id": 519, "label": "Software", "start_offset": 4, "end_offset": 13}, {"id": 520, "label": "Software", "start_offset": 62, "end_offset": 74}, {"id": 521, "label": "Software_Url", "start_offset": 116, "end_offset": 153}, {"id": 522, "label": "Software_Url", "start_offset": 154, "end_offset": 217}]}
{"id": 4393, "text": "An API that allows caregivers to triage information related to observations made during facilitation and workshops. Those observations are then related to and relayed through the API in order to 'flag up' observations that may be useful in anticipating care needs.", "entities": []}
{"id": 4394, "text": "See Research Tools and Methods\nR code for implementing a bi-regional cohort-component model for a large set of sub-populations", "entities": []}
{"id": 4395, "text": "This software allows the user to perform protein-ligand binding free energy calculations using advanced Monte Carlo methods, including grand canonical Monte Carlo.", "entities": []}
{"id": 4396, "text": "Software to automate the setup of free energy calculations", "entities": []}
{"id": 4397, "text": "This is a Monte Carlo biomolecular simulation program which has been written and developed by members of my research group over a number of years. The latest release version, 3.0, was co-written in part by the postdoc currently employed under this grant.", "entities": [{"id": 1624, "label": "Software", "start_offset": 10, "end_offset": 53}]}
{"id": 4398, "text": "This software allows for the calculation of protein-ligand binding free energies. This most recent version incorporates our latest work on grand canonical Monte Carlo.", "entities": []}
{"id": 4399, "text": "This software allows grand canonical Monte Carlo calculations to be performed in the OpenMM simulation environment", "entities": []}
{"id": 4400, "text": "A software to simulate the radiation transport through the patient during a radiotherapy treatment, The software uses a new approach based upon novel optical transport methods.", "entities": []}
{"id": 4401, "text": "Automated extraction of single trees from terrestrial lidar point clouds captured in forest environments", "entities": []}
{"id": 4402, "text": "Enables large-scale extraction of individual trees from larger point clouds collected using terrestrial laser scanner data.", "entities": []}
{"id": 4403, "text": "treeseg has been developed to near-automatically segment individual tree point clouds from high-density larger-area lidar point clouds acquired in forests. A formal, albeit somewhat outdated description of the methods can be found in our paper.", "entities": [{"id": 1625, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4404, "text": "New reference database for 16S amplicon sequencing, with a focus on so far unnamed Archaea", "entities": []}
{"id": 4405, "text": "MATAFILER pipeline to process shotgun metagenomics datasets", "entities": [{"id": 761, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 4406, "text": "C++ program to cluster MAGs into de novo species clusters.", "entities": []}
{"id": 4407, "text": "adhesiomeR is a tool to detect adhesion related genes in E. coli genomes. Based on detected genes, an adhesion profile is created.", "entities": [{"id": 1162, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 4408, "text": "This webtool allows to calculate enterosignatures from any uploaded genus table.", "entities": []}
{"id": 4409, "text": "Amplicon sequencing pipeline", "entities": [{"id": 1626, "label": "Software", "start_offset": 0, "end_offset": 28}]}
{"id": 4410, "text": "Model tool able to capture the non-linear distribution of solid-phase electric charge inside the electrodes.", "entities": []}
{"id": 4411, "text": "A user-friendly lithium battery simulator based on open-source CFD", "entities": [{"id": 762, "label": "Software", "start_offset": 2, "end_offset": 41}]}
{"id": 4412, "text": "The package contains functions and data examples for running univariate or multivariate meta-analysis and meta-regression. It is provided within the free software R and downloadable from internet through the R program.", "entities": []}
{"id": 4413, "text": "The package contains functions and data examples for running distributed lag non-linear models. It is provided within the free software R and downloadable from internet through the R program.", "entities": []}
{"id": 4414, "text": "The package contains functions and data examples for running extended meta-analytical models. It is provided within the free software R and downloadable from internet through the R program.", "entities": []}
{"id": 4415, "text": "BASPLib is an open-source library on GitHub, gathering Python and Matlab codes to solve challenging inverse imaging problems in astronomy and medicine. The primary imaging modality of focus is synthesis imaging by interferometry in radio astronomy, with functionality currently being developed for magnetic resonance imaging and ultrasound imaging in medicine.\n\nThe BASPLib software suite gathers implementations of the most advanced computational imaging algorithms at the interface of optimisation and deep learning theories. The proposed algorithms can be seen as intermediate steps in the quest for an ultimate &quot;intelligent&quot; imaging algorithm (yet to be devised) providing the joint precision, robustness, efficiency, and scalability required by modern applications. A key feature on this past is algorithm modularity, with regularisation modules (enforcing image and calibration models) alternating with data-fidelity modules (enforcing consistency with the observed data).\n\nBASPLib algorithms and software are developed at Edinburgh's Biomedical and Astronomical Signal Processing Laboratory (https://basp.site.hw.ac.uk/) headed by Prof. Wiaux.", "entities": [{"id": 1627, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 1628, "label": "Software", "start_offset": 366, "end_offset": 373}, {"id": 1629, "label": "Software", "start_offset": 990, "end_offset": 997}]}
{"id": 4416, "text": "Mining software repositories at a large scale typically requires substantial computational and storage resources. This creates an increasing need for repository mining programs to be executed in a distributed manner, such that remote collaborators can contribute local computational and storage resources. Crossflow is a novel framework for building polyglot distributed repository mining programs. It offers delegation of mining jobs to remote workers and can cache their results. Workers are able to implement advanced behavior like load balancing and rejecting jobs they either cannot perform or would execute sub-optimally. Workers can be written in different programming languages like Java and Python.", "entities": [{"id": 523, "label": "Software", "start_offset": 306, "end_offset": 315}]}
{"id": 4417, "text": "Code implementing models and optimisations described in 2018 Biorxiv preprint. Allows reproduction of figures from paper as well as further exploration of techniques and results.", "entities": []}
{"id": 4418, "text": "Two Android applications supporting the Lego Rovers activity, together with Parent/Teacher Handbooks, Lego Robot build instructions and an Activity Workbook. One application for the LEGO EV3 Home Set and one for the LEGO EV3 Education Set.", "entities": []}
{"id": 4419, "text": "A set of Java classes for a public understanding activity to demonstrate the principles of artificial intelligence programming of robotic systems. This software was used at Cheltenham Science Festival 2015 in the DinoZone and so is themed around Lego Robot Dinosaurs.", "entities": []}
{"id": 4420, "text": "This is a Fortran90 implementation of a semi-empirical potential for Germanium Telluride. The model itself was taken from the literature (10.1088/1367-2630/15/12/123006 ). It was created for use in Monte Carlo simulations of phase change under confinement as part of this project. However this particular model was found to be unsuitable for simulating GeTe interfaces and hence the code has been open-sourced in case other groups find it useful for Monte Carlo simulations of bulk phase change.", "entities": [{"id": 1407, "label": "Software", "start_offset": 40, "end_offset": 88}]}
{"id": 4421, "text": "This repository contains software and two datasets of developing neural crest single cell expression profiling of Danio rerio. Expression profiling was performed in the lab of Prof. Robert Kelsh (Univ. of Bath, https://researchportal.bath.ac.uk/en/persons/robert-kelsh) with the help of the Nanostring nCounter (R) for the inhouse panel of 45 genes (main portion of files in the SourceData folder) and with the TaqMan assay (tables in the Taqman subfolder of the SourceData folder)\n\nThe code in the R directory conducts the analysis and plots Figures for the manuscript accepted to Nature Communications.\n\nTitle: Zebrafish pigment cells develop directly from highly multipotent progenitors. Authors: Tatiana Subkhankulova[1], Karen Camargo Sosa[1], Leonid A. Uroshlev[2], Masataka Nikaido[1,a], Noah Shriever[1], Artem S. Kasianov[2,3,4], Xueyan Yang[1,b], Frederico S. L. M. Rodrigues[1], Thomas J. Carney[1,c], Gemma Bavister[1], Hartmut Schwetlick[5], Jonathan H.P. Dawes[5], Andrea Rocco[6,7], Vsevolod Makeev[2,3,8] and Robert N. Kelsh[*,1]", "entities": [{"id": 1630, "label": "Software", "start_offset": 127, "end_offset": 147}]}
{"id": 4422, "text": "A dual platform Android and iOS app which allows people to log their mood on a validated scale as well as their activities and social interactions within their circle. The data stored in a backend database for analysis by carers/clinicians. Future releases will allow automated detection of patterns leading to low mood so early intervention is possible.", "entities": []}
{"id": 4423, "text": "Apps for Patients and Nurses on the iOS App Store and Android Play Store for in-patients to self-report pain.", "entities": []}
{"id": 4424, "text": "Software to fit the SITAR method to growth curves, submitted as the sitar package to the Comprehensive R Archive Network (CRAN).", "entities": []}
{"id": 4425, "text": "Refinements to the web-based app include: an improved visual layout; amendments to the existing functionality to improve log-in, data entry and importation and results formats. The development of new features and functions include a data filtering option and a new talk time function. Re-worked sociogram functionality includes improved export options to share the results with users in a variety of formats for clinical/research purposes.\n\nRefinements also include a newly developed seven item coding system to improve coding speed and rater reliability.", "entities": []}
{"id": 4426, "text": "This software fits the gravitational potential of galaxies using a new &quot;MNn&quot; expansion. It is publicly available and already finding application in building compact analytic models of our Galaxy.", "entities": []}
{"id": 4427, "text": "This software determines the gravitational potential near the Sun from the phase space distribution of tracer stars. It is available publicly on request.", "entities": []}
{"id": 4428, "text": "This is a python-based software tool for mass-modelling spheroidal galaxies. It is well-tested on a large suite of mock data, including triaxial and tidally stripped galaxies. It can take advantage of split populations or proper motion data, if available. It is currently being used to mass model dwarf galaxies, but can be applied to elliptical galaxies or even galaxy clusters. The software has been publicly released as part of a follow up paper (https://arxiv.org/abs/1911.09124).", "entities": [{"id": 524, "label": "Software_Url", "start_offset": 450, "end_offset": 482}]}
{"id": 4429, "text": "Artifact for the paper: Dynamically Updatable Multiparty Session Protocols", "entities": [{"id": 763, "label": "Software", "start_offset": 24, "end_offset": 74}]}
{"id": 4430, "text": "Artifact for paper: Rollback Recovery in Session-Based Programming", "entities": []}
{"id": 4431, "text": "Artifact for paper: Generic Go to Go: Dictionary-Passing, Monomorphisation, and Hybrid", "entities": []}
{"id": 4432, "text": "Artifact for the paper: Stay Safe Under Panic: Affine Rust Programming with Multiparty Session Types (https://doi.org/10.4230/DARTS.8.2.9)\n\nThis introduces the `multicrusty` library.", "entities": []}
{"id": 4433, "text": "We introduce Teatrino, a toolchain that supports\n handling multiparty protocols with crash-stop fail-\n ures and crash-handling behaviours. Teatrino\n accompanies the novel MPST theory in the related\n article, and enables users to generate fault-tolerant\n protocol-conforming Scala code from Scribble\n protocols. Local types are projected from the global\n protocol, enabling correctness-by-construction, and\n are expressed directly as Scala types via the\n Effpi concurrency library. Teatrino extends both\n Scribble and Effpi with support for crash-stop\n behaviour. The generated Scala code is execut-\n able and can be further integrated with existing\n systems. The accompanying theory in the related\n article guarantees deadlock-freedom and liveness\n properties for failure handling protocols and their\n implementation. This artifact includes examples,\n extended from both session type and distributed\n systems literature, featured in the related article.", "entities": [{"id": 1631, "label": "Software", "start_offset": 13, "end_offset": 21}, {"id": 1632, "label": "Software", "start_offset": 139, "end_offset": 147}, {"id": 1633, "label": "Software", "start_offset": 481, "end_offset": 489}]}
{"id": 4434, "text": "Artifact of the paper: &quot;Deadlock-Free Asynchronous Message Reoerderign in Rust with Multiparty Session Types&quot;, PPoPP 2022.", "entities": []}
{"id": 4435, "text": "Electronic structure code", "entities": []}
{"id": 4436, "text": "A linked database and search solution wrapped in a novel web application. The VSA 1.0 was developed by integrating Documentum with Endeca's (then) state-of-the-art search protocols (Guided Navigation) that brings the capabilities of online retail search environments to the challenge of accessing seismic data and interpretations. This went live in 2008. In 2014 we recommissioned and launched VSA 2.0 - using open source components. In both cases the VSA has been build in collaboration with our partners Blue Fish (in Austin, Texas).", "entities": [{"id": 967, "label": "Software", "start_offset": 78, "end_offset": 82}, {"id": 968, "label": "Software", "start_offset": 394, "end_offset": 397}, {"id": 969, "label": "Software", "start_offset": 451, "end_offset": 455}]}
{"id": 4437, "text": "Calculates the time evolution of plasma in the edge of fusion devices, including the flow of heat along magnetic field lines to the walls of the device.", "entities": []}
{"id": 4438, "text": "Firedrake is an automated system for the portable solution of partial differential equations using the finite element method (FEM). Firedrake enables users to employ a wide range of discretisations to an infinite variety of PDEs and employ either conventional CPUs or GPUs to obtain the solution.", "entities": [{"id": 1408, "label": "Software", "start_offset": 0, "end_offset": 9}, {"id": 1409, "label": "Software", "start_offset": 132, "end_offset": 141}]}
{"id": 4439, "text": "Bayesian methods for the detection of differences in rates of outcomes for multiple treatments for clustered observations. This software was developed for the Risk Prediction in Pharmacoepidemology project as part of a Rutherford Fund Fellowship at Health Data Research (UK), HRDUK@Scotland.", "entities": []}
{"id": 4440, "text": "The ACHIMULATOR provides a surrogate tool for conducting FLAC model experiments of cutting slope deterioration, in order to support calculations for determining slope performance.\n\nIt is a Gaussian process emulator, developed within the ACHILLES consortium. The application can predict a cutting's time to failure (TTF), factor of safety (FOS), and failure area, in less time and with less expense than FLAC model experiments. The tool enables users to obtain earthwork deterioration diagnostics for specific values of geometry and soil strength. Parameter estimation is done using Bayesian inference.\n\nThe methodology is adapted from Svalova, A., Helm, P., Prangle, D., Rouainia, M., Glendinning, S., Wilkinson, D. (2021), DCE, 2, E12. doi:10.1017/dce.2021.14. Whilst the tool is currently available online (URL provided), work to refine the emulator is on-going.", "entities": [{"id": 525, "label": "Software", "start_offset": 3, "end_offset": 15}]}
{"id": 4441, "text": "This is a repository for the code used in emulating computer experiments of deterioration of infrastructure slopes. The CodeExample RMarkdown and PDF files provide R code to reproduce the results in the file FULLsqM5N.rdsThe data required to compile the CodeExample.rmd file can be found in (DOI) https://doi.org/10.25405/data.ncl.14331314", "entities": [{"id": 764, "label": "Software", "start_offset": 254, "end_offset": 265}, {"id": 765, "label": "Software", "start_offset": 120, "end_offset": 131}]}
{"id": 4442, "text": "See https://s2lab.kcl.ac.uk/projects/tesseract/", "entities": [{"id": 970, "label": "Software_Url", "start_offset": 4, "end_offset": 47}]}
{"id": 4443, "text": "Reformulation of adversarial ML attacks in the problem space; end-to-end adversarial examples generation for Android", "entities": []}
{"id": 4444, "text": "See https://s2lab.kcl.ac.uk/papers/files/usenixsec2017.pdf", "entities": []}
{"id": 4445, "text": "OpenFOAM is a free, open source computational fluid dynamics (CFD) software package released by the OpenFOAM Foundation. It has a large user base across most areas of engineering and science, from both commercial and academic organisations. In this GitHub repository we include codes developed (as an extension to OpenFOAM) for simulating non-continuum fluid dynamics (e.g. mdFoam and dsmcFoam).\n\nThe Micro &amp; Nano Flows (MNF) Group are the original authors of the mdFoam and dsmcFoam applications. This repository provides up to date versions of these applications (name mdFOAM and dsmcFOAM), with the groups most recent developments included along with documentation and new tutorial cases.", "entities": [{"id": 1634, "label": "Software", "start_offset": 0, "end_offset": 8}, {"id": 1635, "label": "Software", "start_offset": 575, "end_offset": 581}, {"id": 1636, "label": "Software", "start_offset": 586, "end_offset": 594}, {"id": 1637, "label": "Software", "start_offset": 374, "end_offset": 380}, {"id": 1638, "label": "Software", "start_offset": 385, "end_offset": 393}, {"id": 1639, "label": "Software", "start_offset": 314, "end_offset": 322}]}
{"id": 4446, "text": "The Temperature Calendar is a web-based visualization of temperature variation within a building over the course of the past week. It is designed mainly for the workplace, and it highlights deviation from organizational temperature policy, with the aim to bring staff &quot;into the loop&quot; of understanding and managing heating, and so reduce energy waste. The Temperature Calendar was conceived as a public display, to be installed in a shared area of a non-domestic building (e.g. an office kitchenette).", "entities": [{"id": 526, "label": "Software", "start_offset": 0, "end_offset": 25}, {"id": 527, "label": "Software", "start_offset": 361, "end_offset": 385}]}
{"id": 4447, "text": "The software consists of packages written in python language to extract and analyze the time-resolved high-resolution spectroscopy of statistically-significant samples of stars. The code is still under development, but we have so far developed the part that allows us to extract the spectra, identify and fit the lines. The entire code is expected to be completed and publicly released by the end of the project.", "entities": []}
{"id": 4448, "text": "Jupyter notebook to generate periodograms for light curve data from the HOYS citizen science project. It is an interactive code that allows to read the light curves of variable stars and to extract and check the period.", "entities": []}
{"id": 4449, "text": "Graphical User Interface (GUI) for processing and analysing hologram data. Provides a non-specialist-friendly interface to the Pym software package that pre-processes and reconstructs holographic data.", "entities": []}
{"id": 4450, "text": "Project partner development of circadian analysis tool for determining effects of stress partially influenced by CoMeHere study on student stress, now being deployed to over 5000 employees in pharma and advertising companies in London and Australian cities, as well as New York.", "entities": [{"id": 1411, "label": "Software", "start_offset": 31, "end_offset": 54}]}
{"id": 4451, "text": "Matlab toolbox for Uncertainty Estimation with example workflows", "entities": []}
{"id": 4452, "text": "Model code of the supraglacial hydrology model. In the file running_instruction(1).txt, we give the steps about compiling and running the fortran coded part of the hydrology model. In the file, running_lake_refreezing_module.txt, we give the steps that should be followed in order to run the matlab coded part of the hydrology model. In README.txt, we give the role and description of all the code files (both fortran-coded as well as matlab-coded)", "entities": [{"id": 528, "label": "Software", "start_offset": 18, "end_offset": 46}]}
{"id": 4453, "text": "Collection of web applications for the internal operations of a DNA assembly Foundry. Leveraging on the computational software of the Edinburgh Genome Foundry, Smart provides user interfaces for order processing (validation of the order, cloning simulation, automatic enzyme selection, robotic files generation) and sample management (creating/moving/updating microplates in the sample manager, or batch-uploading new parts to the foundry's repository)", "entities": []}
{"id": 4454, "text": "An advanced cloning simulator for restriction-based assembly operations (Golden Gate, BASIC), allowing for sequence prediction, automatic part linker selection, assembly troubleshooting, etc.", "entities": []}
{"id": 4455, "text": "Simple library to plot and highlight DNA design", "entities": []}
{"id": 4456, "text": "Python library (and associated web app in CUBA) to generate human-friendly icons representing sequences in an unambigous way: if two sequences have the same icon, they are certainly the same sequence.", "entities": []}
{"id": 4457, "text": "Small Python library providing codon optimization tables for virtually any species, either via built-in data tables, or by automatically downloading the table corresponding to a given TaxID from the internet (http://www.kazusa.or.jp)", "entities": []}
{"id": 4458, "text": "In-progress web application for Computer-Aided-Design of genetic constructs, with integrated ordering to the Edinburgh Genome Foundry. The application allows to manage genetic parts for different leading assembly standards (MoClo, EMMA, etc.), to browse the parts repository of the EGF and other users, and to design constructs from these parts, and to send the order to the EGF.", "entities": []}
{"id": 4459, "text": "Primavera is a framework for primer-based DNA assembly verification (Sanger sequencing and PCR validation). Given a batch of assemblies, Primavera can generate an optimal set of primers to verify the constructs, leveraging on already-available primers. Primavera can also be used to create easy-to-read validation reports from Sanger sequencing data.", "entities": [{"id": 766, "label": "Software", "start_offset": 0, "end_offset": 9}, {"id": 767, "label": "Software", "start_offset": 137, "end_offset": 146}, {"id": 768, "label": "Software", "start_offset": 253, "end_offset": 262}]}
{"id": 4460, "text": "Genome Collector (full documentation here) is a Python library to download and manage reference genome data for specific TaxIDs, in particular nucleotide and protein sequences (in fasta/genbank/gff formats), and alignment databases (BLAST, Bowtie1/2).\n\nThe data is downloaded automatically on a need-to basis, making it very easy for Python projects to use and re-use reference genomes of E. coli, S. cerevisiae, and so on, without the worry of manually downloading from NCBI.", "entities": [{"id": 972, "label": "Software", "start_offset": 0, "end_offset": 16}]}
{"id": 4461, "text": "BandWitch is fragment analysis framework. Given a batch of assemblies, BandWitch will suggest the best enzymatic digestion to create easily-interpretable patterns for all constructs. Then, when the constructs have been experimentally digested and migrated, BandWitch provides methods to validated the batch and generate informative reports indicating which constructs are structurally correct, and helping to troubleshoot constructs with invalid band patterns.", "entities": [{"id": 1165, "label": "Software", "start_offset": 0, "end_offset": 9}, {"id": 1166, "label": "Software", "start_offset": 71, "end_offset": 80}, {"id": 1167, "label": "Software", "start_offset": 257, "end_offset": 266}]}
{"id": 4462, "text": "A library to find collections of compatible overhangs for Type-2S restriction-based assembly.", "entities": []}
{"id": 4463, "text": "A flexible, extensible Python library to optimize nucleotide sequences with respect to constraints and objectives.", "entities": []}
{"id": 4464, "text": "Genedom is a python library for managing the domestication of genetic parts (i.e. the modification of their sequence so as to make them compatible with a given genetic assembly standard). Genedom binds together a sequence optimizer, genetic standards informations, and a reporting routines, to automate the domestication of large batches in an easy and human-friendly way.", "entities": [{"id": 529, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 530, "label": "Software", "start_offset": 188, "end_offset": 195}]}
{"id": 4465, "text": "Small Python library (and associated web app on CUBA) to design sequences with compact arrays of restriction sites.", "entities": []}
{"id": 4466, "text": "Collection of parsers and file generators to interface with Biolab automation robots. Plateo enables to parse and write microplate data for differents robots. It also allows to parse, write, and simulate liquid transfer picklists for different robots. As of February 2018 Plateo counts 10 different parsers, and 10 different file generators, and is regularly being expanded.", "entities": [{"id": 973, "label": "Software", "start_offset": 85, "end_offset": 92}, {"id": 974, "label": "Software", "start_offset": 272, "end_offset": 278}]}
{"id": 4467, "text": "Python library (also usable via a web application on CUBA) to convert DNA sequences specified in Microsoft Word documents (such as .doc and .docx) into GENBANK or FASTA format", "entities": []}
{"id": 4468, "text": "Blabel is a python library to programmaticaly generate labels (typically for printing stickers) with barcodes and other dsplays", "entities": [{"id": 1412, "label": "Software", "start_offset": 0, "end_offset": 6}]}
{"id": 4469, "text": "Collection of useful biological apps open to the general public to use (no registration required). The website counts currently 13 applications for software-assisted design, manufacturing and validation of DNA constructs.", "entities": []}
{"id": 4470, "text": "Pathogenicity screening framework implementing the protocol of the International Gene Synthesis Consortium (BLAST search against databases of blacklisted agents)", "entities": [{"id": 532, "label": "Software", "start_offset": 0, "end_offset": 33}]}
{"id": 4471, "text": "Server and network configuration allowing to transfer files from or to different computers of the Edinburgh Genome Foundry (and in particular robot computers) in a friendly, safe, and traceable way.", "entities": []}
{"id": 4472, "text": "Python library to communicate with the JBEI-ICE DNA sequence manager.", "entities": []}
{"id": 4473, "text": "Saboteurs is a Python library (and associated web app) to detect failure-causing elements from success/failure data. In particular it can use logical and statistical methods to identify genetic parts associated with assembly failure.", "entities": [{"id": 1168, "label": "Software", "start_offset": 0, "end_offset": 9}]}
{"id": 4474, "text": "A library to plot sequence annotations (e.g. from Genbank) in a flexible and customizable way, with export to various image formats.", "entities": []}
{"id": 4475, "text": "Simple Python API for the Kappa simulation framework. Topkappy enables to represent chemical agents (e.g. DNA fragments) and interactions (e.g. ligation) in a programmatic way, making it possible to define and simulate complex problems with hundreds of agents and interactions.", "entities": [{"id": 1641, "label": "Software", "start_offset": 26, "end_offset": 52}]}
{"id": 4476, "text": "Experimental computational software to predict the difficulty of a DNA assembly using Golden-Gate like standards: given a set of parts to assemble, Kappagate will run a simulation to predict which proportion of the final clones will contain the right version of the DNA assembly. From this prediction, Kappagate can inform the experimentalist of how many clones they should pick", "entities": [{"id": 533, "label": "Software", "start_offset": 148, "end_offset": 158}, {"id": 534, "label": "Software", "start_offset": 302, "end_offset": 311}]}
{"id": 4477, "text": "Simple library to display genetic designs using the SBOL Visual language", "entities": []}
{"id": 4478, "text": "Customer front of the Edinburgh Genome Foundry, with informations on the Foundry's services, products, software efforts, team, and contact details. the website also features an interactive strain ordering application.", "entities": []}
{"id": 4479, "text": "The software accompanies the paper, currently under review, &quot;Subset simulation for probabilistic computer models&quot;. It is a result of the work done by postdoctoral researcher Petar Hristov and PI Alejandro Diaz, for the EPSRC-funded project \nDATA-CENTRIC: Developing AccounTAble Computational ENgineering Through Robust InferenCe.", "entities": []}
{"id": 4480, "text": "Software to convert between CT scan images and CAD drawing packages to that which can be printed by a 3D printer.", "entities": []}
{"id": 4481, "text": "Trenchcoat is a software tool to optimise trenching routes for a complex data / power network. optimisation is against cost and system complexity. The software optimises the trenching routes subject to fixed nodal points which must be served by the different networks and takes into account geographic and other constraints (e.g. land ownership, cost of access, cost of digging or other costs).", "entities": [{"id": 1642, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 4482, "text": "The Costing Tool is a software tool to facilitate the costing by a team of engineers of a large project. It implements model based and component-based costing methodologies and enables cost models as well as cost estimates to be made. The tool is used by the SKA Organisation for developing the cost estimates of SKA Phase 1.", "entities": [{"id": 535, "label": "Software", "start_offset": 0, "end_offset": 16}]}
{"id": 4483, "text": "ImageJ plugin to monitor daughter cell size in 3 dimensions during cytokinesis.", "entities": [{"id": 769, "label": "Software", "start_offset": 0, "end_offset": 13}]}
{"id": 4484, "text": "Software for cell segmentation and extraction of cortical linescans for the measurement of cortical thickness.", "entities": []}
{"id": 4485, "text": "Software embeds our method for predicting entropic allostery in proteins by building and analysing Elastic Network Models of their structure as posted on the PDB.", "entities": [{"id": 1169, "label": "Software", "start_offset": 99, "end_offset": 121}]}
{"id": 4486, "text": "The software is code that has been developed for gender bias mitigation in biased text", "entities": []}
{"id": 4487, "text": "This is the link to our website and the website have all the code that link to each project papers: https://bias-ua-2023.github.io/\nBelow are the separate links for each project:\nhttps://github.com/Lei-Ding07/Word_Debias_DeSIR\nhttps://github.com/Lei-Ding07/Conformal_Quantile_Fairness\nhttps://github.com/Shenggang/Text_Bias_Reduction_public\n\nAnd for the website for bias text analysis, you can use the following link: http://142.244.185.74:8899", "entities": [{"id": 1643, "label": "Software_Url", "start_offset": 179, "end_offset": 226}, {"id": 1644, "label": "Software_Url", "start_offset": 100, "end_offset": 131}, {"id": 1645, "label": "Software_Url", "start_offset": 227, "end_offset": 284}, {"id": 1646, "label": "Software_Url", "start_offset": 285, "end_offset": 340}]}
{"id": 4488, "text": "Fabric dynamic friction process never repeats themselves for identical fabrics. The characteristics of stick-slip events in the dynamic friction process provide a fabric's unique surface encoding. In this study, the fabric surface characteristics are generated in the fabric-to-fabric self-friction process, A novel strategy to extract fabric stick-slip features through time-frequency spectrum analysis is proposed. The fabric stick-slip properties were characterized by using the Hjorth parameters which were previously employed for tactile signal processing. The characteristics of stick-slip properties were obtained from the statistical analysis of Hjorth parameters and later analyzed for their entropy, fractal dimension, self-similarity and complex nature of the fabric-fabric friction.", "entities": []}
{"id": 4489, "text": "The software was developed with AkzoNobel and performs a machine-learning algorithm that ensures that the resultant clusters are as different as possible. This addresses the problem with conventional k-means clustering where the centroids or clusters selected are too similar to each other. When applied to colour images to extract key colours automatically, the result of this new algorithm is a colour palette that is more representative of the image; it ensures that colours that may be visually salient but represented in the image by relatively few pixels will still appear in the extracted colour palette.", "entities": []}
{"id": 4490, "text": "In this project, we developed a group of Machine Learning models using LUFHES fabric tactile indices and extracted surface textual properties, after trained by a specific &quot;Golden Hand&quot;, to mimic their decision-making process in determining their fabrics' touch feel preference to the fabrics. &quot;Golden Hand&quot; are referred to the experienced, and skilled designers, buyers and technologists, who carry out subjective evaluation on the fabric's aesthetical properties in order to alter the fabrics design and finishing process to target consumers' needs. This expertise is highly personal, experience-dependent, non-transferrable and unable to be elaborated.", "entities": []}
{"id": 4491, "text": "Long-short-term memory (LSTM) is an artificial neural network having the capacity of learning sequences of time-series data are used in varieties of classification and time-series prediction problems. A prediction scenario is modelled and implemented using sequence-to-sequence topology where the input and output dynamic friction sequences are mapped sequentially to predict the following stick-slip events. The elements of the time-series dynamic friction sequence are dependent on each other, where a more advanced neural network model equipped with memory units are needed to constitute the internal relationship between the elements of such time-series data.", "entities": []}
{"id": 4492, "text": "A predictive Software was designed to help the business at WTJohnson to determine the finishing processes for delivering specific fabric tactile characteristic outcomes. The Software is accompanied by an expanding repository of objective tactile properties and inbuilt automated feature generating modules. The data repository is directly linked with the Software for performing new trainings and predictions. The data were collected using Leeds University Fabric Handle Evaluation System (LUFHES) as a part of the project. The predictive model employs machine learning algorithms for performing required tasks, assisting the finishing procedures at WT Johnson.", "entities": []}
{"id": 4493, "text": "The construction of the ranking model connects the manufacturers, customers, and designers' aesthetical tactile requirements of garments with the objective fabric tactile properties measured by LUFHES; where the prediction of the scoring of different aesthetical criteria of an arbitrary group of fabrics are tailored to the subjects' tactile needs.", "entities": []}
{"id": 4494, "text": "The human hand contact with various fabric surfaces and textures through different modes of touch, namely, sliding, grasping, routing, tapping, and pressing. A realistic interaction with fabrics in virtual spaces should take into account the dynamics of fabric handle during the evaluation process. This accounts to sending the appropriate force feedback to the interacting hand using Ultrahaptics emitters. Rooted in robotics technologies, a system framework is obtained for simulating the various modes of touch using hand parameters. The designed system is compatible with Ultrahaptics technology.", "entities": []}
{"id": 4495, "text": "Stick-slip process are frequently observed in various fabric dynamic friction processes employed in both subjective and objective evaluation of fabric surface tactile properties. It is a dynamic friction process in which the friction force and speed vary abruptly within a short period of time to show phases of gripping and sliding patterns happening within a variety of spatiotemporal intervals, During stick-slip friction process, fabrics show a greater deal of interaction in regular/irregular intervals or sometimes at the beginning of the friction process, could be featured by its associated frequency and duration of the stick/slip events. A novel strategy to extract fabric stick-slip features through time-frequency spectrum analysis, is proposed and applied in the algorithmic tool. The fabric stick-slip properties were characterised by using the Hjorth parameters which were previously employed for tactile signal processing in robotic applications.", "entities": []}
{"id": 4496, "text": "The data are gathered from a large number of fabrics using LUFHES and by mechanically deforming the fabrics during the compression and shearing experiments. The deformations are simulated using the spring-damper models, where the relevant parameters are extracted for each fabric.", "entities": [{"id": 975, "label": "Software", "start_offset": 197, "end_offset": 218}]}
{"id": 4497, "text": "An online tool has been developed that enables user to check their colour vision. Traditionally this is done with a physical test such as the Munsell 100-hue test. Use of this physical test is expensive since it often involves travel. The online test allows employees to check the level of their colour discrimination from their own desktop computer. High levels of colour discrimination are required by many manufacturers for employees who are responsible for making visual assessments of produced goods.", "entities": []}
{"id": 4498, "text": "A front-end for the models and architecture developed in the Cloud Manufacturing project, the platform guides users through either the process of offering manufacturing capability or defining a product to be manufactured in the cloud. For manufacturers, the platform guides the user through the process of defining their manufacturing capabilities, and abstracting and combing them into a formally defined and advertisable form. For customers, it guides the user through the process of defining the process steps required to manufacture a product such that the requirements can be matched to available capabilities. The platform also features a prototype implementation of the model and matching algorithms to match proposed products to one or more manufacturers, and hence validate the process.", "entities": []}
{"id": 4499, "text": "Some of the research outputs have been integrated into https://github.com/zhiweiuu/secs", "entities": [{"id": 1647, "label": "Software_Url", "start_offset": 55, "end_offset": 87}]}
{"id": 4500, "text": "The Clash description of the Heron processor is available as open source software.\n\nThe software source code for the Heron architecture presented in our accepted IFL 2023 paper.", "entities": [{"id": 536, "label": "Software", "start_offset": 117, "end_offset": 135}]}
{"id": 4501, "text": "A set of designs and wireframes for the Observatory user interface, comprising pages for View a record, Search, Search Results, Filtering, Home, About, T&amp;Cs.", "entities": []}
{"id": 4502, "text": "A prototype for the OHOS output &quot;the Observatory&quot; so that users can access community generated enriched metadata. The user interface enables users to view, search, and filter community generated digital data.", "entities": [{"id": 976, "label": "Software", "start_offset": 38, "end_offset": 53}]}
{"id": 4503, "text": "A set of designs and wireframes for data visualisations for the Remixer. 1. A map visualisation showing the distribution and aggregation of location of CGDC data 2. A histogram visualisation to show the frequency and distribution of dates in CGDC data. 3. A frequency view of named entities extracted by the AI Lab's NLP pipeline", "entities": []}
{"id": 4504, "text": "Script and graphical user interface used to digitally unroll three-dimensional representations (stack of images) of deformed tubes of non-unifrom thickness. I use this to digitally unroll X-ray micro-computed tomographic scans of murine colons and study their structure. The software is written in Jython and it is tightly linked to ImageJ.", "entities": []}
{"id": 4505, "text": "It takes a binary image stack of branching structures such as the colonic crypts and quantifies key topological and morphological characteristics. I use this to quantify the branching crypts in micro-computed tomographic image stacks of murine colons with early-stage colorectal cancer. It can, however, be used for other structures with similar topologies, such as the airways in the lung.", "entities": []}
{"id": 4506, "text": "The laboratory continues to develop and refine software/hardware tools for data acquisition and analysis relevant to electrophysiology, single-cell imaging and analysis. These activities are long-standing and open-ended, and develop in line with the current research activities and needs of the laboratory. All software and related packages are made freely available to the research community through the laboratory website at psrg.org.uk", "entities": []}
{"id": 4507, "text": "A suite of software that allows time resolved analysis of large stacks of images but also including a novel method for creating and analysing super-resolution images from structured illumination microscopy", "entities": []}
{"id": 4508, "text": "A suite of software that allows the control of imaging equipment including cameras, light sources, digital RF synthesisers, microscopes and scanning devices", "entities": []}
{"id": 4509, "text": "A driver that allows control of a radiofrequency digital synthesiser for control of acousto-optic devices", "entities": []}
{"id": 4510, "text": "This is a set of codes for history matching for climate models and is currently used by developers of the French model and being tested by developers of the Canadian model. The codes produce robust emulators, history matching and imaging and contain the methods developed in papers that have spun out of my fellowship award.", "entities": []}
{"id": 4511, "text": "Overview\n\nThis folder contains a generic MATLAB code to obtain trends in power system failures reported to NaFIRS and the Met Office set of weather patterns by season in the UK. It is divided in 4 parts described as follows:\n\n\n\nPart 1 obtains weather-induced power system failures and daily weather patterns by season.\n\nPart 2 obtains trends in weather patterns and weather induced power system failures a few days before a power system failure occurs.\n\nPart 3 generates 2-D histograms showing the frequency of power system failures caused by specific weather phenomena by weather pattern and season.\n\nPart 4 generates Sankey diagrams showing the strength of trends in weather patterns and power system failures caused by specific weather phenomena by season.\n\n\nLicense and use permissions\n\nThe code available through 10.5281/zenodo.10476553 is licensed as Creative Commons Attribution 4.0 International (CC BY 4.0), meaning you are free to copy, redistribute and adapt them, provided you give appropriate credit. Note that the code is made available as-is and without warranty. We cannot guarantee its accuracy, and accept no responsibility for any liability arising from its use. You are advised to examine the quality of the code for your intended purposes, and to consult the publications linked on this page.\n\nAttribution\n\nPlease cite the paper describing our methods [1] and, if possible, link to 10.5281/zenodo.10476553.\n\n[1] Souto, L., Neal, R., Pope, J. O., Gonzalez, P. L. M., Wilkinson, J., Taylor, P. C. (2024): &quot; Identification of weather patterns and transitions likely to cause power outages in the United Kingdom&quot;, Nature Communications Earth &amp; Environment, DOI: 10.1038/s43247-024-01217-w.", "entities": [{"id": 1648, "label": "Software_Url", "start_offset": 818, "end_offset": 841}]}
{"id": 4512, "text": "The software is a computational implementation of a conceptual model of quality of life synthesised from different existing sources. The underpinning model defines 75 different types of quality of life goal of people living with dementia, and how these types of goal are associated. These 75 quality of goal types are associated to almost 900 different types of meaningful activity that, if undertaken effectively, contribute towards the achievement of the quality of life goals. The model can be instantiated for different people living with dementia, with other chronic conditions, and for older people without health problems. Different values can be propagated through the model, so that the model can generate: 1) recommended alternative quality of life goals with which to achieve the same outcomes; 2) recommended meaningful activities to achieve preferred quality of life goals; 3) quality of life goal types that current activities do not impact.", "entities": []}
{"id": 4513, "text": "This interactive software, optimised for use on tablet devices, has been developed for use by older people with and without cognitive impairments. The planner enables a person and his or her carer and relatives to explore and prioritise quality of life preferences, use these preferences to explore different types of meaningful activity related to achieving these life preferences, access information about concrete instances of these services, and develop a simple visual life plan. This plan can then be verified, critiqued and shared with others. The plan can also be used to monitor progress towards the regular achievement of different quality of life preferences in the plan.", "entities": []}
{"id": 4514, "text": "botok_tokenizer.py is a tokenization (word segmentation) utility for Tibetan, based on BoTok, a tokenizer developed by OpenPecha. botok_tokenizer.py allows you to point to a whole folder/directory or to a single .txt file. It selects just the tokenizer element of Botok, rather than Botok's POS tagger element, which we have not incldued in this utility.\n\nbotok_tokenizer.py was developed by James Engels of SOAS University of London for the Divergent Discourses project. The project is a joint study involving SOAS University of London and Leipzig University, funded by the AHRC in the UK and the DFG in Germany. &nbsp;Please acknowledge the project in any use of these materials. Copyright for the project resides with the two univerisities.", "entities": [{"id": 977, "label": "Software", "start_offset": 0, "end_offset": 18}, {"id": 978, "label": "Software", "start_offset": 130, "end_offset": 148}, {"id": 979, "label": "Software", "start_offset": 356, "end_offset": 374}]}
{"id": 4515, "text": "This utility accepts Transkribus PageXML as input and then interprets the text regions on each page/image (such as headers, titles, blocks of text, etc.) as &quot;paragraphs&quot; and returns the raw text of each paragraph along with its metadata.\n\nParagraph Extractor was developed by James Engels of SOAS University of London for the Divergent Discourses&nbsp;project. The project is a joint study involving SOAS University of London and Leipzig University, funded by the AHRC in the UK and the DFG in Germany.\n\nPlease acknowledge the project in any use of these materials. Copyright for the project resides with the two univerisities.", "entities": [{"id": 1171, "label": "Software", "start_offset": 249, "end_offset": 268}]}
{"id": 4516, "text": "TibNorm is a utility for producing normalised versions of Tibetan texts to make them easier for contemporary users to search and read, in line with current Tibetan writing conventions. As part of the normalisation process, TibNorm:\n\n+ changes Tibetan numbers into Arabic numerals\n+ changes Tibetan brackets and quotation marks into the standard western equivalents\n+ removes a ? if found after a ?, ? or ?, with or without a vowel - adds a ? between ? and ?\n+ reduces two or more ? to a single one\n+ changes ?? or ?? to ??? unless preceded by a white space, tab, or new line\n+ changes non-standard &quot;illegal&quot; stacks into standard ones\n+ deletes a ? if found at the beginning of a line\n\nTibNorm also expands abbreviations so that they are shown in their full form. For abbreviations in classical Tibetan, TibNorm draws from the list of over 6,000 classical Tibetan abbreviations compiled by Bruno Lain&eacute; of the Tibetan Manuscript Project Vienna (TMPV) as part of the project's Resources for Kanjur and Tanjur Studies. In TibNorm, the user can manually change the flag in the abbreviations table to exclude any abbreviation that they don't want to expand.\n\nCitation: Kyogoku, Yuki, Robbie Barnett, Franz Xaver Erhard and Nathan Hill. (2024). TibNorm - Normaliser for Tibetan (Version v1). Zenodo. https://doi.org/10.5281/zenodo.10806456", "entities": [{"id": 1413, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 1414, "label": "Software", "start_offset": 223, "end_offset": 230}, {"id": 1415, "label": "Software", "start_offset": 695, "end_offset": 702}, {"id": 1416, "label": "Software", "start_offset": 813, "end_offset": 820}, {"id": 1417, "label": "Software", "start_offset": 1255, "end_offset": 1262}, {"id": 1418, "label": "Software", "start_offset": 1035, "end_offset": 1042}]}
{"id": 4517, "text": "The Community Strengths Data Archive contains detailed descriptions of the procedures, data and ongoing work using neighbourhood data to capture and understand the E-Risk Study members' behaviour, mental health and physical health. This electronic data archive was created to facilitate the safe and effective use of community level data among the research team. A brief presentation describing the type of data archived as part of this project can be found here: http://prezi.com/lo2eqvsgsock/?utm_campaign=share&amp;utm_medium=copy&amp;rc=ex0share", "entities": [{"id": 1649, "label": "Software", "start_offset": 4, "end_offset": 36}]}
{"id": 4518, "text": "The Grassroots free-text search engine, based upon Lucene, allows us to give ranked, faceted results for various types of field trial data. Each facet automatically weights searches for its specific fields. For example, queries that match study names get ranked higher than those that match queries in their description field instead. This is used for general searches as well as a specific faceted search applications such as the one we have for Measured Variables to denote phenotypic data.", "entities": [{"id": 538, "label": "Software", "start_offset": 0, "end_offset": 38}]}
{"id": 4519, "text": "This is a search service querying and mapping clusters to genes for sequence data", "entities": []}
{"id": 4520, "text": "This is a web service that uses the Grassroots Field Trial service and adds a Breeding API (BrAPI) layer on top to allow other BrAPI-compliant software to access the field trial data. We currently have complete support for approximately a third of BrAPI classes and calls with partial support for others.", "entities": []}
{"id": 4521, "text": "The Grassroots Infrastructure project aims to create an easily-deployable suite of computing middleware tools to help users and developers gain access to scientific data infrastructure that can easily be interconnected. With the data-generative approaches that are increasingly common in modern life science research, it is vital that the data and metadata produced by these efforts can be shared and reused. The Grassroots Infrastructure project wraps up industry-standard software tools with a consistent API that can be federated on a number of levels. This means institutions and groups can deploy a simple lightweight virtual machine, expose local data, connect up any existing data services, and federate their instance of the Grassroots with others out-of-the-box. The Grassroots Infrastructure uses a controlled vocabulary of JSON messages to communicate, so any server or client that can understand JSON can be used to access and connect to the platform. We provide infrastructure to ensure that the scientific data remains the important factor, and not the worry about how to build a system to expose your data.", "entities": [{"id": 1172, "label": "Software", "start_offset": 776, "end_offset": 801}, {"id": 1173, "label": "Software", "start_offset": 4, "end_offset": 29}, {"id": 1174, "label": "Software", "start_offset": 413, "end_offset": 438}]}
{"id": 4522, "text": "The Grassroots free-text search engine, based upon Lucene, allows us to give ranked, faceted results for various types of research data such as field trial information, research datasets, sequence data, etc. These data items are all faceted and each facet automatically weights searches for its specific fields. For example, queries that match study names get ranked higher than those that match queries in their description field instead. This is used for general searches as well as a specific faceted search applications such as the one we have for Measured Variables to denote phenotypic data.", "entities": [{"id": 1419, "label": "Software", "start_offset": 4, "end_offset": 38}]}
{"id": 4523, "text": "Continuous updating of our existing web-based application for submitting and searching for various aspects of field trial experimental data. Updates include adding images , treatment factors, research programmes and vastly expanded faceted search functionality.", "entities": []}
{"id": 4524, "text": "Eirods-dav provides access to iRODS servers using the WebDAV protocol and has a complete REST API for accessing and manipulating metadata from within a web browser. It adds a substantial amount of functionality to the original Davrods module written by Ton Smeele and Chris Smeele, which is a bridge between the WebDAV protocol and the iRODS API. Eirods-dav leverages the Apache server implementation of the WebDAV protocol, mod_dav, for compliance with the WebDAV Class 2 standard. It also automatically generates and exports the datasets as Frictionless Data Packages.", "entities": [{"id": 539, "label": "Software", "start_offset": 0, "end_offset": 10}, {"id": 540, "label": "Software", "start_offset": 347, "end_offset": 358}]}
{"id": 4525, "text": "This is a tool to allow the iRODS client icommands to have auto-complete functionality within Bash as is the case with normal mounted filesystems.", "entities": []}
{"id": 4526, "text": "Eirods-dav provides access to iRODS servers using the WebDAV protocol and has a complete REST API for accessing and manipulating metadata from within a web browser. It adds a substantial amount of functionality to the original Davrods module written by Ton Smeele and Chris Smeele, which is a bridge between the WebDAV protocol and the iRODS API. Eirods-dav leverages the Apache server implementation of the WebDAV protocol, mod_dav, for compliance with the WebDAV Class 2 standard.", "entities": [{"id": 980, "label": "Software", "start_offset": 0, "end_offset": 10}, {"id": 981, "label": "Software", "start_offset": 346, "end_offset": 357}]}
{"id": 4527, "text": "A web-based application for submitting and searching for various aspects of field trial experimental data.", "entities": []}
{"id": 4528, "text": "This software stores information regarding peak markers and parental genotype information for various QTL. It is part of a collaboration between the University of Bristol, the John Innes Centre and the Earlham Institute.", "entities": []}
{"id": 4529, "text": "The Parental Genotype Service works with data from various cross-parental breeding lines with associated genotypic markers along with which parent is responsible for their presence in the child line. It can accept various queries across this data,", "entities": [{"id": 1650, "label": "Software", "start_offset": 4, "end_offset": 35}]}
{"id": 4530, "text": "The Grassroots software is an open source &quot;as-a-Service&quot; stack that powers a number of data dissemination and analysis activities at EI, and other sites such as CerealsDB at the University of Bristol. We have continued to develop the functionality within the software stack to share crop-related datasets.", "entities": [{"id": 541, "label": "Software", "start_offset": 0, "end_offset": 23}]}
{"id": 4531, "text": "This is a containerised version of KnetMiner for Cloud deployment - particularly for use in the Cyverse UK environment", "entities": [{"id": 770, "label": "Software", "start_offset": 35, "end_offset": 44}]}
{"id": 4532, "text": "The Grassroots Infrastructure project aims to create an easily-deployable suite of computing middleware tools to help users and developers gain access to scientific data infrastructure that can easily be interconnected.\n\nWith the data-generative approaches that are increasingly common in modern life science research, it is vital that the data and metadata produced by these efforts can be shared and reused. The Grassroots Infrastructure project wraps up industry-standard software tools with a consistent API that can be federated on a number of levels. This means institutions and groups can deploy a simple lightweight virtual machine, expose local data, connect up any existing data services, and federate their instance of the Grassroots with others out-of-the-box.\n\nThe Grassroots Infrastructure uses a controlled vocabulary of JSON messages to communicate, so any server or client that can understand JSON can be used to access and connect to the platform. We provide infrastructure to ensure that the scientific data remains the important factor, and not the worry about how to build a system to expose your data.", "entities": [{"id": 982, "label": "Software", "start_offset": 778, "end_offset": 803}]}
{"id": 4533, "text": "This is a command-line tool to extract the resources within a Frictionless Data Package into a variety of formats such as Markdown, HTML, CSV, etc. It will be available for as many different platforms as possible. It uses the schemas for each resource within the Data Package to generate the reports. It has in-built support for tabular-data-resources and will download and parse any web-based schemas from the resource profiles and use these when they are specified. It will output a file for each Data Resource within the Data Package.", "entities": []}
{"id": 4534, "text": "Continuous updating of our existing web-based application for submitting and searching for various aspects of field trial experimental data. Updates include adding images , treatment factors, research programmes and vastly expanded faceted search functionality.", "entities": []}
{"id": 4535, "text": "The Grassroots Infrastructure project aims to create an easily-deployable suite of computing middleware tools to help users and developers gain access to scientific data infrastructure that can easily be interconnected. With the data-generative approaches that are increasingly common in modern life science research, it is vital that the data and metadata produced by these efforts can be shared and reused. The Grassroots Infrastructure project wraps up industry-standard software tools with a consistent API that can be federated on a number of levels. This means institutions and groups can deploy a simple lightweight virtual machine, expose local data, connect up any existing data services, and federate their instance of the Grassroots with others out-of-the-box. The Grassroots Infrastructure uses a controlled vocabulary of JSON messages to communicate, so any server or client that can understand JSON can be used to access and connect to the platform. We provide infrastructure to ensure that the scientific data remains the important factor, and not the worry about how to build a system to expose your data.", "entities": [{"id": 1651, "label": "Software", "start_offset": 776, "end_offset": 801}, {"id": 1652, "label": "Software", "start_offset": 4, "end_offset": 29}, {"id": 1653, "label": "Software", "start_offset": 413, "end_offset": 438}]}
{"id": 4536, "text": "This is documentation for how to develop and deploy KnetMiner using Docker", "entities": []}
{"id": 4537, "text": "software written in R environment for the analysis of ChiP-Chip datasets", "entities": []}
{"id": 4538, "text": "An app was developed to allow users, the general public, educational units and 3rd mission institutions, to identify common saltmarsh plants, birds, invertebrates and soil types and in addition submit a soil carbon stock measurement using predominant vegetation type and soil type. The app is also linked to a website where people that submit results can see their results and further information. The app was launched the first of July 2017. It has currently just under 100 active users, in the UK and Netherlands. We have had enquiries to whether a Dutch institution can produce a Dutch-language version of the App.", "entities": []}
{"id": 4539, "text": "With the CBESS team we produced a GIS-interface tool for predicting saltmarshes in Welsh and English Salt marshes. The tool was launched the 1st of July 2016. As an output, we produced a full spatial predition of saltmarsh carbon for all of Wales. The tool uses NVC (National Vegetation Community) plant type and soil type (sandy or silt-clay) to predict soil organic carbon stock (vegetation type within site) with between 40 and 60 % accuracy. So far, the tool has been downloaded by more than 25 UK national linstitutions, from national agencies (NE, EA, NRW), 3rd sector (RSPB, etc), schools and Universities (excluding own institutions)", "entities": [{"id": 1175, "label": "Software", "start_offset": 34, "end_offset": 52}]}
{"id": 4540, "text": "In order to fully understand the genomic components of, in particular, bacterial pathogens, we must address variation in the core genome (components present in all isolates of a particular species) along with non-core or accessory genes. Traditionally, only core genome data are utilised to create phylogenies and such phylogenies are utilised to map relevant epidemiological and other characteristics to enhance understanding of the system under investigation. Clearly, for public health utility we require ways to rapidly interrogate both core and non-core. We introduced PANINI, to enable the rapid processing of core and non-core gene content and the delivery of results in an integrated fashion , along with core phylogenies, geographic and epidemiological data through the Microreact.org platform.", "entities": [{"id": 1420, "label": "Software", "start_offset": 574, "end_offset": 580}]}
{"id": 4541, "text": "Microreact is a web application for the interactive visualisation of trees, geographic data, and temporal data. Together with Pathogenwatch, a platform for the analysis of genomic and epidemiology surveillance data, these tools are enabling collective interpretation and data sharing between project participants in the Philippines and collaborators in the UK.", "entities": [{"id": 1654, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 4542, "text": "Digital game providing users with a demonstration of various scenarios related to servitization.", "entities": []}
{"id": 4543, "text": "An interactive game designed to persuade users of the potential benefits of servitization from the perspective of the customer.", "entities": []}
{"id": 4544, "text": "A gamified application providing users with visual insight into their competitive strategy in relation to servitization.", "entities": []}
{"id": 4545, "text": "Minority Language Audio Journalism and Podcast Service", "entities": [{"id": 1176, "label": "Software", "start_offset": 0, "end_offset": 54}]}
{"id": 4546, "text": "The app enables carbon measurement across the entire media supply chain.", "entities": []}
{"id": 4547, "text": "Prototype app-based platform for healthcare. The app collects info on patients' daily comfort score, images of joints when flexed or extended and then records a patient's range of motion via the Pose Estimation technology. The project experimented with gamification and coaching methods to innovate the monitoring process of patients.", "entities": []}
{"id": 4548, "text": "Clwstwr Atlas - an interactive, browser-based discovery tool and database, mapping creative firms and freelancers to their narrow geographical regions, displaying local economic data on creative industries, such as employment, sectoral composition and output.", "entities": [{"id": 542, "label": "Software", "start_offset": 0, "end_offset": 13}]}
{"id": 4549, "text": "The research &amp; development process looked into making vertical video multifunctional, by developing a new platform. The project investigated the use of blockchain smart contract technology to create a transformative application.", "entities": []}
{"id": 4550, "text": "Spatial design app and workspace for set decorators, production designers, cinematographers and architects that helps organising collaborative visual thinking.", "entities": []}
{"id": 4551, "text": "Digital platform offering an integrated solution for managing career prospectives (including training)", "entities": []}
{"id": 4552, "text": "The app enables an interactive experience with live content. The solution was tested through a live streaming, starring The Disappearance of Jayden Jones. The audience were able to participate in this live scripted experience across Facebook and YouTube in a meaningful and engaging way. Uisng their super-sleuth skills to play a vital part in solving the mystery.", "entities": []}
{"id": 4553, "text": "Software that extracts information from court lists and registers and stores it in a searchable format.", "entities": []}
{"id": 4554, "text": "Remote editing toolkit that provides a new way of working.", "entities": []}
{"id": 4555, "text": "Plan V is a virtual reality bespoke studio environment which can be used directly through a local and/or remote framework, allowing the user to experiment with lenses, storyboards, pre-visualisation and many other options.", "entities": [{"id": 771, "label": "Software", "start_offset": 0, "end_offset": 6}]}
{"id": 4556, "text": "ERSEM: European Regional Seas Ecosystem Model For more information please visit http://ersem.com.", "entities": [{"id": 983, "label": "Software", "start_offset": 0, "end_offset": 5}, {"id": 984, "label": "Software", "start_offset": 7, "end_offset": 46}]}
{"id": 4557, "text": "ERSEM: European Regional Seas Ecosystem Model For more information please visit http://ersem.com.", "entities": [{"id": 1177, "label": "Software", "start_offset": 7, "end_offset": 45}, {"id": 1178, "label": "Software", "start_offset": 0, "end_offset": 5}]}
{"id": 4558, "text": "Implements a path integral approach to calculate the thermodynamics of quantum spin in a constant magnetic field along the z-direction. It contains functions for analytic solutions and a numerical approach based on atomistic spin dynamics.", "entities": []}
{"id": 4559, "text": "k-Wave is an open source MATLAB toolbox designed for the time-domain simulation of propagating acoustic waves in 1D, 2D, or 3D. The toolbox has a wide range of functionality, but at its heart is an advanced numerical model that can account for both linear and nonlinear wave propagation, an arbitrary distribution of heterogeneous material parameters, and power law acoustic absorption.\n\nThe numerical model is based on the solution of three coupled first-order partial differential equations which are equivalent to a generalised form of the Westervelt equation. The equations are solved using a k-space pseudospectral method, where spatial gradients are calculated using a Fourier collocation scheme, and temporal gradients are calculated using a k-space corrected finite-difference scheme. The temporal scheme is exact in the limit of linear wave propagation in a homogeneous and lossless medium, and significantly reduces numerical dispersion in the more general case.\n\nPower law acoustic absorption is accounted for using a linear integro-differential operator based on the fractional Laplacian. A split-field perfectly matched layer (PML) is used to absorb the waves at the edges of the computational domain. The main advantage of the numerical model used in k-Wave compared to models based on finite-difference time domain (FDTD) schemes is that fewer spatial and temporal grid points are needed for accurate simulations. This means the models run faster and use less memory.\n\nMajor k-Wave versions were released in 2014, 2017, and 2020.", "entities": [{"id": 1655, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 1656, "label": "Software", "start_offset": 1490, "end_offset": 1496}, {"id": 1657, "label": "Software", "start_offset": 1265, "end_offset": 1271}]}
{"id": 4560, "text": "k-Plan is an advanced modelling tool for precision planning of transcranial ultrasound procedures. It uses a streamlined and intuitive workflow that allows users to select an ultrasound device, position the device using a template or medical image, and specify the sonication parameters. High-resolution calculations of the ultrasound field and temperature inside the skull and brain are then automatically calculated in the cloud with a single click.", "entities": [{"id": 543, "label": "Software", "start_offset": 0, "end_offset": 6}]}
{"id": 4561, "text": "Repository of RStudio project for the Enggano-Dutch word list in Helfrich (1916) How to cite Rajeg, Gede Primahadi Wijaya. 2023. Materials for the Enggano-Dutch word list in Helfrich (1916). University of Oxford. Software. https://doi.org/10.25446/oxford.23508945 Helfrich, O. L. 1916. &quot;Nadere Bijdrage Tot de Kennis van Het Engganeesch.&quot; Bijdragen Tot de Taal-, Land- En Volkenkunde 71 (1): 472-555. https://doi.org/10.1163/22134379-90001719. Description This version tracks the R codes to process the word list into common transcription. The future version will include the word list when it has been ready and finalised.", "entities": [{"id": 772, "label": "Software", "start_offset": 0, "end_offset": 29}, {"id": 773, "label": "Software_Url", "start_offset": 411, "end_offset": 452}]}
{"id": 4562, "text": "Repository containing the R codes and the associated materials to process the retro-digitisation output of the Enggano-German Dictionary (K&auml;hler 1987)", "entities": []}
{"id": 4563, "text": "An extension to the KLEE symbolic execution engine that uses the metaSMT framework to add support for multiple SMT solvers (Boolector, STP and Z3).", "entities": []}
{"id": 4564, "text": "A symbolic execution tool that is designed to generate test inputs that cover the new program behaviours introduced by a patch. The technique works by executing both the old and the new version in the same symbolic execution instance, with the old version shadowing the new one. During this combined shadow execution, whenever a branch point is reached where the old and the new versions diverge, we generate a test case exercising the divergence and comprehensively test the new behaviours of the new version.", "entities": []}
{"id": 4565, "text": "A lightweight symbolic execution tool for improving existing test suites by thoroughly checking for errors all sensitive operations executed by a test suite.", "entities": []}
{"id": 4566, "text": "Combines dynamic symbolic execution with several novel heuristics based on program analysis to automatically and comprehensively test code patches.", "entities": []}
{"id": 4567, "text": "The Infobiotics Workbench is a executable biology framework implementing multi-compartmental stochastic and deterministic simulation, formal model analysis and structural/parameter model optimisation for computational systems and synthetic biology.\n\nThe Infobiotics Workbench is comprised of the following components:\n\n a modelling language based on P systems which allows modular and parsimonious multi-cellular model development where the outermost compartments can be positioned in 2-dimensional space to facilitate modelling at either extra-, inter- or intracellular levels of detail\n\n deterministic and stochastic simulator using algorithms optimised for large multi-compartmental systems (the simulator also accept a subset of SBML, allowing for visual model specification using tools such as CellDesigner)\n\n formal model analysis for the study of temporal and spatial model properties supported the model checkers PRISM and MC2\n\n model structure and parameter optimisation using a variety of evolutionary and population-based algorithms to automatically generate models whose dynamics match specified target timeseries\n\n a user-friendly front-end for performing in-silico experiments, plotting and visualisation of simulations with many runs and compartments", "entities": [{"id": 776, "label": "Software", "start_offset": 4, "end_offset": 25}, {"id": 777, "label": "Software", "start_offset": 254, "end_offset": 275}]}
{"id": 4568, "text": "VRMLGen is a free software package for 3D data visualisation on the web. It supports VRML and LiveGraphics3D formats. The package runs within the R environment for statistical computing and is available for download from CRAN. It is licensed under the terms of GNU GPL version 2 (or later).\n\nVRMLGen can be used to generate 3D line and bar charts, scatter plots with density estimation contour surfaces, visualizations of height maps, parametric functions and 3D object models. \n\nThe 3D visualisation can be viewed directly in a web browser or a standalone viewer (see e.g. Xj3D, Cortona3D or BS Contact) and studied in detail using zoom, pan and rotate controls. In addition VRMLGen can be combined with POV-Ray using vrml2pov to render high-quality images.", "entities": [{"id": 985, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 986, "label": "Software", "start_offset": 292, "end_offset": 299}, {"id": 987, "label": "Software", "start_offset": 676, "end_offset": 683}]}
{"id": 4569, "text": "ArrayMining is a server for automating statistical analysis of gene and protein expression microarray data, designed as a supporting tool for investigation of the genetic components of diseases. It performs five common gene expression analysis tasks:\n\n cross-study normalisation\n feature selection\n sample clustering\n sample classification\n network analysis\n gene set analysis\n\nUnlike other microarray-related servers, ArrayMining is using ensemble and consensus techniques (e.g. ensemble feature selection, ensemble prediction, consensus clustering) and performs automatic parameter selection. For a given analysis task it is possible to combine multiple algorithms and data sets in a semi-automatic fashion. This way new exploratory routes become available, e.g. ensemble sample classification can be performed with predictors obtained from a gene set analysis applied to combined data from multiple studies.\n\nThe analysis is further simplified by the integration with annotation databases. This enables further functional analysis and literature mining. The results are presented as interactive sortable tables and three dimensional VRML visualizations.", "entities": [{"id": 1179, "label": "Software", "start_offset": 0, "end_offset": 11}, {"id": 1180, "label": "Software", "start_offset": 419, "end_offset": 430}]}
{"id": 4570, "text": "Event structures are mathematical structures underpinning our approach to modeling our treatments of multimorbid patients.\nThe software we produced outputs all possible such structures of a given cardinality, allowing us to perform simulations and computational experiments on them.\nMoreover, this software is verified using theorem provers. This means that the correctness of the output is proven to the highest standards available, granting that our work is based on the right data.", "entities": []}
{"id": 4571, "text": "HelioPy is a python software package for automatically downloading and importing common datasets in heliospheric physics.", "entities": [{"id": 1658, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4572, "text": "A python package for computing Potential Field Source Surface magnetic field models of the Sun.", "entities": []}
{"id": 4573, "text": "Parallel version of the Birmingham Cluster Genetic Algorithm for global optimisation of isolated clusters and clusters in the presence of a support (e.g. a metal oxide substrate).", "entities": [{"id": 778, "label": "Software", "start_offset": 23, "end_offset": 61}]}
{"id": 4574, "text": "User-friendly software is developed by my research team at The University of Sheffield to find more efficient cold-formed steel (CFS) beam and column sections with significantly higher ultimate capacity compared to existing standard sections. The software is developed in MATLAB.", "entities": []}
{"id": 4575, "text": "The Enset App is a free Android application aimed at Agricultural extension agents in Ethiopia.\n\nIt has three main functions:\n1. It provides disease diagnostic digrams and photographs on a field portable device.\n2. It provides information on management best practice.\n3. It uses genomic analysis performed by the project to identify landraces optimally suited to local climates. Thereby support the climate adaptation of farmers.", "entities": [{"id": 1182, "label": "Software", "start_offset": 4, "end_offset": 13}]}
{"id": 4576, "text": "E-PANNs is an efficient version of existing PANNs network. E-PANNs can be used to recognize sound activity happening in the surrounding. E-PANNs can recognize 527 sound activities including human speech, animal sounds, ambulance siren and smoke alarm. The memory size requirement by the PANNs network is 312MB. On the other hand, E-PANNs requires approximately 92MB and also, E-PANNs is faster in computation compared to PANNs with improved performance.", "entities": [{"id": 1421, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 1422, "label": "Software", "start_offset": 137, "end_offset": 144}, {"id": 1423, "label": "Software", "start_offset": 59, "end_offset": 66}, {"id": 1424, "label": "Software", "start_offset": 376, "end_offset": 383}, {"id": 1425, "label": "Software", "start_offset": 330, "end_offset": 337}]}
{"id": 4577, "text": "The General-Purpose Sound Recognition application is intended to work on conventional computers, leveraging PANNs for real-time audio event detection. The developed software, equipped with a user-friendly Tkinter interface, has demonstrated significant utility in real-time event detection. The prediction is obtained by applying the audio tagging system on consecutive short audio segments. It is able to perform multiple updates per second on a moderate CPU.", "entities": [{"id": 1659, "label": "Software", "start_offset": 4, "end_offset": 49}]}
{"id": 4578, "text": "Matlab based Iterative optimisation algorithm package developed in-house", "entities": [{"id": 544, "label": "Software", "start_offset": 0, "end_offset": 53}]}
{"id": 4579, "text": "The NMR Exchange Format (NEF) has been developed in a collaboration between the CCPN, the BioMagResBank, the RCSB, and the main developers of macromolecular NMR software (Peter Guntert (CYANA), Charles Schwieters (XPLOR-NIH), Michael Nilges (ARIA), Torsten Herrmann (UNIO), David Wishart, David Case (AMBER), Guy Montelione (AutoAssign, ASDP)). It covers sequence, chemical shifts, spectra, peak lists, and restraints. The format specification is controlled by consensus of the partners, and all developers have committed to supporting the format as an input/output exchange format. Version 1.0 of the format specification is now stable and fully supported by CCPN, and will be supported by the upcoming release of NMR-STAR (version 3.2.0.1).", "entities": [{"id": 784, "label": "Software", "start_offset": 4, "end_offset": 24}, {"id": 785, "label": "Software", "start_offset": 25, "end_offset": 28}, {"id": 786, "label": "Software", "start_offset": 186, "end_offset": 191}, {"id": 787, "label": "Software", "start_offset": 242, "end_offset": 246}, {"id": 788, "label": "Software", "start_offset": 214, "end_offset": 223}, {"id": 789, "label": "Software", "start_offset": 267, "end_offset": 271}, {"id": 790, "label": "Software", "start_offset": 301, "end_offset": 306}, {"id": 791, "label": "Software", "start_offset": 325, "end_offset": 335}, {"id": 792, "label": "Software", "start_offset": 336, "end_offset": 341}, {"id": 793, "label": "Software", "start_offset": 715, "end_offset": 723}]}
{"id": 4580, "text": "Free software in the R language for studying the evolution of traits among species using phylogenetic trees.", "entities": []}
{"id": 4581, "text": "A WordPress LMS to facilitate online learning and track researcher's learning journey", "entities": [{"id": 1183, "label": "Software", "start_offset": 2, "end_offset": 15}]}
{"id": 4582, "text": "A package for statistical analysis in High Energy Physics.", "entities": []}
{"id": 4583, "text": "An online webtool to help businesses define their servitization strategy.", "entities": []}
{"id": 4584, "text": "An online tool to help organisations construct a business model for advanced services.", "entities": []}
{"id": 4585, "text": "A fun and educational game about different service offerings a drilling company can offer based on servitization", "entities": []}
{"id": 4586, "text": "A game to teach users the principles of engineering design for services, in which the player takes on the role of a board member at a washing machine manufacturing company.", "entities": []}
{"id": 4587, "text": "An online game adapted from the service transformation board game (see Artistic and Creative Products) based on the classic board game snakes and ladders, that facilitates the understanding of, and engagement with, the advanced services transformation roadmap.", "entities": []}
{"id": 4588, "text": "A game in which the player takes on the role of a boardroom member who is negotiating with the board about deploying advanced services in the company", "entities": []}
{"id": 4589, "text": "New likelihood to distribute and utilize data from 2 seasons of observations of the Atacama Cosmology Telescope polarimeter.", "entities": []}
{"id": 4590, "text": "iDIEL Plant can segment Arabidopsis rosettes from both VIS (light) and NIR (dark) images and can extract quantitative estimates of projected rosette area (PRA). The software automatically numbers plants from left to right as they appear in the image, or manually by clicking on the centre of each plant. Thus, plants could be analysed regardless of arrangement in the image.", "entities": [{"id": 545, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 4591, "text": "This is a patch release containing the following changes.\n\n#4351: Fixed bug in large blocks optimization with triclinic boxes\n#4364: Fixed error in barostat", "entities": []}
{"id": 4592, "text": "The dataset annotation tool provides the end-user with a GUI-based simple to use package for annotating datasets for interesting visual features and landmarks (e.g., planetary surficial rocks). The annotated datasets can be used for evaluating visual object detection/tracking techniques.", "entities": []}
{"id": 4593, "text": "This is a prototype of autonomous software for robotic systems with ontology-based architecture and reconfigurability.", "entities": []}
{"id": 4594, "text": "Matches the accepted submission to the Journal of Open Source Software: https://joss.theoj.org/papers/71097ad0617d8fd3da4c5196877ccb73 Unit testing for src libraries Compilation with CMake", "entities": []}
{"id": 4595, "text": "NLP on social media data is hard. Content is often brief, contains mistakes, lacks context, and is uncurated - very different from the well-formed news text that tools typically operate over.\n\n\n\nTwitIE is a GATE pipeline for Information Extraction over tweets, one of the noisiest forms of social media text.", "entities": [{"id": 1660, "label": "Software", "start_offset": 195, "end_offset": 201}]}
{"id": 4596, "text": "tbc", "entities": []}
{"id": 4597, "text": "The game combines various language resource acquisition tasks in multiple languages (German, Spanish, Russian, Chinese, and Czech), some of them based on translated versions of existing English-language resources. Initially, the system collects answers from a group of players. From their answers the majority opinion is determined, which is considered to be the correct answer and serves as the basis for awarding game points", "entities": []}
{"id": 4598, "text": "tbc", "entities": []}
{"id": 4599, "text": "tbc", "entities": []}
{"id": 4600, "text": "tbc", "entities": []}
{"id": 4601, "text": "tbc", "entities": []}
{"id": 4602, "text": "A GWAP Plugin for the validation of ontologies for the Protege Ontology Editor", "entities": [{"id": 547, "label": "Software", "start_offset": 2, "end_offset": 13}]}
{"id": 4603, "text": "tbc", "entities": []}
{"id": 4604, "text": "The game combines practical steps to reduce one's carbon footprint with language resource acquisition tasks and questions about future climate-related conditions that we cannot answer today, but will be able to answer in the future.", "entities": []}
{"id": 4605, "text": "tbc", "entities": []}
{"id": 4606, "text": "tbc", "entities": []}
{"id": 4607, "text": "tbc", "entities": []}
{"id": 4608, "text": "The open-source GATE Crowdsourcing plugin offers infrastructural support for mapping documents to crowdsourcing units and back, as well as automatically generating reusable crowdsourcing interfaces for NLP classification and sequence annotation task", "entities": [{"id": 548, "label": "Software", "start_offset": 5, "end_offset": 41}]}
{"id": 4609, "text": "tbc", "entities": []}
{"id": 4610, "text": "tbc", "entities": []}
{"id": 4611, "text": "tbc", "entities": []}
{"id": 4612, "text": "ARElight is an application for a granular view onto sentiments between mentioned named entities in texts.", "entities": [{"id": 1426, "label": "Software", "start_offset": 0, "end_offset": 8}]}
{"id": 4613, "text": "An Gocair is a transformer-based orthographic standardiser for Scottish Gaelic. Its interface is similar to Google Translate. Users can enter orthographically older or irregularly spelled Gaelic text into the left box, and have it transformed to a Gaelic Orthographic Conventions in the right-hand box. Data deriving from the DHH project was used, in part, to train the transformer models.", "entities": [{"id": 1661, "label": "Software", "start_offset": 3, "end_offset": 9}]}
{"id": 4614, "text": "We constructed a new branch of the popular open source planetarium software, Stellarium, to work with the Oculus Rift Virtual Reality headset. The new branch will be released to the open source community, and will also be used by ourselves to run public stargazing events over the internet.", "entities": []}
{"id": 4615, "text": "This is the software for detecting individual trees from remotely-sensed data we developed as part of our new method as laid out in the methods section of our reporting. This has been cleaned and simplified to make a user friendly package to use in MATLAB. Once we submit our manuscript we intend to publish the full code-base in a publicly available repository at which point we will adopt and appropriate license. it is expected that this software will be made avaailable for use on the condition that attribution is given to our project members and reference is made to the article introducing our work.", "entities": []}
{"id": 4616, "text": "Monte Carlo generator to take into account radiative correction in kaon decays", "entities": [{"id": 988, "label": "Software", "start_offset": 0, "end_offset": 21}]}
{"id": 4617, "text": "Code that implements a variety of cuts for selecting two-body kinematics at hadron colliders, including the cuts from arXiv:2106.08329. Also to be found at https://github.com/gavinsalam/two-body-cuts", "entities": [{"id": 1184, "label": "Software_Url", "start_offset": 156, "end_offset": 199}]}
{"id": 4618, "text": "A code for parton showers.", "entities": []}
{"id": 4619, "text": "Alpha prototype for an Action Plan Interactive Tracker", "entities": [{"id": 1662, "label": "Software", "start_offset": 23, "end_offset": 54}]}
{"id": 4620, "text": "SpeckTackle, a custom-tailored JavaScript charting library for spectroscopy in life sciences. SpeckTackle is freely available and targeted at life science communities that deal with spectroscopic data such as coming from mass spectroscopy, infrared spectroscopy, or NMR. It contains several default chart types, supports common functionality, e.g. for spectra overlays or tooltips, and is designed to be portable.", "entities": [{"id": 549, "label": "Software", "start_offset": 0, "end_offset": 11}, {"id": 550, "label": "Software", "start_offset": 93, "end_offset": 105}]}
{"id": 4621, "text": "Version 5.0.0: February 2021\n\nChange of license DL_POLY_4 is now LGPL 3.0\nVersion bump to 5.0.0\nEmpirical Valence bond formalism is implemeneted, see Manual.\nThermal conductivity can be estimated now using, heat flux\nA more logical consistent structure for control file is available\nnew command line arguments, see -h for details\nBug fix core_shells_on_top shells wrap-around crossing MD box by adding relative vectors' move of shells on cores\nmore go to statements removed to make the code easier to read\nmultipolar electrostatics is disabled till put in line with new refactored electrostatics.\nfixed a memory leak in electrostatics, introduced by refactor\nzero correctly dihedrals, etc.\nnetcdf is deprecated and will be removed in the next release.", "entities": [{"id": 794, "label": "Software", "start_offset": 96, "end_offset": 128}]}
{"id": 4622, "text": "Integrability with a third party open source library for metadynamics methodology", "entities": []}
{"id": 4623, "text": "DL_POLY is a general purpose classical molecular dynamics (MD) simulation software developed at Daresbury Laboratory", "entities": [{"id": 1185, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4624, "text": "DL_POLY is a general purpose classical molecular dynamics (MD) simulation software developed at Daresbury Laboratory", "entities": [{"id": 1427, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4625, "text": "Py-ChemShell is the python-based version of the ChemShell multiscale computational chemistry environment, a leading package for combined quantum mechanical/molecular mechanical simulations.", "entities": [{"id": 1663, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 4626, "text": "collection of python3 scripts to allow creation of table files for DL_POLY_4 for potentials unsupported by the code yet.", "entities": []}
{"id": 4627, "text": "Very simple microCanonical fortran 2008 MD code.", "entities": [{"id": 795, "label": "Software", "start_offset": 11, "end_offset": 47}]}
{"id": 4628, "text": "This is a computer program package written in C that primarily serves as a support application software tool for DL_POLY MD simulation package. Following the same development philosophy as that of DL_FIELD, the main function of DL_ANALYSER is to carry out a variety of post analysis work on the trajectory files produced by the DL_POLY. It is also used to carry out multiple file format conversions. The program basically contains a collection of unified analysis tools that can produce a variety of results concurrently in a single-read through a collection of DL_POLY's trajectory files.", "entities": [{"id": 989, "label": "Software", "start_offset": 228, "end_offset": 240}]}
{"id": 4629, "text": "support for DL_POLY_4 to Aten. Visualizer and builder for atomic systems", "entities": []}
{"id": 4630, "text": "classical molecular dynamics software", "entities": [{"id": 1428, "label": "Software", "start_offset": 0, "end_offset": 37}]}
{"id": 4631, "text": "is a collection of python scripts to analyse dlpoly outputs using simplified graphical interfaces and jupyter notebooks.", "entities": []}
{"id": 4632, "text": "DLWizard graphically displays statistical outputs from DL_POLY_4. Helps users to extract and visualize STATIS file. Future versions may add more.", "entities": [{"id": 551, "label": "Software", "start_offset": 0, "end_offset": 20}]}
{"id": 4633, "text": "python module for dlpoly", "entities": []}
{"id": 4634, "text": "Additional functionality of the DL_POLY_4 software", "entities": [{"id": 990, "label": "Software", "start_offset": 32, "end_offset": 50}]}
{"id": 4635, "text": "DL_FIELD is a computer program package written in C that primarily serves as a support application software tool for the DL_POLY molecular dynamics simulation package.\nThe primary functions of DL_FIELD are:\n\n(1) Force field model convertor: DL_FIELD converts user's atom models, in particular those of large complex biomolecular systems, into file formats that are recognisable and ready to run in DL_POLY_Classic, DL_POLY_3 and DL_POLY_4 programs with minimum user's intervention. This basically involves the conversion of a user's atomic configuration in simple xyz coordinates into identifiable atom types base on a particular user-selectable potential schemes and then automatically generate the DL_POLY configuration file (CONFIG), the force field file (FIELD) and a generic control file (CONTROL).\n\n(2) Force field editor: DL_FIELD allows user to edit or modify a particular force field scheme to produce a customised scheme that is specific to a particular simulation model. For instance, introduction of pseudo points and rigid body implementation to an otherwise standard potential scheme such as CHARMM or AMBER, etc.\n\n(3) Force field model repertoire: DL_FIELD has a consistent file structure format for all FF schemes and molecular structure definitions. It also allows user to easily expand the existing standard model library to include user-defined molecular model.\n\n(4) Full automatic atom typesetting (the DLF notation) and identification of chemical nature of atoms.", "entities": [{"id": 1186, "label": "Software", "start_offset": 0, "end_offset": 8}, {"id": 1187, "label": "Software", "start_offset": 121, "end_offset": 128}, {"id": 1188, "label": "Software", "start_offset": 193, "end_offset": 201}, {"id": 1189, "label": "Software", "start_offset": 241, "end_offset": 249}, {"id": 1190, "label": "Software", "start_offset": 700, "end_offset": 707}, {"id": 1191, "label": "Software", "start_offset": 829, "end_offset": 837}, {"id": 1192, "label": "Software", "start_offset": 1163, "end_offset": 1171}, {"id": 1193, "label": "Software", "start_offset": 398, "end_offset": 413}, {"id": 1194, "label": "Software", "start_offset": 415, "end_offset": 425}, {"id": 1195, "label": "Software", "start_offset": 429, "end_offset": 438}]}
{"id": 4636, "text": "DL_POLY is a general purpose classical molecular dynamics (MD) simulation software developed at Daresbury Laboratory", "entities": [{"id": 1429, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4637, "text": "python module for dlpoly 4.10", "entities": [{"id": 1664, "label": "Software", "start_offset": 18, "end_offset": 24}]}
{"id": 4638, "text": "DL_MESO is a general purpose mesoscale simulation package developed by Michael Seaton for CCP5(link opens in a new window) under a grant provided by EPSRC. It is written in Fortran90 and C++ and supports both Lattice Boltzmann Equation (LBE) and Dissipative Particle Dynamics (DPD) methods. It is supplied with its own Java-based Graphical User Interface (GUI) and is capable of both serial and parallel execution.", "entities": [{"id": 552, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4639, "text": "General Purpose Molecular Dynamics Program", "entities": [{"id": 796, "label": "Software", "start_offset": 0, "end_offset": 42}]}
{"id": 4640, "text": "The software was designed to provide new software tools to allow those interested in modelling soft matter to understand and predict the phase behaviour and stability for systems where the numbers of atoms required are too large for atomistic MD and/or suffer from the time constraints of observing slowly evolving processes and hence require using a coarse grain (CG) approach.\n\nThere are two aspects to the CG approach that has been undertaken:\n\n1. A fully featured interface has been introduced between DL_POLY and VOTCA, the latter being the well-known nowadays Versatile Object-oriented Toolkit for Coarse-graining Applications (www.votca.org) introduced in 2009 by the theoretical group Prof. Kurt Kremer [J. Chem. Theor. Comp. 2009, vol. 5(12), p. 3211] and now being further developed at UI-UC, University of Cambridge and LANL.\n\n2. A stand-alone tool for CG mapping - DL_CGMAP. This additional tool is aimed at providing the academic community using DL_POLY with a set of &quot;in-house&quot; utilities for coarse-graining and supplementary analysis of trajectories generated by DL_POLY.", "entities": [{"id": 991, "label": "Software", "start_offset": 877, "end_offset": 885}]}
{"id": 4641, "text": "A few special routines within the DL_POLY-4 software for performing analyses of the probability distributions of intra-molecular (bonded) interactions, and also creation of the numerical (tabulated) inputs for these interactions (via potential of mean force). Altogether, the routines extend the functionality in DL_POLY-4 to MD simulation of coarse-grain systems.", "entities": [{"id": 1196, "label": "Software", "start_offset": 34, "end_offset": 44}, {"id": 1197, "label": "Software", "start_offset": 313, "end_offset": 322}]}
{"id": 4642, "text": "Py-ChemShell is the python-based version of the ChemShell multiscale computational chemistry environment, a leading package for combined quantum mechanical/molecular mechanical simulations.", "entities": [{"id": 1430, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 4643, "text": "Version 4.10.0: August 2020\n\n\nImprovements, updates, new features:\n\ntotally refactores DL_POLY_4, using OOP principles and modern software engineering\nnew SPME to allow per particle calculations for various quantities as stress and energy, see pp_dump\nnew IO systems, almost all the usual files now can be customised\na new method to compute neighbour lists that can offer non-negligible speedups for certain soft-matter systems, use\n-DWITH_HALF_HALO to activate\nset bounds is totally rewritten, allowing clearer understanding of how various buffer sizes are computed\nstatis file structure changed, amsd and stress are swapped in the arrays now\nyaml formats for statis and rdf, see yml_statis and yml_rdf keywords in control\nnew timing reporting in OUTPUT\nn(r) is not printed in RDFDAT rather that OUTPUT files\nOUTPUT is cleaned up, with verbosity level option added, see l_print\nautomatic regression testing is extented from 28 tests to 169\nunit testing infrastructure added\nopenkim 2.0 api support\nplumed and openkim now are installed by default for the user\neasybuild templates available for easy deployment on hpc clusters\nangular distribution function added for on the fly calculations\non the fly coordination calculation for radiation damage simulations\ncurrent calculations\nnew potentials available, ZBL, calcite Raitieri tappered, Generalised Lennard Jones by Frenkel, etc...\nintegrate was removed, no leapfrog integration scheme.\nexpansion of the two-temperature model (TTM) to triclinic (non-orthorhombic) systems - ttm_modile, langevin_forces, ttm_ion_diffusion, ttm_thermal_diffusion\nprocessing tabbed data is reinforced for all reading routines parse_module, read_field\n\n\n\nBug fixes:\n\nfix array bounds in tersoff potential\nboundaries in stochastic thermostat work correctly now\nfix for core-shell infrequent bug\nfix mdf long range correction incorrect non-zero for mbuck\nfixing memory leak io_module\nfixing halo particles identification and designation to halo's link-cell space in link_cell_pairs and defects_link_cells\nTTM fixes for cell shape and integrator stability", "entities": [{"id": 1665, "label": "Software", "start_offset": 87, "end_offset": 96}]}
{"id": 4644, "text": "General purpose Monte Carlo simulation of materials. Updated versions of the software were released In May 2016, August 2016 and Jan feb 2017.", "entities": [{"id": 553, "label": "Software", "start_offset": 0, "end_offset": 39}]}
{"id": 4645, "text": "General Purpose Molecular Dynamics Program", "entities": [{"id": 797, "label": "Software", "start_offset": 0, "end_offset": 42}]}
{"id": 4646, "text": "DL_MESO is a general purpose mesoscale simulation package written in Fortran and C++. It supports both Lattice Boltzmann Equation (LBE) and Dissipative Particle Dynamics (DPD) simulations for a wide range of phenomena. It is supplied with its own Java-based Graphical User Interface (GUI) and is capable of both serial and parallel execution. Version 2.7 was released in December 2018.", "entities": [{"id": 992, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4647, "text": "Py-ChemShell is the python-based version of the ChemShell multiscale computational chemistry environment, a leading package for combined quantum mechanical/molecular mechanical simulations.", "entities": [{"id": 1198, "label": "Software", "start_offset": 0, "end_offset": 11}]}
{"id": 4648, "text": "DL_POLY is a general purpose classical molecular dynamics (MD) simulation software developed at Daresbury Laboratory", "entities": [{"id": 1431, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4649, "text": "GUI customization for Aten to be used for Chemistry in School Days in Daresbury Laboratory \nAllows high school students to prepare input files to be run in simulation of materials for solar cells.", "entities": []}
{"id": 4650, "text": "able to generate full inputs for dlpoly control and config, fields for simple systems. all progrmatically from python", "entities": []}
{"id": 4651, "text": "An extended, largely refactored version of DL_MONTE-1, enhanced by continuous optimisation and added new advanced methodologies, such as Free Energy difference and Phase Switch methods, but also quasi-2D (planar pore) geometry for simulation of constrained systems.", "entities": [{"id": 798, "label": "Software", "start_offset": 43, "end_offset": 53}]}
{"id": 4652, "text": "Update of the general purpose Monte Carlo code DL_MONTE.", "entities": [{"id": 994, "label": "Software", "start_offset": 47, "end_offset": 55}]}
{"id": 4653, "text": "Safarnama is an open-access software platform: safarnama (story of a journey). This platform consists authoring software: (safarnama.lancaster.ac.uk) and a native app (available from Google Play). The safarnama software is a web-based authoring tool that allows users to create 'experiences' by combining and mapping a range of digital media - sound, 2D and 3D images and text - on a Google Map layer. These experiences can published within the safarnama app or published as QR codes and downloaded using the safarnama app. \n\nThe safarnama software creates heritage engagement based in mobility and proximity. The experiences contain trigger zones around places of interest. If app users pass within these trigger zones, they receive a push notification alerting them to nearby heritage. In this way, smart phone users can encounter 'ambient' heritage in small bursts, and in several languages, as they travel across urban landscapes.", "entities": [{"id": 1199, "label": "Software", "start_offset": 0, "end_offset": 9}, {"id": 1200, "label": "Software", "start_offset": 47, "end_offset": 56}, {"id": 1201, "label": "Software_Url", "start_offset": 123, "end_offset": 148}, {"id": 1202, "label": "Software", "start_offset": 201, "end_offset": 210}, {"id": 1204, "label": "Software", "start_offset": 445, "end_offset": 454}, {"id": 1205, "label": "Software", "start_offset": 509, "end_offset": 518}, {"id": 1206, "label": "Software", "start_offset": 530, "end_offset": 539}]}
{"id": 4654, "text": "The Cinnamon domain-specific language and compiler targets DynamoRIO (via the Janus tool), Pin and Dyninst binary instrumentation systems to allow flexible and framework-independent ways of building binary profiling and monitoring tools.", "entities": [{"id": 1432, "label": "Software", "start_offset": 59, "end_offset": 68}]}
{"id": 4655, "text": "Web browser", "entities": []}
{"id": 4656, "text": "Janus is a binary parallelisation tool, also capable of automatically vectorising applications, as well as inserting useful software prefetches.", "entities": [{"id": 554, "label": "Software", "start_offset": 0, "end_offset": 5}]}
{"id": 4657, "text": "The software can take climate and hydrological data to produce analysis on failures and robustness of water resources systems, based on a combination of simulation and opimisation techniques.", "entities": []}
{"id": 4658, "text": "The Smart Donations App is an ongoing development of this research. Through this blockchain-based app, it allows users to donate money directly to charitable causes with a number of conditions attached upheld with the use of smart contracts.\n\nFor example a contract may look like this,\n\nI will donate &pound;100 to an earthquake response fund which will be released if there is a significant earthquake anywhere in the world in the next 12 months. After 12 months, if there has not been an earthquake, then the donor has a number of options;\n\nTo withdraw their donation and keep their money\nTo donate directly to the charity's general unrestricted funds\nTo renew or create a new contract with the same charity through the app\nTo create a new contract with a different charity through the app\nBy working with a number of charitable partners, we are exploring the opportunities and challenges presented by this new approach to giving.", "entities": [{"id": 995, "label": "Software", "start_offset": 4, "end_offset": 23}]}
{"id": 4659, "text": "The CAPTAIN Toolbox is a collection of Matlab functions for system identification, time series analysis, forecasting and control. The current developers are Prof. Peter Young, Dr. Wlodek Tych and Prof. James Taylor, Lancaster University, UK. Although the toolbox has been available for many years, new and improved algorithms have been added to the package as a result of recent EPSRC funded research. For details see e.g. Taylor, C.J., Young, P.C., Tych, W., Wilson, E.D. (2018) New developments in the CAPTAIN Toolbox for Matlab with case study examples, IFAC-PapersOnLine, 51, 15, 694-699, 2018 (https://doi.org/10.1016/j.ifacol.2018.09.202).", "entities": [{"id": 1207, "label": "Software", "start_offset": 4, "end_offset": 19}]}
{"id": 4660, "text": "Software package which calculates travel time fields and subsequently traces raypaths through locally anisotropic media based on the ALI-FMM algorithm detailed in https://arxiv.org/pdf/2302.10988.pdf", "entities": []}
{"id": 4661, "text": "This code package demonstrates a deep learning aproach to ultrasound tomography for reconstructing grain maps of polycrystalline media from travel time data using deep neural networks (DNNs) and generative adversarial networks (GANs). It accompanies the paper &quot;Real-time super-resolution mapping of locally anisotropic grain orientations for ultrasonic non-destructive evaluation of crystalline material&quot;, J Singh, KMM Tant, A Curtis, AJ Mulholland. Neural Computing and Applications, 2021.", "entities": []}
{"id": 4662, "text": "Process optimisation toolbox, based on MATLAB script, capable of optimising process conditions.", "entities": [{"id": 555, "label": "Software", "start_offset": 0, "end_offset": 28}]}
{"id": 4663, "text": "Image and signal processing toolbox for time-domain fluorescence lifetime imaging data but and for RGB spectral unmixing, foci counting and other batch processing, formatting, printing and export functions.Toolbox developed to run in a 'workspace' framework and allows user to try out different processing functions on images.", "entities": []}
{"id": 4664, "text": "The Open Platform for Energy Networks (OPEN) provides a python toolset for modelling, simulation and optimisation of smart local energy systems. The framework combines distributed energy resource modelling (e.g. for PV generation sources, battery energy storage systems, electric vehicles), energy market modelling, power flow simulation and multi-period optimisation for scheduling flexible energy resources.\n\nWe continue to extend OPEN as it is used on new projects.", "entities": [{"id": 996, "label": "Software", "start_offset": 4, "end_offset": 37}, {"id": 997, "label": "Software", "start_offset": 39, "end_offset": 43}, {"id": 998, "label": "Software", "start_offset": 433, "end_offset": 437}]}
{"id": 4665, "text": "This is a bespoke development from the open source Steer Suite modelling tool for agent based pedestrian simulation. The primary contributions are (i) Pedestrian navigation algorithms specific to the platform-train interface for passenger railways. (ii) Addition of social distancing as a behaviour followed by agents in the railway environment. (iii) Calibrated real-world behaviour on compromise in social distancing when subject to incentives to board or alight public rail passenger transport. (iv) Extension to consider behaviour of groups, and the influence of luggage on movement.", "entities": []}
{"id": 4666, "text": "A visualisation tool for spectral imaging data", "entities": []}
{"id": 4667, "text": "Provide pre- and post-processing tools for the FVCOM hydrodynamic model.", "entities": []}
{"id": 4668, "text": "Python tools for interrogating FVCOM model data.", "entities": []}
{"id": 4669, "text": "The FLIGHT model is a three dimensional model of light interaction with the land surface, suitable for modelling canopy photosynthesis, radiation absorption and spectral reflectance. It is suitable for developing application in remote sensing and land surface modelling. Under NERC funding, the model was extended to simulate space borne lidar, intended to improve remote sensing of forest structure.", "entities": [{"id": 799, "label": "Software", "start_offset": 4, "end_offset": 16}]}
{"id": 4670, "text": "CamoGAN uses Generative Adversarial Networks to simulate an evolutionary arms race between camouflage of a synthetic prey and its predator. CamoGAN can be used to evolve progressively more effective concealment against an artificial predator.", "entities": [{"id": 999, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 1000, "label": "Software", "start_offset": 140, "end_offset": 147}]}
{"id": 4671, "text": "CamoGAN uses Generative Adversarial Networks to simulate an evolutionary arms race between camouflage of a synthetic prey and its predator. CamoGAN can be used to evolve progressively more effective concealment against an artificial predator.", "entities": [{"id": 1208, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 1209, "label": "Software", "start_offset": 140, "end_offset": 147}]}
{"id": 4672, "text": "A new solver has been under development under my lab for generalised modelling of cryogenic fluids with various functionalitis including supercritcal fluids, real fluid themrodynamics compressibility, heat tranfer and fluid solid interactions", "entities": []}
{"id": 4673, "text": "We have developed withn OpenFoam (OpenSource) a new method to model the real fluid thermodynamics of cryogenic fluids at a range of temperatures and pressures based on polynomial fitting of NIST data base. \n\nSome initial results are presented in 2. M.Jaya Vignesh, S. Harvey A. Atkins, P. Atkins1, G. De Sercey, M.Heikal, R. Morgan,, K. Vogiatzaki, Use of cryogenic fluids for zero toxic emission hybrid engines, IMechE, Internal Combustion Engines and Powertrain Systems for Future Transport Conference, 2019. \n\nOne more paper (currently invited for publicaiton at Energies) is under preparation", "entities": []}
{"id": 4674, "text": "A new solver has been developed for treating the interaction of cryogenic fluids with surfaces. This software update is relevant to a new library added to the code relevant to the interface treatment of fluid structures interacting with solid surfaces. The code has been under development the year 2020-2023 and this update was published in the followin publications : \n\n\nG. Tretola and K. Vogiatzaki. Unpicking the interplay of turbulence, diffusion and thermophysics in cryogenic\njets at supercritical pressures. Scientific Reports, 12:2045-2322, 2022\n\nG. Tretola and K. Vogiatzaki, Numerical treatment of the interface in two phase flows using a compressible framework in OpenFOAM: Demonstration on a high velocity droplet impact case, Fluids 6(2), 78; https://doi.org/10.3390/fluids6020078, 2021\n\nG. Tretola, K. Vogiatzaki, &quot;Comparison of cryogenic and non-cryogenic droplet impact dynamics at low velocities using OpenFOAM&quot;, ICLASS, 30 August - 2 September, Edinburgh, Scotland UK 2021\n\nThe sofware is cabable of dealing with wetability problems but without heat trasnfer which is the focus on our current work and will be published as Paert 2", "entities": []}
{"id": 4675, "text": "In this study, a new three-fluid volume of fluid framework is presented in order to be used as a tool for providing physical insight-in a unified manner-to cavitating sprays and other complex multi-fluid, multiphase fluid flows. The framework accounts for phase change across a sharp interface between two fluids (gas and liquid) including miscibility between the fluid generated due to phase change (liquid vapor due to cavitation in the investigated cases) and one of the existent fluids (gaseous air). Systematic validation of the framework was performed over three cases. The first case is a bubble rising test case that an analytical solution for a two-phase system is available. Comparisons based on previous results from other interface tracking solvers and against the analytical solution are presented. This test case was then expanded by the authors so that a third non-condensable gas phase with a free-surface interface over a rising bubble was present. This second test case was used to further validate the three-fluid system behavior. Finally, experimental comparisons were made with a more realistic orthogonal spray geometry that captures different cavitation characteristics over a range of flow intensities. \n\nPublication: P. McGinn, G. Tretola, and K. Vogiatzaki, Unified modeling of cavitating sprays using a three-component volume of fluid method accounting for phase change and phase miscibility Physics of Fluids 34, 082108 (2022); https://doi.org/10.1063/5.0094196", "entities": []}
{"id": 4676, "text": "We developed a small app, that captures an image, e.g. of a face, and assesses how the grayscale intensity of the image is distorted by the diffusion and reaction processes that underlie Turing's mechanism. This will be used to explore some of the mathematical and biological ideas in a manner that requires no scientific background, to help with future public awareness activities that are planned.", "entities": []}
{"id": 4677, "text": "We have developed some general methodologies for solving reaction diffusion models of Turing systems with diverse spatial heterogeneities, including spatial curvature.", "entities": []}
{"id": 4678, "text": "This is a software platform designed by using MATLAB programming. This program will help users to calculate impact metrics by supplying exposure, hazard and vulnerability data. In addition, WP2 Application will be embedded inside this program to generate a more user friendly environment with a lot of flexibility.", "entities": [{"id": 1433, "label": "Software", "start_offset": 190, "end_offset": 205}]}
{"id": 4679, "text": "Updates forecasts to use 1985-2005 as model input (1984-2004 forecasts are still included in the forecasts folder). Updates code to include pairwise comparison plots and fix minor issues in running.", "entities": []}
{"id": 4680, "text": "The model aims to forecast the spatial distribution of urban settlements in line with the SDGs and for the assessment of future disaster risk using open-access multi-temporal satellite imagery spanning approximately the last 20 years. The framework applicable to everywhere on Earth is revealed since it depends on open data and well-known machine learning RF algorithm and supports the authorities in terms of;\nUrban growth estimation, \nSupport decision-making mechanisms, \nBetter planning, \nRisk mitigation.", "entities": []}
{"id": 4681, "text": "Two independently working software options (QGIS script and standalone executable) for excluding requested layers from land-use plan.", "entities": []}
{"id": 4682, "text": "Three independently working software options (MATLAB script, Python script and standalone executable) for generating XY coordinates and footprints from tabular data.", "entities": []}
{"id": 4683, "text": "The online version of the capacity strengthening material (to be uploaded when complete)", "entities": [{"id": 1210, "label": "Software", "start_offset": 26, "end_offset": 58}]}
{"id": 4684, "text": "A publicly available web dashboard to compare impact metrics for different land-use scenarios.", "entities": []}
{"id": 4685, "text": "The software is a by-product of a paper that currently is under review. It has been developed to analyse a transportation network around the Fikirtepe neighbourhood in Istanbul, Turkey.", "entities": []}
{"id": 4686, "text": "Github repository related to the physical impact model scoring system", "entities": [{"id": 556, "label": "Software", "start_offset": 32, "end_offset": 69}]}
{"id": 4687, "text": "This software forms the computational model of the preliminary version of the operational DSE published in Earth's Future", "entities": []}
{"id": 4688, "text": "This program will help users to generate building, household and individual layer dataset just by giving land use data along with some probability distributions. Users will be able to generate synthetic dataset by using this program with their own customisation.", "entities": []}
{"id": 4689, "text": "Github repository related to the first consistent Tomorrowville data schema", "entities": [{"id": 1211, "label": "Software", "start_offset": 50, "end_offset": 75}]}
{"id": 4690, "text": "Open source flood and landscape evolution model. The original model was developed in the University of Edinburgh prior to the start of the hub. My work in the hub has improved the model so that it can be used in more diverse geographic locations and can incorporate different drivers of flooding. The model has also been tested and calibrated in an urban context for the first time. \n\nThe current version was released (update) in 2021", "entities": [{"id": 1434, "label": "Software", "start_offset": 12, "end_offset": 47}]}
{"id": 4691, "text": "Digital platform to carry out the future visioning activities on a webtool", "entities": []}
{"id": 4692, "text": "SPCAM-KPP comprises the Super-Parameterized Community Atmospheric Model (SPCAM), coupled to the multi-column implementation of the K Profile Parameterization (KPP) one-dimensional ocean model. SPCAM was developed previously by the Center for Multi-scale Modelling of Atmospheric Processes at Colorado State University. It is based on the National Center for Atmospheric Research Community Atmospheric Model (CAM), but replacing the conventional convective parameterization with a cloud-resolving model. Our work has been to couple SPCAM to the multi-column KPP model, which was developed at the National Centre for Atmospheric Science. The coupled model allows atmosphere-ocean interactions while maintaining a realistic ocean mean state through corrections to ocean temperature and salinity.", "entities": [{"id": 557, "label": "Software", "start_offset": 9, "end_offset": 81}]}
{"id": 4693, "text": "The product connects wi-fi plugs connected to the internet and provides statistics for their use. There is an administrator dashboard available and a user-level dashboard. All data are collected and used for the experiments we conducted.", "entities": []}
{"id": 4694, "text": "Infineon Technologies collaborated with XAIN AG on a Minimal Viable Product that uses blockchain technology to program more secure usage control of cars through consumer-facing apps and where the usage control is executed on an electronic control unit as used in cars, embedded devices that do hot have an operating system on them. We refer to the official press release by Infineon Technologies: https://www.infineon.com/cms/en/about-infineon/press/press-releases/2018/INFATV201810-005.html\n\nThis work was influenced by the publications \n\nLeif-Nissen Lundbaek, Daniel Janes Beutel, Michael Huth, Stephen Jackson, Laurence Kirk, Robert Steiner, Proof of Kernel Work: a democratic low-energy consensus for distributed access-control protocols, Published on 8 August 2018 in the journal Royal Society Open Science\nhttps://royalsocietypublishing.org/doi/full/10.1098/rsos.180422\n\nand the Yellow Paper on the FROST Access Control Language, e.g. available at https://xain.foundation/assets/downloads/xain-frost-yellow-paper.pdf.", "entities": [{"id": 1001, "label": "Software", "start_offset": 53, "end_offset": 76}]}
{"id": 4695, "text": "An open IoT data management platform based on CKAN to support the storage and distribution of highways maintenance datasets", "entities": [{"id": 1212, "label": "Software", "start_offset": 3, "end_offset": 36}]}
{"id": 4696, "text": "The main purpose of the developed software is to assist the user in better understanding of gene expression data via a suitable construction and further analysis of (hidden) networks. Previously the CS team had developed an early network analysis software allowing analysis, manipulation and visualization of generic networked data. The software developed as a part of this project provides a pipeline that conveniently incorporates a number of already used by biologists data processing and analysis mechanisms previously handled manually. More particularly, all elements/features of the pipeline are introduced as additional modules to the existing network analysis/visualization software tool. The main features incorporated into the software include:\n\n\n\n- the ability to load data in the form of an Expression Matrix and a ranked list/lists of genes. \n\n(With options to view and select the required information from these files)\n\n\n\n- the automated use of the SOTA: Self Organising Tree Algorithm to cluster the genes provided. \n\n(the user has control over the input parameters if required)\n\n\n\n- gene set enrichment capabilities \n\n(with user control over input parameters)\n\n\n\n- functional annotation of genes and clusters\n\n(with user control over input parameters)\n\n\n\n- automated use of ARACNE algorithm to construct networks.\n\n(the user is given the choice of building either a network based on individual genes or the clusters created by the SOTA algorithm)\n\n\n\n- various colouring capabilities to aid with cluster visualization in the main window of the software.\n\n\n\n- data display windows to enable users to easily click on a gene or cluster in the network and gain access to the data procured from the above features.", "entities": []}
{"id": 4697, "text": "TractoR is a flexible and integrated package for medical image analysis based on the open-source R platform for statistical computing. It provides interfaces for technical and less technical users, to allow them to perform image manipulation and brain connectivity analyses on their own data. It is also the context in which our methodological work is first developed and made publicly available to the community.\n\nThe software is being updated on a rolling basis during the course of the project, to include the methodological advances arising from it.", "entities": [{"id": 1666, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4698, "text": "Lare3d configuration required to generate data used/analysed in the &quot;Flux Rope Formation..&quot; manuscript, accepted for publication in Solar Physics", "entities": [{"id": 558, "label": "Software", "start_offset": 0, "end_offset": 20}]}
{"id": 4699, "text": "The research findings informed the development of a web-based tool for profiling the design for occupational safety and health organisational capability of design firms. The tool is called &quot;Design for Occupational Safety and Health Capability Maturity Indicator (DfOSH-CMI)&quot;. Details about the tool is available at https://www.sciencedirect.com/science/article/pii/ S0925753519303789?via=ihub.", "entities": [{"id": 800, "label": "Software", "start_offset": 195, "end_offset": 266}, {"id": 801, "label": "Software", "start_offset": 268, "end_offset": 277}, {"id": 802, "label": "Software_Url", "start_offset": 325, "end_offset": 402}]}
{"id": 4700, "text": "CoastalME is a modelling environment to simulate decadal and longer coastal morphological changes.\n\nIt is an engineering tool for advanced modellers seeking to simulate the interaction of multiple coastal landforms and different types of human interventions Payo et al. (2015).\n\nPayo et al., (2016) described in detail the rationale behind CoastalME and demonstrated how it can be used to integrate; the Soft Cliff and Platform Erosion model SCAPE, the Coastal Vector Evolution Model COVE and the Cross Shore model CSHORE.\n\nThe software is written in C++ following the object oriented paradigm and has been documented using Doxygen.\n\nThe C++ source code is available for download under GNU open source license.\n\nCreation and visualization of all inputs an ouputs can be done using your prefereed text editor (i.e. Notepad++ for the config files) and QGIS (for the raster and vector output files).", "entities": [{"id": 1002, "label": "Software", "start_offset": 0, "end_offset": 9}, {"id": 1003, "label": "Software", "start_offset": 340, "end_offset": 349}]}
{"id": 4701, "text": "UNITY - a programming tool for creating immersive virtual environments.", "entities": [{"id": 1213, "label": "Software", "start_offset": 0, "end_offset": 5}]}
{"id": 4702, "text": "The EpiGraphDB-ASQ (ASQ; /??sk/ i.e. &quot;ask&quot;) interface is a natural language interface to query the integrated epidemiological evidence of the EpiGraphDB data and ecosystem. The starting point of the query is either a short paragraph of text from which ASQ will derive and extract claim triples, or users can supply those claim triples directly. ASQ will retrieve data from EpiGraphDB, both biomedical entities and evidence from various sources, to faciliate the triangulation of the evidence regarding a specific claim.", "entities": [{"id": 1435, "label": "Software", "start_offset": 4, "end_offset": 18}, {"id": 1436, "label": "Software", "start_offset": 355, "end_offset": 358}, {"id": 1438, "label": "Software", "start_offset": 262, "end_offset": 265}]}
{"id": 4703, "text": "This code reproduces all the results presented in the article Core Imaging Library Part I: a versatile python framework for tomographic imaging by Jakob S. J&oslash;rgensen, Evelina Ametova, Genoveva Burca, Gemma Fardell, Evangelos Papoutsellis, Edoardo Pasca, Kris Thielemans, Martin Turner, Ryan Warr, William R. B. Lionheart, and Philip J. Withers which will be available from 5 July 2021 at https://doi.org/10.1098/rsta.2020.0192 A preprint is available from arXiv: https://arxiv.org/abs/2102.04560 Instructions are available in the file README.md as well as at the source GitHub repository https://github.com/TomographicImaging/Paper-2021-RSTA-CIL-Part-I", "entities": [{"id": 1667, "label": "Software_Url", "start_offset": 595, "end_offset": 659}]}
{"id": 4704, "text": "CIL is an open-source mainly Python framework for tomographic imaging for cone and parallel beam geometries. It comes with tools for loading, preprocessing, reconstructing and visualising tomographic data.", "entities": [{"id": 560, "label": "Software", "start_offset": 0, "end_offset": 3}]}
{"id": 4705, "text": "Good software development practices have been implemented, including software code project management, version control, issue tracking, and systematic code testing and builds.", "entities": []}
{"id": 4706, "text": "This code reproduces all the results presented in the article Core Imaging Library Part II: multichannel reconstruction for dynamic and spectral tomography by Evangelos Papoutsellis, Evelina Ametova, Claire Delplancke, Gemma Fardell, Jakob S. J&oslash;rgensen, Edoardo Pasca, Martin Turner, Ryan Warr, William R. B. Lionheart, and Philip J. Withers which will be available from 5 July 2021 at https://doi.org/10.1098/rsta.2020.0193 A preprint is available from arXiv: https://arxiv.org/abs/2102.06126 Instructions are available in the file README.md as well as at the source GitHub repository https://github.com/TomographicImaging/Paper-2021-RSTA-CIL-Part-II", "entities": [{"id": 1004, "label": "Software_Url", "start_offset": 593, "end_offset": 658}]}
{"id": 4707, "text": "MWASTools provides a complete pipeline to perform metabolome-wide association studies. Key functionalities of the package include: quality control analysis of metabonomic data; MWAS using different association models (partial correlations; generalized linear models); model validation using non-parametric bootstrapping; visualization of MWAS results; NMR metabolite identification using STOCSY; and biological interpretation of MWAS results.", "entities": [{"id": 1214, "label": "Software", "start_offset": 0, "end_offset": 9}, {"id": 1215, "label": "Software", "start_offset": 177, "end_offset": 181}, {"id": 1216, "label": "Software", "start_offset": 338, "end_offset": 343}, {"id": 1217, "label": "Software", "start_offset": 429, "end_offset": 433}]}
{"id": 4708, "text": "MetaboSignal is an R package that allows merging, analyzing and customizing metabolic and signaling KEGG pathways. It is a network-based approach designed to explore the topological relationship between genes (signaling- or enzymatic-genes) and metabolites, representing a powerful tool to investigate the genetic landscape and regulatory networks of metabolic phenotypes.", "entities": [{"id": 1439, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 4709, "text": "Enable causal inference using Mendelian randomisation across multiple ancestries", "entities": []}
{"id": 4710, "text": "Tardigraph is a bash script developed by Martino Morandi which generates live editable Graphviz diagrams. It was motivated by a fascination for how diagramming both influences and is in friction with our understanding of relations. It brings together the moment of considering with others how something &quot;is the same as&quot; &quot;is NOT&quot; or maybe &quot;is sort of like&quot; something else, next to the limited mode in which these relations are translated into the network imaginaries of AT&amp;T. To allow live editing, this script requires an Etherpad installation running, either locally or on a friendly instance, as long as the web server allows the etherpad page to be loaded inside an iframe.", "entities": [{"id": 563, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 4711, "text": "wiki-to-pdf is a contraption for ongoing publication efforts. It is developed by Martino Morandi for TITiPI and combines the collaborative editing possibilities of Mediawiki with the pdf-in-the-browser approach of the pagedjs library to produce paginated, elastic, malleable and re-editable publications for printing and on-line reading.", "entities": [{"id": 803, "label": "Software", "start_offset": 0, "end_offset": 11}]}
{"id": 4712, "text": "Burrow is a rudimentary script for archiving interdependent etherpad collections that might be distributed over multiple servers and etherpad installs. It is developed by Aggeliki Diakrousi (TITiPI) and aimed at users that don't have access to the server that hosts their etherpad files or that work across different groups with each their own etherpad installations. Burrow offers a simple back-up plan for when pads are down or when needing to work off-line. Burrow protects against the unwanted loss of expired pads and lessens the dependency on always being connected. It also goes against the tendency to centralize installations, and towards a non-sovereign infrastructure approach.", "entities": [{"id": 1005, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 1006, "label": "Software", "start_offset": 368, "end_offset": 374}, {"id": 1007, "label": "Software", "start_offset": 461, "end_offset": 467}]}
{"id": 4713, "text": "Automatic analysis software for quantifying traits in Microphenotron images", "entities": []}
{"id": 4714, "text": "Probabilistic Swarm Verifier for Faulty systems is a software package for the verification of properties in probabilistic swarm systems that may exhibit faults. Further information can be found in the corresponding paper (published at IJCAI 2020).", "entities": [{"id": 1440, "label": "Software", "start_offset": 0, "end_offset": 28}]}
{"id": 4715, "text": "PSV provides a toolkit for verifying properties of unbounded probabilistic multi-agent systems. It combines our previous toolkits PSV-BD, PSV-CA, PSV-F, and PSV-S to support all the models and specifications that they did in one unified software package.", "entities": []}
{"id": 4716, "text": "Probabilistic Swarm Verifier for Strategic properties is a software package for the verification of strategic properties in probabilistic swarm systems. Further information can be found in the corresponding paper (published at AAMAS 2020).", "entities": [{"id": 565, "label": "Software", "start_offset": 0, "end_offset": 53}]}
{"id": 4717, "text": "Probabilistic Swarm Verifier for BoundeD time properties is a software package for the verification of emergence of bounded time properties in probabilistic swarm systems. Further information can be found in the corresponding paper (published at IJCAI 2018).", "entities": [{"id": 804, "label": "Software", "start_offset": 0, "end_offset": 56}]}
{"id": 4718, "text": "Probabilistic Swarm Verifier using Counter Abstraction is a software package for the verification of properties in probabilistic swarm systems. Further information can be found in the corresponding paper (published at AAMAS 2019).", "entities": [{"id": 1008, "label": "Software", "start_offset": 0, "end_offset": 29}]}
{"id": 4719, "text": "We have expanded and improved the core L2D materials and modes and mechanisms of delivery in response to adapting to routine delivery at the 100+ learner scale. WE have continued our rolling programme of continual improvements in content and delivery of the majority of our high-quality materials. Three have been significant innovations in three areas. Firstly on-line monitoring, automatic distribution, tutor grading and return with feedback of learner assignments and assessments. Secondly, tutor support through a portal to book 1-2-1 focus sessions with tutors for assistance with course difficulties. Thirdly issuing of certification for course components passed by learners.", "entities": []}
{"id": 4720, "text": "We provide live-streamed, interactive training webinars weekly/bi-weekly, where we deliver our training materials, and extensions on it, live to remotely attending students. The webinars comprise live, step-by-step programming training, with a team of tutors on standby to help answer student queries, on an individual, one-to-one basis. The webinars also comprise interactive exercises and problems that the students work on collaboratively, in small groups. The solutions are then shared and worked through with the entire group, once the exercise has been completed.", "entities": []}
{"id": 4721, "text": "In an effort to migrate from the Moodle VLE, we have developed infrastructure to handle and support students learning, via GitHub Classroom. The platform provides an easily navigable and manageable interface for students, instructors and tutors, to manage all aspects of the course. The portal allows students to login with their GitHub profiles, and allows access to all learning materials, together with topic-specific forums, where students can interact, and post questions that we can review, and reply to. The system also generates repositories for individual students, complemented by a clear set of instructions and tutorial video, that instructs them how to submit assignments required throughout the course; such that we can easily access and manage these, grade them, and return them to the students.", "entities": []}
{"id": 4722, "text": "We spent time developing and transitioning our written learning and training materials, and incorporating these into Sandpaper. The lesson template / infrastructure makes use of three R packages; namely Sandpaper, Varnish and Pegboard. These packages and the materials have been tailored and designed to fit the aesthetics and teaching requirements of the L2D course, and reflect our materials in a way that is unique to our project. The materials are hosted online, on GitHub.", "entities": [{"id": 566, "label": "Software", "start_offset": 203, "end_offset": 212}, {"id": 567, "label": "Software", "start_offset": 214, "end_offset": 221}, {"id": 568, "label": "Software", "start_offset": 226, "end_offset": 234}]}
{"id": 4723, "text": "We have expanded greatly the provision of live-streamed, interactive training webinars weekly/bi-weekly training webinars. The comprise live, step-by-step programming training, with a team of tutors on standby to help answer student queries, on an individual, one-to-one basis. Interactive exercises and problems that the students work on collaboratively, in small groups are also featured. The solutions are then shared and worked through with the entire group, once the exercise has been completed.", "entities": []}
{"id": 4724, "text": "We filmed and edited to a very high professional standard in excess of 88 tutorial and webinar videos. We established a green screen filming studio, recording video materials specifically designed to complement the written course materials that we provide for our students. These are filmed in 4K resolution, with binaural audio, and code and figures are animated to make the videos easy to follow along with, and paced, so that students can learn, and code while watching.", "entities": []}
{"id": 4725, "text": "There has been further creation and transposition of written learning and training materials, into Sandpaper (again using three R packages Sandpaper, Varnish and Pegboard) with continued hosting, distribution and interaction through GitHub.. There were small adaptations in aesthetics to continue to give a unique look and feel to the course .", "entities": []}
{"id": 4726, "text": "We filmed and edited to a very high professional standard a further 17 very high-quality support videos and 19 further tutorial videos expanding recorded materials provision by 40%. Work was undertaken in a new bespoke &quot;pop-up&quot; mobile green screen filming studio equipped with professional quality video and sound recording equipment. All productions (at 4K resolution with binaural sound) are specifically designed to complement our written course materials and feature animated code and figures for students to follow and implement at their own speed whilst viewing.", "entities": []}
{"id": 4727, "text": "We expanded our footprint and infrastructure on GitHub Classroom as the central hosting platform for students to login with their GitHub profiles and access to all L2D learning materials. Here students can easily join topic-specific forums to post questions and receive replies. Students create their own repositories and receive study instructions and guidance and details for submission of assignments. This greatly eases access and programme and student management.", "entities": [{"id": 1668, "label": "Software", "start_offset": 72, "end_offset": 96}]}
{"id": 4728, "text": "An expanded package of training materials in data handling and elements of machine learning applied to biosciences was created for live e-learning following earlier successful field testing.\n\nFollowing an earlier successful, small-scale field test of e-learning packages with 10 participants in London, Newcastle and Edinburgh, and later participation of 50 users in May 2021, engagement was scaled to 100 users in November 2021 (to end May 2022) mostly based in London and Cambridge. This was the first use at scale of materials developed in the SysMIC programme but with a rolling programme of continual improvements in content and delivery of much high quality materials. This continuing process was achievable with new staff and the expertise captured in an expanded project team made possible by this Innovation Scholars: Data Science Training in Health and Bioscience (DaSH) initiative and award.", "entities": []}
{"id": 4729, "text": "This is a web-delivered physical activity tool for patients with pre-diabetes. It allows patients to access information about pre-diabetes, measure and monitor their physical activity levels using a web-based pedometer, set physical activity goals and ask questions of other patients.", "entities": [{"id": 805, "label": "Software", "start_offset": 10, "end_offset": 47}]}
{"id": 4730, "text": "Set of command-line tools that can be used for powerful astronomical catalogue interrogation, manipulation, and plotting.\n2010 releases v2.1-2, v2.2, v2.2-1\n2011 releases v2.3, v2.3-1, v2.4\n2013 releases v2.5, v2.5-1, v2.5-2\n2014 releases v2.5-3, v3.0", "entities": []}
{"id": 4731, "text": "Astronomical data-handling software", "entities": [{"id": 1218, "label": "Software", "start_offset": 0, "end_offset": 35}]}
{"id": 4732, "text": "The software, fully coded by myself, creates predicted cytochrome operons based on whole genome sequence (WGS) coding sequence DNA (CDS) from RefSeq. \nIt is good for finding novel operons in species previously not known to have any cytochromes.", "entities": []}
{"id": 4733, "text": "THANDAV' digital platform - a website from where study participants can view, download and save 'THANDAV' videos on their computers/laptops/smart phones, allowing them to practice between sessions. Participants are encouraged to practice the routines 2-3 times a week at home. The 'THANDAV' website is open to all and offers details about the 'THANDAV' program as well as educational content. Once women/girls are part of this online community, it enables them to post their queries, talk about their experiences, watch fellow 'THANDAVITES' dance videos or reels and share their own on this webpage.", "entities": [{"id": 1669, "label": "Software", "start_offset": 0, "end_offset": 25}, {"id": 1670, "label": "Software", "start_offset": 282, "end_offset": 289}, {"id": 1671, "label": "Software", "start_offset": 97, "end_offset": 104}, {"id": 1672, "label": "Software", "start_offset": 344, "end_offset": 351}]}
{"id": 4734, "text": "The is repository contains an old version of HiRep (https://github.com/claudiopica/HiRep) modified for the heatbath LLR algorthim. A version of this based on a newer version of HiRep is in progress. This repository contains the code for the LLR method used in the paper: Lucini, B., Mason, D., Piai, M., Rinaldi, E., &amp; Vadacchino, D. (2023). First-order phase transitions in Yang-Mills theories and the density of state method. arXiv preprint arXiv:2305.07463.", "entities": [{"id": 569, "label": "Software", "start_offset": 45, "end_offset": 50}, {"id": 570, "label": "Software_Url", "start_offset": 52, "end_offset": 88}, {"id": 571, "label": "Software", "start_offset": 177, "end_offset": 182}]}
{"id": 4735, "text": "I designed and implemented the volume overlapping steric repulsion algorithm in FFEA as a new method to deal with contact interactions. Accordingly, bodies feel a steric repulsion energy that is proportional to their overlapping volume, resulting into a repulsion force that is applied at the center of the overlapping volume. The force is calculated numerically as the negative gradient of this energy. Because volume is an extensive quantity, the calculation of this volume can be split into a number of parts and summed up. Furthermore, the resulting force does not depend on any path, and so it is a conservative force. The description of this force was presented also in the PLOS Computational Biology paper together with the FFEA software package.", "entities": [{"id": 806, "label": "Software", "start_offset": 31, "end_offset": 76}]}
{"id": 4736, "text": "The FFEA (Fluctuating Finite Element Analysis) is a software tool that intends to simulate large molecular systems as viscoelastic solids subject to thermal noise. The software consists of two parts, the 'runner' and the 'tools'. The runner is the part that simulates the dynamics of a molecular system given a set of input files. The 'tools' are a set of small programs that help the user through all the FFEA work-flow, together with a plugin for PyMOL for visual inspection of the systems and the resulting trajectories.\n\nBesides coding and working on the performance of the runner, I have been working on other aspects of the code release. The code has been documented, both from the user and from the developer perspectives using Doxygen and Markdown, and a tutorial has been written, all resulting in a nice web site. A test suite has been included, where short simulations of simple systems are compared to known analytical results, aiming to ensure that the physics is correctly reproduced. Finally, the building and installation processes have been fully automated using CMake, while binaries are also provided for Linux x86 64bit platforms.", "entities": [{"id": 1009, "label": "Software", "start_offset": 4, "end_offset": 8}, {"id": 1010, "label": "Software", "start_offset": 10, "end_offset": 45}, {"id": 1011, "label": "Software", "start_offset": 406, "end_offset": 410}]}
{"id": 4737, "text": "The Fertilizer Optimzer App (which can be downloaded from https://play.google.com/store/apps/details?id=org.cabi.ofra&amp;hl=en_US) is now deployed in fifteen countries, including Uganda, Kenya, Tanzania, Zambia, Ghana and Ethiopia. The largest number of download requests (536) have come from India. Since the app was first released we have had ~2.6k downloads. There have been 17.7k sessions (optimization calculations) on the app. An upgrade to the mobile phone app now offers farmers across Africa even more benefits and cutting-edge fertilizer use technology. This will help farmers to grow healthier, more productive crops with increased profitability, as a result of more informed use of how small amounts of fertilizer impact the crops they grow. Pilot work on the CABI Fertilizer Optimizer app in Uganda has shown that some farmers realised up to a seven-fold increases in yield. Using funding from the BBSRC Global Challenges Research Fund, the app has now been upgraded to make it easier to use. The new app includes an integrated soil fertility management (ISFM) practices feature, and a calibration tool which helps farmers to apply the correct quantity of fertilizer to their crops. \n\nThe Fertilizer Optimizer app is designed to help resource-constrained farmers to maximise the return on investment on fertilizer, based on what the farmer can realistically afford. In the latest version of the Fertilizer Optimizer app it is possible to calibrate the fertilizer recommendation to the planting conditions of a user's field. Version 1 of the app provided users with an amount of fertilizer to use and an application rate (e.g. 5kg per hectare). Now it is possible to enter field measurements, container sizes and preferred application technique and the app will help to evenly distribute the recommended fertilizers across the crop providing actionable information tailored to a each field.", "entities": [{"id": 1219, "label": "Software", "start_offset": 4, "end_offset": 27}, {"id": 1220, "label": "Software_Url", "start_offset": 58, "end_offset": 130}, {"id": 1221, "label": "Software", "start_offset": 773, "end_offset": 802}, {"id": 1222, "label": "Software", "start_offset": 1203, "end_offset": 1227}, {"id": 1224, "label": "Software", "start_offset": 1409, "end_offset": 1433}]}
{"id": 4738, "text": "A web-delivered tool to estimate micronutrient deficiencies and explore pathways to improve nutrition. This will have associated user-support and educational resources. The tool will be fully open access, with pre-loaded and bring-your-own data options.\nMicronutrient Action Policy Support (MAPS) tool delivers a co-designed, web-hosted tool, to enable the best possible estimates of MNDs to be communicated at national and sub-national scales in Africa. The MAPS tool is a unique enabling environment for the wider Agriculture-Nutrition community and beyond. Through novel functionality, this tool allow users to view and explore MND risks at various spatial and temporal scales. The tool provide users with dietary micronutrient supply estimates of all nations in Africa using national-scale data, which can be spatially disaggregated by population data. Where survey data on food consumption (e.g. Household Consumption and Expenditure Surveys, HCES) or food composition (e.g. GeoNutrition surveys) are available for a nation, these data will support delivery of sub-national estimates of dietary micronutrient supplies and risks of deficiency. Where both types of data are available with good spatial resolution for the geography of interest, these provide the most spatially disaggregated estimates possible.", "entities": [{"id": 1441, "label": "Software", "start_offset": 254, "end_offset": 289}, {"id": 1442, "label": "Software", "start_offset": 291, "end_offset": 295}, {"id": 1443, "label": "Software", "start_offset": 459, "end_offset": 463}]}
{"id": 4739, "text": "AtomECS is a Rust software for simulating ultracold atom experiments. It supports numerous features:\n\n Laser-cooling of atoms by optical scattering forces.\n Doppler forces on atoms that scatter light, including the random fluctuations that give rise to the Doppler temperature limit.\n Magnetic fields, implemented on a grid or through simple analytical models.\n Hot atoms generated by an oven.\n Hot atoms generated on the surface of a simulation volume (eg, to simulate thermal vapor in a chamber).\n Cooling light beams, defined by their detuning and gaussian intensity profiles.\n Volumes that define bounds for the simulation.\n File output in binary or text format.\n Thorough unit testing to ensure simulation results are correct.\n Good parallel performance on modern multi-core CPUs.\n Simulations can be wrapped using python/matlab, as shown in the source_optimisation_example or the matlab examples.\n Optical dipole force traps.\n Confinement of atoms by magnetic fields, e.g. quadrupole and TOP traps.", "entities": [{"id": 1673, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4740, "text": "PorkMart aims to deliver real-time market intelligence on the pork value chain for Uganda. It leverages stakeholder inputs, market research and state of the art data science to deliver actionable end user information", "entities": [{"id": 572, "label": "Software", "start_offset": 0, "end_offset": 8}]}
{"id": 4741, "text": "This is a mobile application for digital contact tracing tailored to haulage in East Africa\n\nhttps://play.google.com/store/apps/details?id=com.theatrucker", "entities": [{"id": 807, "label": "Software_Url", "start_offset": 93, "end_offset": 154}]}
{"id": 4742, "text": "Polysaccharide utilisation loci (PUL) are regions within bacterial genomes that encode all the necessary machinery for the cleavage of particular carbohydrates. For the Bacteroidetes phylum, prediction of PUL from genomic data alone involves the identification of carbohydrate-active enzymes (CAZymes) co-localised with susCD gene pairs. Here we present the open prediction of PUL in 5414 public Bacteroidetes genomes, and an open-source pipeline to reproduce or extend the results.", "entities": [{"id": 1012, "label": "Software", "start_offset": 0, "end_offset": 31}, {"id": 1013, "label": "Software", "start_offset": 33, "end_offset": 36}, {"id": 1014, "label": "Software", "start_offset": 205, "end_offset": 209}, {"id": 1015, "label": "Software", "start_offset": 377, "end_offset": 380}]}
{"id": 4743, "text": "Project-THEA aims to deliver an open access mobile application to support track and trace tailored to the haulage industry. The tool is designed to combine anonymized time-stamped geo-location information relative to the road infrastructure with COVID-19 test results, to not only support public health efforts to limit transmission but also the safe reopening of economies. Critically the efficiency in track and trace enhances the flow of the regional supply chain as well as strategic allocation of public health surveillance resources.\nNB: The tool is open access but the data access is limited to public health institutions. This way its use is not limited to East Africa.", "entities": []}
{"id": 4744, "text": "This is a digital platform to enable one heath pathogen surveillance, it supports metadata capture and integration at point of capture, analysis, sharing and archiving of surveillance data at the one health interface", "entities": []}
{"id": 4745, "text": "Craft Shelf is a web app designed by Bow Software in collaboration with the Devon Guild of Craftsmen and Dr Thomas. It connects the consumer who buys craft from the Devon Guild to the makers who make the work.", "entities": [{"id": 1674, "label": "Software", "start_offset": 0, "end_offset": 11}]}
{"id": 4746, "text": "This is a website that records and presents the Gloucestershire Guild of Craftsmen History.", "entities": []}
{"id": 4747, "text": "This software is designed to work as a part of the SewerBatt acoustic sensing technology or independently with data files saved in the standardised format. It is capable of detecting, locating and classifying the conditions in underground pipes.", "entities": []}
{"id": 4748, "text": "Openly available version of the software was developed, publicized and widely used in specific case studies.\nFollowing practitioner uptake and demand this has now been incorporated into leading commercial software packages used by water companies internationally. Packages include Synergi, produced by DNV-GL and Infoworks, produced by Innovyze.\nWater companies would not reply on the freeware versions for business critical activities, and requested that their software providers integrated our research model functionality.", "entities": [{"id": 1018, "label": "Software", "start_offset": 281, "end_offset": 288}, {"id": 1019, "label": "Software", "start_offset": 312, "end_offset": 322}]}
{"id": 4749, "text": "PUrE Intrawise is a sustainability assessment software. It integrates life cycle assessment geographical information systems (GIS), multi-criteria decision analysis and uncertainty analysis. It helps to identify the most sustainable options out of the alternative products or activities being considered, taking into account environmental, economic and social aspects.", "entities": [{"id": 1226, "label": "Software", "start_offset": 0, "end_offset": 14}]}
{"id": 4750, "text": "To enable wider use of EMA data from the ESPF facility, Articulate Instruments Ltd produced an extra component of the AAA software programme specifically to handle EMA data. This commerically-available software, designed for articulatory speech analysis, therefore provides the opportunity for users familiar with other articulatory data to access and analyse EMA data without having to learn new software. In addition, the company's contribution to the design of the facility enables synchronised collection of EPG (electropalatography) data.", "entities": []}
{"id": 4751, "text": "A deck of cards was designed by the UNIMAS CreativeCulture team to introduce educators to the idea of adopting gamification in learning in their classrooms. The acronym PLAY is derived from the phrases &quot;Pick-Look-Activate-Yield,&quot; which stand for the typical processes in lesson planning. It was completed in 2018. The finished online version is now accessible and usable online since 2022.", "entities": []}
{"id": 4752, "text": "PyOP2 is a domain-specific language (DSL) for the parallel executions of computational kernels on unstructured meshes or graphs.\n\nPyOP2 is a key enabling abstraction on which the Firedrake Project is built. It is based on concepts from OP2 (https://github.com/OP2/OP2-Common, http://www.oerc.ox.ac.uk/projects/op2) but is implement in Python and entirely at runtime, rather than as a source-to-source compiler-time tool. It includes substantial extensions and optimisations, mainly to support finite element applications.", "entities": [{"id": 573, "label": "Software", "start_offset": 0, "end_offset": 5}, {"id": 574, "label": "Software", "start_offset": 130, "end_offset": 135}]}
{"id": 4753, "text": "Firedrake is an automated system for the portable solution of partial differential equations using the finite element method (FEM). Firedrake enables users to employ a wide range of discretisations to an infinite variety of PDEs and employ either conventional CPUs or GPUs to obtain the solution.", "entities": [{"id": 808, "label": "Software", "start_offset": 0, "end_offset": 9}, {"id": 809, "label": "Software", "start_offset": 132, "end_offset": 141}]}
{"id": 4754, "text": "OP2 is framework for the execution of unstructured grid applications on clusters of GPUs or multi-core CPUs. Although OP2 is designed to look like a conventional library, the implementation uses source-source translation to generate the appropriate back-end code for the different target platforms.", "entities": [{"id": 1020, "label": "Software", "start_offset": 0, "end_offset": 3}, {"id": 1021, "label": "Software", "start_offset": 118, "end_offset": 121}]}
{"id": 4755, "text": "Publicly released Python code for determining the true source of exoplanet transit-like events in TESS photometry.", "entities": []}
{"id": 4756, "text": "This Sage module provides functions for estimating the concrete security of Learning with Errors instances. The main purpose of this estimator is to give designers an easy way to choose parameters resisting known attacks and to enable cryptanalysts to compare their results and ideas with other techniques known in the literature.", "entities": []}
{"id": 4757, "text": "Lattice reduction software that implements the most recent theoretical and practical advancements.", "entities": [{"id": 1675, "label": "Software", "start_offset": 0, "end_offset": 26}]}
{"id": 4758, "text": "A web tool to allow volcanologists to determine the volume of a volcanic deposit from their own field data", "entities": []}
{"id": 4759, "text": "EvoSuite is an automated unit test generation tool for Java. It takes as input a Java class, and produces a JUnit test suite optimised for branch coverage.", "entities": [{"id": 810, "label": "Software", "start_offset": 0, "end_offset": 8}]}
{"id": 4760, "text": "This grant is all about the brain response to visual symmetry. We have develop a public database with over 1TB of EEG data. We have developed a downloadable app for data visualization. A GUI allows uses to enter datasets, electrodes and timewindows. This is a far more complete way to archive humanities scientific record.", "entities": []}
{"id": 4761, "text": "De novo DNA synthesis is in need of new ideas for increasing production rate and reducing cost. DNA reuse in combinatorial library construction is one such idea. Here, we describe an algorithm for planning multistage assembly of DNA libraries with shared intermediates that greedily attempts to maximize DNA reuse, and show both theoretically and empirically that it runs in linear time. We compare solution quality and algorithmic performance to the best results reported for computing DNA assembly graphs, finding that our algorithm achieves solutions of equivalent quality but with dramatically shorter running times and substantially improved scalability. We also show that the related computational problem bounded-depth min-cost string production (BDMSP), which captures DNA library assembly operations with a simplified cost model, is NP-hard and APX-hard by reduction from vertex cover. The algorithm presented here provides solutions of near-minimal stages and thanks to almost instantaneous planning of DNA libraries it can be used as a metric of ?manufacturability? to guide DNA library design. Rapid planning remains applicable even for DNA library sizes vastly exceeding today's biochemical assembly methods, future-proofing our method.", "entities": []}
{"id": 4762, "text": "The webserver presented here provides solutions of near-minimal stages and thanks to almost instantaneous planning of DNA libraries it can be used as a metric of ?manufacturability? to guide DNA library design. Rapid planning remains applicable even for DNA library sizes vastly exceeding today's biochemical assembly methods, future-proofing our method.", "entities": []}
{"id": 4763, "text": "Software for automated detection and extraction of sperm flagellar motion", "entities": []}
{"id": 4764, "text": "These tools simplify the rool out of customised ENSEMBL databases.", "entities": []}
{"id": 4765, "text": "jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj", "entities": []}
{"id": 4766, "text": "The point energy technology is developed for SMEs to improve the insight of the energy usage in the manufacturing processes, initially used for plastics and food sectors, and the most recent one was installed in a local bakery in Northern Ireland.", "entities": []}
{"id": 4767, "text": "Sankey diagrams are used to visualise flows and use of resources, but constructing them can be time-consuming. This software allows many diagrams to be easily generated from the results of a study to present different viewpoints.", "entities": []}
{"id": 4768, "text": "Code and data supporting the paper &quot;Incremental Material Flow Analysis with Bayesian Inference&quot;", "entities": []}
{"id": 4769, "text": "A Python library for the automated design of molcules.", "entities": []}
{"id": 4770, "text": "The software implements the methods for emergent constraints from our paper &quot;How are emergent constraints quantifying uncertainty and what do they leave behind?&quot; This is a fully Bayesian interpretation of emergent constraints with software for guided elicitation of key uncertainties needed in the analysis, plus a suite of diagnostic tools for model checking etc. We provide detailed instructions for use with the software and demonstrate its use in the paper.", "entities": []}
{"id": 4771, "text": "Visual exploration of gene expression within the context of an anatomy ontology.", "entities": []}
{"id": 4772, "text": "To identify and resolve inconsistencies between selected gene expression databases.", "entities": []}
{"id": 4773, "text": "Linear-scaling density-functional theory code for understanding and predicting the properties of materials from first-principles quantum mechanics.", "entities": [{"id": 1228, "label": "Software", "start_offset": 0, "end_offset": 45}]}
{"id": 4774, "text": "onetep is linear scaling density functional theory code. under a commercial license free to use for academics", "entities": [{"id": 1444, "label": "Software", "start_offset": 0, "end_offset": 6}]}
{"id": 4775, "text": "An updated version of ONETEP within Dassault Systemes BIOVIA's Materials Studio 2024 release.", "entities": [{"id": 1676, "label": "Software", "start_offset": 22, "end_offset": 28}]}
{"id": 4776, "text": "pybela, developed by QMUL PhD researcher Teresa Pelinski with support from the Augmented Instruments Laboratory and an industrial internship at Bela (http://bela.io), is a toolchain and workflow for training AI models to deploy on the Bela embedded hardware platform. pybela consists of tools for capturing data on a Bela embedded platform (a 1GHz ARM-Linux computer running a real-time operating system), transferring the data to python running on a host computer for training models in pytorch, and deploying lightweight models back on the Bela board.", "entities": [{"id": 575, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 576, "label": "Software", "start_offset": 268, "end_offset": 274}]}
{"id": 4777, "text": "we built a VR software where respondents can interact with automated vehicles circulating in a &quot;real&quot; street and cross a real street in both Newcastle and Toronto where vehicles are running at different speed, in different composition (number of vehicles, types of vehicles, automated and normal) and under different weather conditions (sunny, rainy, snowing) and different time of the day, (morning or night).\n\nThe software has been tested with a pilot of colleagues and students until March 2020, then with other participants, both in the UK and in Canada. The software is now completed and used to collect data. \n\nThe experiment has been complete, all data collected, in both the UK and Canada and data already analysed and we are working on producing the relevant publications.", "entities": []}
{"id": 4778, "text": "we built a VR software where respondents can interact with automated vehicles circulating in a &quot;real&quot; street and select a taxi that can be a normal one with driver or an automated taxi. The street is &quot;real&quot; in the sense that we reproduce in the VR environment a street that exists and where there is currently a taxi rank for normal taxi\n\nThe software has been tested with a pilot of colleagues and students until March 2020, before the start of the lockdown. Since then we kept working on it, but we could only test it among ourselves, the researchers (as covid did not allow to have any external participants to test the VR). We have managed to advance. The software is now ready 90%, but need to have a final test with &quot;real&quot; participants. Unfortunately, the VR uses headsets, and due to covid, it is not yet possible to do any real tests. \n\nThe software has been updated in 2022, re-tested and used to run lab experiments in both Newcastle and Toronto. the lab experiment is concluded in Newcastle, in progress in Toronto.\nThe experiment has been complete also in Toronto and data already analysed and we are working on producing the relevant publications.", "entities": []}
{"id": 4779, "text": "Developed a software to package improve the adjustment of kinetic data to non-linear mechanistic functions. The manuscript is in preparation.", "entities": []}
{"id": 4780, "text": "PepFoot allows rapid analysis and visualisation of protein footprinting data, in particular at the peptide-level. LC-MS data from all major instrument vendors can be processed once converted to the open source format '.mz5', allowing open and reproducible analysis. A key feature of the software is semi-automated batch processing -- where the user will manually process a single representative data file (aided by the software) and subsequent analysis of all remaining data files is handled by the software -- which greatly reduces processing times and tackles human error in analysis of large and complex data-sets. The processed data are then automatically visualised, using an open-source PDB viewer, to allow identification of sites of interest. The output of the software is itself human-readable and open-source, allowing reproducible sharing of the analyses.", "entities": [{"id": 1445, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4781, "text": "Python implementation of a charge positioning algorithm for gas-phase molecular dynamics", "entities": []}
{"id": 4782, "text": "Custom designed and built website to disseminated education and training materials in relation to the 3Hs (Housing, Handling and Habituation) initiative. The website is built around 3 core modules with background material and demonstration videos and a CPD course users can complete. Additional resources such as guidance documents and more detailed protocols are also available. The site launched Feb 2024 and will continue to be developed.", "entities": []}
{"id": 4783, "text": "BioDynaMo is a software platform to easily create, run, and visualise 3D agent-based simulations. It enables cutting edge research in computational biology. It is highly performing and optimized to harness the computational power of modern hardware. Moreover, due to its modular architecture, it has been adapted for cryopreservation modelling.", "entities": [{"id": 811, "label": "Software", "start_offset": 0, "end_offset": 9}]}
{"id": 4784, "text": "The OSKAR package consists of a number of applications for the simulation of astronomical radio interferometers. OSKAR has been designed primarily to produce simulated visibility data from large aperture arrays, such as those envisaged for the SKA. The computation performed by OSKAR applications is accelerated using NVIDIA graphics processing units (GPUs).", "entities": [{"id": 1022, "label": "Software", "start_offset": 4, "end_offset": 10}, {"id": 1023, "label": "Software", "start_offset": 113, "end_offset": 118}, {"id": 1024, "label": "Software", "start_offset": 278, "end_offset": 283}]}
{"id": 4785, "text": "CellPhoneDB is a publicly available repository of curated receptors, ligands and their interactions. Subunit architecture is included for both ligands and receptors, representing heteromeric complexes accurately. This is crucial, as cell-cell communication relies on multi-subunit protein complexes that go beyond the binary representation used in most databases and studies.\n\nCellPhoneDB integrates existing datasets that pertain to cellular communication and new manually reviewed information. CellPhoneDB utilises information from the following data bases: UniProt, Ensembl, PDB, the IMEx consortium, IUPHAR.\n\nCellPhoneDB can be used to search for a particular ligand/receptor or interrogate your own single-cell transcriptomics data.", "entities": [{"id": 1229, "label": "Software", "start_offset": 0, "end_offset": 11}, {"id": 1230, "label": "Software", "start_offset": 377, "end_offset": 388}, {"id": 1231, "label": "Software", "start_offset": 496, "end_offset": 507}, {"id": 1232, "label": "Software", "start_offset": 613, "end_offset": 624}]}
{"id": 4786, "text": "Software to automatically generate Beliefs in Normal, Anomaly and Uncertainty for Dempster-Schaffer combinaion of predictors of netwark attack.", "entities": []}
{"id": 4787, "text": "A Julia library for simulating, processing, and plotting multiple scattering of acoustic waves.", "entities": []}
{"id": 4788, "text": "A package to calculate the effective waves travelling in materials comprised of randomly distributed particles or inclusions.", "entities": []}
{"id": 4789, "text": "A Mathematica package to calculate exact multiple scattering, in time and frequency, according to the 2D wave equation.", "entities": []}
{"id": 4790, "text": "This is an implementation of a modular Java-based API to the Ensemble data systems. The demonstration architecture addresses a number of objectives: specifically, it provides access to all versions of databases at Ensembl and EnsemblGenomes. It implements a varied selection of data access functions to demonstrate data retrieval from 'Core', 'Variation' and 'Compara' databases; mapping between CoordinateSystems and mapping transparently between database versions where there has been a change in schema requiring alternate data access methods.", "entities": []}
{"id": 4791, "text": "Findr is a fast and scalable software for causal inference and gene network reconstruction from genome-transcriptome variation data", "entities": []}
{"id": 4792, "text": "Glmnat is Matlab toolbox for L1-penalised regression in generalised linear models, using the natural coordinate descent algorithm, a novel algorithm hat is entirely described in terms of the natural formulation of the model and is guaranteed to converge to the true optimum. Currently Glmnat is available for penalised logistic regression, more models will be added in the future.", "entities": [{"id": 1446, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 1447, "label": "Software", "start_offset": 285, "end_offset": 291}]}
{"id": 4793, "text": "Whole-genome shotgun metagenomics experiments produce DNA sequence data from entire ecosystems, and provide a huge amount of novel information. Gene discovery projects require up-to-date information about sequence homology and domain structure for millions of predicted proteins to be presented in a simple, easy-to-use system. There is a lack of simple, open, flexible tools that allow the rapid sharing of metagenomics datasets with collaborators in a format they can easily interrogate. We present Meta4, a flexible and extensible web application that can be used to share and annotate metagenomic gene predictions. Proteins and predicted domains are stored in a simple relational database, with a dynamic front-end which displays the results in an internet browser. Web services are used to provide up-to-date information about the proteins from homology searches against public databases. Information about Meta4 can be found on the project website1, code is available on Github2, a cloud image is available, and an example implementation can be seen at http://www.ark-genomics.org/tools/meta4", "entities": [{"id": 1677, "label": "Software", "start_offset": 501, "end_offset": 506}, {"id": 1678, "label": "Software", "start_offset": 912, "end_offset": 917}, {"id": 1679, "label": "Software_Url", "start_offset": 1059, "end_offset": 1098}]}
{"id": 4794, "text": "Identification of novel ERV integration in WGS data", "entities": []}
{"id": 4795, "text": "The use of phased sequencing data has been shown to significantly increase the accuracy of imputation. AlphaPhase has been used as part of an imputation pipeline. Existing programs for phasing, have generally scaled poorly to large datasets with long and expensive burden in the computational resources available. Additionally, the increasing production of large sequencing data bundles and its heterogeneity complicate the phasing process. The current version of AlhaPhase implements methods to determine phase using an extended Long Range Phasing and Haplotype Library Imputation.", "entities": [{"id": 812, "label": "Software", "start_offset": 102, "end_offset": 114}, {"id": 813, "label": "Software", "start_offset": 464, "end_offset": 473}]}
{"id": 4796, "text": "hapbin is an ultra-efficient program for performing haplotype-based scans for positive selection in very large genomic datasets.", "entities": [{"id": 1025, "label": "Software", "start_offset": 0, "end_offset": 6}]}
{"id": 4797, "text": "Database and associated web interface to handle pedigree populations, genotypes and phenotypes for genetic linkage mapping and quantitative trait linkage mapping studies. System checks inheritance of markers and formats/reformats data in readiness for import into common analysis programs.", "entities": []}
{"id": 4798, "text": "Transcriptome Annotation by Modular Algorithms (for isoseq data)", "entities": []}
{"id": 4799, "text": "LocaTR identification pipeline for annotating LTR retrotransposons in any assembled genome", "entities": [{"id": 1680, "label": "Software", "start_offset": 0, "end_offset": 30}]}
{"id": 4800, "text": "This is a network analysis tool designed for the analysis of biological data. It is a commercial product produced by Kajeka Ltd a company founded on the IP and know how behind BioLayout Express3D.", "entities": []}
{"id": 4801, "text": "JEnsembl is an API (application programmable interface) which provides access to all versions of databases at Ensembl and EnsemblGenomes. It implements a varied selection of data access functions to demonstrate data retrieval from 'Core', 'Variation' and 'Compara' databases; mapping between CoordinateSystems and mapping transparently between database versions where there has been a change in schema requiring alternate data access methods. \n27-08-2014 Release version 1.76. Updated to handle up to Ensembl Schema 76 (Ensembl Genomes 23). Handles changes to homology records in Compara databases.", "entities": [{"id": 814, "label": "Software", "start_offset": 0, "end_offset": 8}]}
{"id": 4802, "text": "AlphaPlantImpute is a software package designed for phasing and imputing genotype data in plant breeding populations. AlphaPlantImpute can be implemented within and across bi-parental populations to phase and impute focal individuals genotyped at low-density to high-density.", "entities": [{"id": 1026, "label": "Software", "start_offset": 0, "end_offset": 16}, {"id": 1027, "label": "Software", "start_offset": 118, "end_offset": 134}]}
{"id": 4803, "text": "Lemon-Tree is a &quot;one-stop shop&quot; software suite for module network inference that aims to make module network methods available to a broader community of users while simultaneously facilitating and encouraging collaborations between developers. Module networks are probabilistic graphical models which consist of modules of coregulated genes and their regulatory programs, and they can be inferred from integrated genomic data compendia (including gene expression, microRNA expression, copy number variation, and more) measured in a large number of individuals or experimental conditions.", "entities": [{"id": 1233, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 4804, "text": "kruX is an algorithm implemented in Matlab, Python and R that uses matrix multiplications to simultaneously calculate the Kruskal-Wallis test statistic for several millions of marker-trait combinations at once. KruX is more than ten thousand times faster than computing associations one-by-one on a typical human dataset.", "entities": [{"id": 1448, "label": "Software", "start_offset": 0, "end_offset": 4}, {"id": 1449, "label": "Software", "start_offset": 211, "end_offset": 215}]}
{"id": 4805, "text": "TAMA is a bioinformatics package intended to be used for constructing transcriptome/genome annotations. TAMA is ideal for working with Iso-Seq (long read RNA sequencing) data. However, due to its modular nature, it can be used for other data types as well.\nMost recent update 17 December 2020.\nSee wiki for manual: https://github.com/GenomeRIK/tama/wiki", "entities": [{"id": 1681, "label": "Software", "start_offset": 0, "end_offset": 4}, {"id": 1683, "label": "Software", "start_offset": 104, "end_offset": 108}, {"id": 1684, "label": "Software_Url", "start_offset": 315, "end_offset": 353}]}
{"id": 4806, "text": "socialmixr is an R package to derive social mixing matrices from survey data.", "entities": [{"id": 579, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 4807, "text": "These are R packages to be used with the Bayesian state-space modelling platform libbi.", "entities": []}
{"id": 4808, "text": "The TAMSAT-ALERT Drought Forecasting API provides a simplified way for users to extract TAMSAT-ALERT drought forecasts for their region and season of interest. The Python code is freely available on GitHub, along with extensive training materials, enabling users to access the tool freely and easily. The software itself is designed to be run on a standard laptop and only requires the input of a single line of code, reducing technical and capacity barriers for entry.", "entities": [{"id": 1028, "label": "Software", "start_offset": 4, "end_offset": 40}]}
{"id": 4809, "text": "The online, interactive spreadsheet allows for comparison of the many different accessibility standards for UK housing,helping the designer understand and make a judgment about the appropriate level of access required around every aspect of the home.", "entities": []}
{"id": 4810, "text": "A set of commands that allow users to compute the distribution function, density, equi-coordinate quantiles, and random vectors of the multivariate normal and multivariate t distributions. Any non-degenerate cases of the multivariate normal and multivariate t distributions can be worked with, along with a particular class of non-central multivariate t distributions. The commands are written in a combination of Stata and Mata for speed.", "entities": []}
{"id": 4811, "text": "A selection of functions to determine the boundaries and sample size required by several common group sequential designs, for two-arm trials with continuous outcome variables.", "entities": []}
{"id": 4812, "text": "The Oxford Active Vision Library (OxVisionLib) is a loose collection of computer vision library and applications provided by the Active Vision Lab in the Department of Engineering Science, University of Oxford. These include\nInfiniTAM - A multi-platform framework for real-time, large-scale depth fusion and tracking.\ngSLICr - A library for much faster-than-real-time superpixel segmentation.\nLibISR - A library for tracking multiple 3D objects from depth images.\nPTAM - Parallel Tracking and Mapping\nfastHOG \\ Tech Report \\ single GPU version \\ multi GPU version \\ git (by Ashwin Nanjappa) \\ ubuntu build guide\nPWP3D \\ Paper \\ single object and view, VS2008 32bit \\ multiple objects and views, VS2010 64bit \\ git (by Lu Ma at CU-Boulder)", "entities": [{"id": 580, "label": "Software", "start_offset": 4, "end_offset": 32}, {"id": 581, "label": "Software", "start_offset": 34, "end_offset": 45}, {"id": 582, "label": "Software", "start_offset": 225, "end_offset": 234}, {"id": 583, "label": "Software", "start_offset": 318, "end_offset": 324}, {"id": 584, "label": "Software", "start_offset": 393, "end_offset": 399}, {"id": 585, "label": "Software", "start_offset": 464, "end_offset": 468}]}
{"id": 4813, "text": "Hal Blackburn (Cambridge University Library) created an enhanced OCR tool, based upon palaeographic chart of Schnitzler's handwriting produced by A. Neumann and dactylographic analysis by K. Fink (Wuppertal).", "entities": [{"id": 815, "label": "Software", "start_offset": 56, "end_offset": 73}]}
{"id": 4814, "text": "Pilot of new method of impact-related evaluation, creating a mosaic image of audience feedback, providing the basis for an interactive digital resource. Developed by Hal Blackburn (Cambridge University Library), in consultation with A. Neumann.", "entities": []}
{"id": 4815, "text": "Display tool to show how ripple framework works hosted on an tablet to show how it could be used in an care home or management in the sector.", "entities": []}
{"id": 4816, "text": "The app guides the user through the city of Prague, exploring the life and activities of composer Gideon Klein before the Holocaust. It is based upon the research of Dr David Fligg, Project Consultant for Performing the Jewish Archive.", "entities": []}
{"id": 4817, "text": "Our secondment from NPL created an app for the modelling of our HiPoBat battery cells.", "entities": []}
{"id": 4818, "text": "multi-agent public access platform that interactively teaches users how to factcheck news about COVID-19", "entities": [{"id": 586, "label": "Software", "start_offset": 0, "end_offset": 34}]}
{"id": 4819, "text": "interactive multi-agent chatbot to teach communication gatekeeepers how to avoid creating and spreading misleading news.", "entities": [{"id": 816, "label": "Software", "start_offset": 0, "end_offset": 31}]}
{"id": 4820, "text": "This is further development of the recurrent neural network for modeling music transcriptions.", "entities": []}
{"id": 4821, "text": "This software provides a means for concatenative sound synthesis via non-negative matrix factorisation.", "entities": []}
{"id": 4822, "text": "GnssMapper provides tools for generating 3D maps by using Global Navigation Satellite System (GNSS) data.", "entities": [{"id": 1450, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 4823, "text": "Program written in Igor code to simulate variable period X-ray standing wave data for comparison with experimental data. It calculates the variable period X-ray standing wave intensity produced over a range of angles for grazing reflection of an X-ray beam from a mirror surface, and then simulates the photoelectron/ Auger electron emissions expected, for a three layer system. The three layer system comprises vacuum, adsorbate, substrate for the purpose of X-ray reflection, while the composition of the adsorbate can be of arbitrary complexity for the purpose of simulating photoelectron/Auger electron emissions. The simulations are compared with intensity versus angle data obtained from fitting raw data using the edcfitprog program.\nThe program is still operable, but still being developed to encompass heterogeneous surfaces.", "entities": []}
{"id": 4824, "text": "Program written in Igor code to fit Normal Incidence X-ray Standing Wave (NIXSW) for a particular Bragg flection, producing the coherent fraction/coherent position structural data for the species under study. X-ray constants for the Bragg reflection are used plus photoelectron/Auger electron/background intensity vs X-ray energy data extracted from raw data using edcfitprog.", "entities": []}
{"id": 4825, "text": "Program written in Igor code used to determine the adsorption geometry of molecular species on surfaces using normal incidence X-ray standing wave (NIXSW) data. Experimental coherent position/coherent fraction vectors for a range of Bragg reflections, for all the chemical species within an adsorbed molecule, are compared with calculated values for all orientations and positions of the molecule on the surface, to determine the best fit.", "entities": []}
{"id": 4826, "text": "Data reduction program written in Igor code. Used to extract photoelectron / Auger electron/ background intensities from sequences of energy distribution curves (EDCs) measured for the purposes of X-ray standing wave (XSW) / SEXAFS / NEXAFS experiments. The program fits peaks with Gaussian/Doniach-Sunjic/no-fit shapes and backgrounds with a flexible polynomial/structured shape. Intensities extracted can be peak heights or areas or raw-background-subtracted and provide input for XSW/SEXAFS/NEXAFS analysis.\nProgram is continuously updated and extended to include data for new synchrotrons. \nLatest updates are for data taken at the Diamond Synchrotron for the normal incidence X-ray standing wave (NIXSW), Near Edge X-ray Fine Structure and Variable Period X-ray Standing Wave (VPXSW) techniques.", "entities": []}
{"id": 4827, "text": "A Monte Carlo simulation version of the Band collision risk model produced to include uncertainty and variability.", "entities": [{"id": 1234, "label": "Software", "start_offset": 2, "end_offset": 24}]}
{"id": 4828, "text": "A bioinformatics R package for statistical characterisation of antibody and T cell receptor repertoires.", "entities": []}
{"id": 4829, "text": "GramatiKat is a corpus tool providing data for research into grammatical categories, whether from a grammatical, lexicological, or lexicographical perspective. It can also be used in teaching Czech, especially Czech as a foreign language. One of its main functions is to track the distribution of word forms within a specific grammatical category, either across an entire part of speech or for a specific lemma in comparison with the entire class of words. Interactive tables allow, among other things, the search for lemmas in whose paradigm a particular form occurs unusually often, or conversely, does not occur at all. In the second version of the application, data on Czech adjectives and verbs are added to the data on nouns.", "entities": [{"id": 1686, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 4830, "text": "The web tool is used to retrieve information from the Database of Croatian morphological doublets using a number of criteria such as time period, type of the corpora etc. The same tool enables researchers included in the project to expand the database with additional items.", "entities": []}
{"id": 4831, "text": "GramatiKat is a corpus tool providing data for research into grammatical categories within fields of morphology, lexicology, and lexicography. It can also be used in teaching Czech (or another language) as a foreign language. One of its main functions is to observe the distribution of word forms within a specific grammatical category for either an entire word class or for a particular lemma in comparison with the word class. Interactive tables allow searching for lemmas with missing word forms or with word forms that are unusually frequent. The tool is ready to be extended for other languages, especially languages similar to Czech in structure. At the moment, Croatian and Slovak data are available internally (or upon request). The GramatiKat application contains detailed descriptions of each function that the user can navigate by.", "entities": [{"id": 817, "label": "Software", "start_offset": 0, "end_offset": 10}, {"id": 818, "label": "Software", "start_offset": 741, "end_offset": 751}]}
{"id": 4832, "text": "Python 3 Code which interfaces with an OPC-N3 manufactured by Alphasense via serial connection and properly records the data.", "entities": []}
{"id": 4833, "text": "A collection of many algorithms (new and old) for CAD, implemented as a Maple package. Open source code, available freely online together with introductory guide and technical reports detailing implementation and theoretical findings which followed.", "entities": []}
{"id": 4834, "text": "A web-based tool for presenting machine learning-generated predictions to a user performing data extraction for systematic review. The tool serves two purposes: it functions as a prototype of a fully-fledged system we hope to deploy, and also as a tool to investigate user perceptions of different methods of interacting with machine learning predictions and automation.", "entities": []}
{"id": 4835, "text": "The app allows the user to explore and contribute content to a multilayered digital map of Bristol that is populated with crowdsourced content. The aim is that through the app and its companion website (http://www.mapyourbristol.org.uk/) people can explore, research and co-create Bristol's history, heritage and culture. The app was created for the Know Your Bristol project, which is a collaboration between the University of Bristol, Bristol City Council and several Bristol community groups.", "entities": []}
{"id": 4836, "text": "The app allows the user to explore and contribute content to a multilayered digital map of Bristol that is populated with crowdsourced content. The aim is that through the app and its companion website (http://www.mapyourbristol.org.uk/) people can explore, research and co-create Bristol's history, heritage and culture. The app was created for the Know Your Bristol project, which is a collaboration between the University of Bristol, Bristol City Council and several Bristol community groups.", "entities": [{"id": 588, "label": "Software_Url", "start_offset": 203, "end_offset": 236}]}
{"id": 4837, "text": "This is a mobile application that allows users to read, listen to, and watch performances of a selection of Bloodaxe-published poetry. It is the first iteration of a larger project to develop new and novel ways to encounter and interact with poetry on mobile devices.", "entities": []}
{"id": 4838, "text": "A mobile app that presents poems commissioned from eight poets by the Newcastle Poetry Festival in response to the paintings of Sean Scully. The app was an experiment in using the mobile device to present site-specific writing by allowing users to read and listen to the poems in the Hatton and Laing Galleries, where the paintings were on exhibition during the 2018 Newcastle Poetry Festival.", "entities": []}
{"id": 4839, "text": "This web portal allows Behaviour Analysts (BAs) and parents to review recorded behaviour data, over time. (please refer to 'BMAC_app' section in Software and Technical Products). Consequently, BAs can interpret and action upon a functional analysis of these data in order to implement new / modified interventions. The web portal is linked with a data-mining component (please refer to section on research databases and models), which is used to extract patterns occurring within the recorded data, based on the application of association rule mining to link data attributes.\n\nThe data collected is visualised using appropriate charts, graphs and text in order to provide summarised and structured information to users, to assist with highlighting behaviour correlations associated with varying environmental causes and effects. Furthermore, the web portal is also used to support communication between BAs and parents via the BMAC mobile application at home. This can be general information relating to autism, specific guidance about a particular intervention procedure and / or other useful information/ links as well as personalised intervention direction, pertaining to observations made through the web portal. As a result, this component of the system endeavours to augment traditional and on-going face-to-face interactions between BAs, parents and children rather than serve to replace them.", "entities": [{"id": 1235, "label": "Software", "start_offset": 124, "end_offset": 132}, {"id": 1236, "label": "Software", "start_offset": 927, "end_offset": 950}]}
{"id": 4840, "text": "'LifePal' is a new app that has emerged from the growing collaboration with PEATNI and our previous research into behavioural monitoring, supported by technology. While BMAC focused on delivering tools to support parents to record observable behaviours, this new technology promotes a self-management paradigm by encouraging young people with ASD to take responsibility to recognised and record their own behaviours. \n\nThere is growing recognition of the need for effective intervention and support to reduce the risk of children and young people with ASD from being excluded from society and in particular from education. This follow-on research is investigating contemporary approaches for providing 'virtual' support to young people with ASD that will complement existing approaches, which enable self-management and 'self-coping' with everyday challenges.\n\nThe service is based around a smartphone App that provides users with task management, life-logging, reminding, and travel support. The App is supported via a dedicated web portal that promotes collaboration between caregivers and their dependents, towards defining obtainable life goals.", "entities": [{"id": 1451, "label": "Software", "start_offset": 1, "end_offset": 8}]}
{"id": 4841, "text": "The BMAC smartphone application facilitates the recording of behaviour data, the reviewing of that data and the receipt of messages from the families Behaviour Analyst (BA). Developed for deployment on the Android platform, the current application allows quick data collection of common behaviour Antecedents, Behaviours and Consequences, as detailed within SimpleSteps Forced Choice ABC charts [Available: http://www.simplestepsautism.com]\n\nThe users of the application can indicate the person recording the behaviour and the setting in which it occurs. In the situation where multiple children within a family have autism spectrum disorder, the application allows the caregiver to select the child that exhibited the behaviour being recorded. Users are then requested to highlight from a predefined (clinically validated) list of Antecedents, Behaviours and Consequences, which are displayed as a scrolling list that can be navigated using simple 'swipe' gestures. If an Antecedent, Behaviour or Consequence is not available from the list the user has the ability to access and submit free text entry. After selecting the events from the lists, the Behaviour specific details are selected and include the duration, intensity (scale of 1-5) and frequency of the identified behaviour. As it may not be possible for the user to record the event as and when it occurs, the system allows the retrospective time stamping of collected data.", "entities": [{"id": 1687, "label": "Software", "start_offset": 4, "end_offset": 31}]}
{"id": 4842, "text": "The Values &amp; Value project website and Facebook App have been written in Python using the Django Framework. Admonitor has been developed with the Firefox SDK and is written in JavaScript. The source code for the project software is released under an open licence and is freely available on a public repository at: https://github.com/valuesandvalue", "entities": [{"id": 589, "label": "Software", "start_offset": 0, "end_offset": 15}, {"id": 590, "label": "Software_Url", "start_offset": 317, "end_offset": 351}]}
{"id": 4843, "text": "This is a linter for the CASTEP source code, which enforces certain style decisions and removes the ability to make a few common mistakes.", "entities": [{"id": 819, "label": "Software", "start_offset": 24, "end_offset": 31}]}
{"id": 4844, "text": "CASTEP is a software package for predictive, quantum-mechanical simulations of materials and chemicals. It is based on density functional theory, and can simulate a wide range of materials proprieties including energetics, the structure at the atomic level, vibrational properties and electronic response properties. In particular, it has a wide range of spectroscopic features that link directly to experiment, such as infra-red and Raman spectroscopies, NMR, and core level spectra. CASTEP version 23 extended a top-level Python layer to enable CASTEP to be embedded within other computational workflows, for example transition-state searches or multiscale modelling.", "entities": [{"id": 1029, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 1030, "label": "Software", "start_offset": 485, "end_offset": 491}, {"id": 1031, "label": "Software", "start_offset": 547, "end_offset": 553}]}
{"id": 4845, "text": "This is a collection of tools for manipulating electron-phonon coupling matrix elements from CASTEP output. These can be used to calculate superconductivity transition temperatures as well as transport properties.", "entities": []}
{"id": 4846, "text": "CASTEP is a software package for predictive, quantum-mechanical simulations of materials and chemicals. It is based on density functional theory, and can simulate a wide range of materials proprieties including energetics, the structure at the atomic level, vibrational properties and electronic response properties. In particular, it has a wide range of spectroscopic features that link directly to experiment, such as infra-red and Raman spectroscopies, NMR, and core level spectra. CASTEP version 24 included a new parallel data distribution, which significantly enhanced parallel scaling.", "entities": [{"id": 1452, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 1453, "label": "Software", "start_offset": 485, "end_offset": 491}]}
{"id": 4847, "text": "This is a software interface to present a code-agnostic way of running various DFT codes", "entities": []}
{"id": 4848, "text": "Evaluator for first denotational semantics of C/C++ which forbids thin-air executions.", "entities": []}
{"id": 4849, "text": "Evaluates small programs, called litmus tests, under a cutting edge mathematical model of concurrency.", "entities": []}
{"id": 4850, "text": "- Code and tools for extracting, analysing and scaling fuelling machine data (fuelling machine log data analysis)\n- Prototype dashboard implementing engineer-led fuelling machine metrics (Power BI prototype implementing the code above)\n- On-demand analysis of fuel reliability data to support engineering decision making (running ad-hoc dataset from fuel defects to compare model outputs with engineering insights)\n- Prototype sensor degradation tool updated to feature multiple models for field testing (an interface for testing the electrical/sensor failure trained models against more data)\n- Proof of Concept Site Condition Report Classification Tools (code to support automating the classification and assignment of fault reports)", "entities": []}
{"id": 4851, "text": "In 2022, expanding on analytics previously developed/reported, the Fuel Machine Log Analysis (FMLA) analytic for Bruce Power has now been deployed on a cloud-based platform and this initiative has unlocked and accelerated further capability, including 3 new models for estimating remaining useful life of D2O filters. The FMLA was developed between Strathclyde and The Turing (using additional EPSRC Impact Acceleration Account funds). Additional analytics have been developed for Bruce Power; including using fuel machine trolley coasting distance, vault temperature and torque feedback to develop a metric for the health of the power track and drive train; the optimisation of the trolley maintenance and/or isolation time and linking this to clearance orders within Maximo; and, the development of cloud-based dashboards to visualise data for both the data analysts and the end-users in the field. A final suite of analytics have been developed focussing on detection of failed nuclear fuel. These algorithms have been deployed for evaluation on the desktop of the reactor physicist responsible for isolating instances of failed fuel in the reactor core. Another significant area of work has been translating algorithms initially developed for EDF's graphite reactor cores but now repurposed for a key inspection activity of Bruce Power's main component replacement (MCR) programme.", "entities": [{"id": 1237, "label": "Software", "start_offset": 67, "end_offset": 92}, {"id": 1238, "label": "Software", "start_offset": 94, "end_offset": 98}, {"id": 1239, "label": "Software", "start_offset": 322, "end_offset": 326}]}
{"id": 4852, "text": "Project 11-2 has produced 6 software based technical demonstrators, which have been delivered to EDF Energy and demonstrate an option for the deployment of the underpinning research. These demonstrators cover a range of Data Analytic and Machine Learning techniques developed as part of the project.", "entities": []}
{"id": 4853, "text": "The Digital Workbench, built in collaboration with the Digital Humanities Institute at Sheffield University, is a platform designed to enable collaborative editing. As users edit work, adding annotations and comments, the Workbench stores this information and alerts other editors who are working on related problems. The Workbench also functions as a repository for sources that editors can upload and share, as well as a space for discussion.", "entities": [{"id": 1688, "label": "Software", "start_offset": 4, "end_offset": 21}]}
{"id": 4854, "text": "The software is not available yet but will be made publicly available (for free) upon publication. We developed a software that solves a dynamic model of educational choices which incorporates subjective beliefs (elicited through our survey) and that can be estimated using experimental data. The model can be used to predict the impact of various designs for the PACE poloicy, so it is of immediate use to Chilean policy-makers. Moreover, we are pushing the frontier of research by combining innovative data (subjective beliefs) with structural modelling and randomized experiments. Therefore, the software provides a framework that can serve as input for future researchers.", "entities": []}
{"id": 4855, "text": "We have adapted the JupyterLab data science environment to use execute Vadalog, the reasoning language developed in the context of the VADA project. \nFeatures include: (1) Rule authoring, execution, (2) Interaction with Python and R, (3) Program analysis and debugging (4) Model Explanations (Proof Trees and Audit Trails), (5) Visualisation", "entities": [{"id": 821, "label": "Software", "start_offset": 20, "end_offset": 31}]}
{"id": 4856, "text": "A software tool for automatically locating the outline of certain bones in radiographs, allowing accurate measurement of shape.", "entities": []}
{"id": 4857, "text": "Software that drives our automated DNA assembly process", "entities": []}
{"id": 4858, "text": "Python code for combining multiple widely available datasets into a single map identifying the most suitable locations for nature recovery and nature-based solutions, created by the Agile Nature-based Solutions Sprint team.", "entities": []}
{"id": 4859, "text": "Webmapping tool to disseminate the results of the article Soterroni et al., 2023 hosted on GitHub.", "entities": []}
{"id": 4860, "text": "Public repository for retaining and sharing scientific workflows. Social sharing platform. myExperiment makes it easy to find, use and share scientific workflows and other Research Objects, and to build communities.", "entities": [{"id": 591, "label": "Software", "start_offset": 91, "end_offset": 103}]}
{"id": 4861, "text": "Scientific Workflow Management System and Toolsuite including: enactment engine, workbench, plugins and plugin framework, server, commandline tool, player, interaction service.", "entities": []}
{"id": 4862, "text": "A software package to analyse x-ray scattering data from fibrous biomaterials was developed and published", "entities": []}
{"id": 4863, "text": "The creation of a CXL e-registry within Open Eyes software to facilitate the tracking of keratoconus progression and treatment outcomes following NICE recommendations", "entities": [{"id": 1240, "label": "Software", "start_offset": 18, "end_offset": 58}]}
{"id": 4864, "text": "Popcorn, a software for linking genes to upstream regulators in a network.\nUsed for analysis of networks, linking genes that are not otherwise discoverable using existing software.\nThe details will be published soon, but it is available on GitHub now.\nSoftware written and developed by Dr Morag Lewis.", "entities": [{"id": 1454, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4865, "text": "Popcorn, a software for linking genes to upstream regulators in a network.\nUsed for analysis of networks, linking genes that are not otherwise discoverable using existing software.\nThe details will be published soon, but it is available on GitHub now.\nSoftware written and developed by Dr Morag Lewis.", "entities": [{"id": 1689, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4866, "text": "Smartphone application collecting active and passive data regarding behaviour and activity for the purposes of digital phenotyping.", "entities": []}
{"id": 4867, "text": "The software will detect Acute Kidney Injury events given only eGFR or serum creatinine time-series. It is useful for retrospective analysis of eGFR time-series for which AKI events have not been identified.", "entities": []}
{"id": 4868, "text": "I have helped to develop and test a user-written command for Stata software called &quot;slopepower&quot;, along with some collaborators at LSHTM. We have also written an associated help file. Although Stata is proprietary software, user-written packages are freely downloadable to anyone who wishes to use it. The package enables Stata users to perform sample size or power calculations for trials which compare slopes over time.", "entities": [{"id": 1032, "label": "Software", "start_offset": 89, "end_offset": 99}]}
{"id": 4869, "text": "The design and optimisation model developed for the innovative PVT Loop heat pipe has been converted to a software. This software permits to size and optimize all components of the system.", "entities": []}
{"id": 4870, "text": "1. Extracts Loop parallelism from normal nested python loops \n2. Framework to do if-conversion on normal Python loops \n3. Framework to defer compilation and generation of CPU or GPU kernels from normal nested Python loops\n4. Cost modelling to accurately determine which device in a heterogeneous JIT compiling environment will execute a given loop computation faster.", "entities": []}
{"id": 4871, "text": "A Hall-MHD software written in C++ that allows the investigation of high-frequency wave modes in two-dimensional plasma equilibria, with special application in magnetically confined fusion plasmas.", "entities": [{"id": 1690, "label": "Software", "start_offset": 2, "end_offset": 19}]}
{"id": 4872, "text": "Implements several RAL/LBNF target geometries for the FLUKA simulation package.", "entities": []}
{"id": 4873, "text": "Geant4 simulation of the LBNF target system implementing the design work from the RAL High Power Targets Group.", "entities": [{"id": 822, "label": "Software", "start_offset": 0, "end_offset": 18}]}
{"id": 4874, "text": "The QCrBox (Quantum Crystallography Box) is the core product to be developed during this award. The current version (March 2024) is an alpha developer release version. It is functional, and several sample applications are included. The documentation is up to a standard that knowledgeable developers and contributors can work with the software.", "entities": [{"id": 1033, "label": "Software", "start_offset": 4, "end_offset": 11}, {"id": 1034, "label": "Software", "start_offset": 12, "end_offset": 39}]}
{"id": 4875, "text": "Pipeline of software to find transposable elements within genomes, and compare various aspects of their evolution among multiple species.", "entities": []}
{"id": 4876, "text": "A general purpose computer program for the calculation of the properties of materials, using quantum mechanics. CASTEP is distributed world-wide via Accelrys Inc to many industrial partners, including Electronics, Aviation, Car manufacturers, consumer electronic devices, pharmaceuticals, etc.\n\nBeneficiaries: Many industrial customers of the CASTEP code, including electronics, aviation, automobile and pharmaceuticals. Examples include Canon, Toyota, General Motors, etc.\n\nContribution Method: Probert and Hasnip (PDRA) are two of the 6 core developers of the CASTEP code.", "entities": [{"id": 1455, "label": "Software", "start_offset": 112, "end_offset": 118}, {"id": 1456, "label": "Software", "start_offset": 343, "end_offset": 349}, {"id": 1457, "label": "Software", "start_offset": 562, "end_offset": 568}]}
{"id": 4877, "text": "The software can predict performance of products when subsituting virgin raw materials with waste products. FactSage represents one of the essential elements that drive our developed thermodynamic simulation-guided recycling strategy, ThermoRecycliSt. It contains thermodynamic databases that we require to find important parts of problem solution and help with phase evolution simulation.", "entities": [{"id": 1691, "label": "Software", "start_offset": 108, "end_offset": 116}]}
{"id": 4878, "text": "SYNERGie&reg; software hosts information for over 100,000 resources from 34,000 organisations across 23 countries on 6 continents; resources and organisations on the platform are growing at 10% per year. Quantified impacts in England alone include 42 million tonnes carbon avoided whilst achieving over &pound;1 billion cost savings and, &pound;1 billion revenue generation. The advisor function running in the background accesses a library of past successes to present the user with automatic, evidence-based solutions without having to search manually. SYNERGie&reg; has been used by many industry sectors and facilitators to advance resource efficiency, bringing cost savings, reducing supply risks and improving environmental sustainability.\n\nA version of the software has been developed for TransFIRe where our industrial partners and other interested parties can upload information about their resources (WANTs &amp; HAVEs). Its primary function is to overcome information barriers: the lack of knowledge within one company or sector about opportunities within another company or sector to move the (waste) resource up the value chain and keep it in productive use for longer. A categorisation system for non-material resources is included to enable the reuse of equipment and other non-waste assets.", "entities": [{"id": 592, "label": "Software", "start_offset": 0, "end_offset": 12}, {"id": 593, "label": "Software", "start_offset": 555, "end_offset": 567}]}
{"id": 4879, "text": "The software provides a fast implementation of complete linkage clustering that allows arbitrary data to be clustered into groups according to similarity scores.", "entities": []}
{"id": 4880, "text": "cath-resolve-hits provides a fast, effective way to collapse a set of domain matches (e.g. from a typical protein sequence search) down to a non-overlapping subset or &quot;domain architecture&quot; assignment.\n\nFast:\n Can process around 1-2 million input hits per second\nPowerful:\n - Finds the optimal result that maximises the sum of hits' scores\n - Handles discontinuous domains\n - Supports tolerance for overlaps between hits; auto-resolves any that occur\nTransparent:\n - Provides visualisation of input data and decisions via graphical HTML\nSimple:\n - Uses a simple default input file format\n - Also accepts HMMER domtblout files and hmmsearch output files\n - Accepts input that hasn't been pre-sorted or even pre-grouped (but can exploit that where specified)\nConfigurable:\n - Allows users to determine their own scoring system to be maximised\n - Offers many easy-to-use options to configure the default behaviour\n\nSoftware Features:\n - written and tested in strict C++ \n - removed a number of local dependencies to allow the tool to be used by the wider community \n - source code released on GitHub under the GPLv3 license (as part of the cath-tools suite)\n - incorporated into a robust continuous integration (CI) build with tests and releases", "entities": [{"id": 1035, "label": "Software", "start_offset": 0, "end_offset": 18}]}
{"id": 4881, "text": "cathpy is a Bioinformatics toolkit written in Python. It is developed and maintained by the Orengo Group at UCL and is used for maintaining the CATH protein structure database (and associated research).", "entities": [{"id": 1241, "label": "Software", "start_offset": 0, "end_offset": 6}]}
{"id": 4882, "text": "cath-ssap finds the optimal structural alignment between two protein structures, then uses this alignment to calculate a quantitative measure of the structural similarity. \n\nThe program employs a highly sensitive double-dynamic algorithm that calculates and compares the local structural environment of residues. Since protein structure is more conserved that protein sequence during the process of evolution, these similarity scores provide a sensitive measure of remote homologies between distantly related proteins. \n\n - cath-ssap is a complete rewrite of the original SSAP algorithm of Taylor and Orengo (1989)\n - ported from C to strictly written and tested C++ \n - removed a number of local dependencies to allow the tool to be used by the wider community \n - source code released on GitHub under the GPLv3 license (as part of the cath-tools suite)\n - incorporated into a robust continuous integration (CI) build with tests and releases", "entities": [{"id": 1458, "label": "Software", "start_offset": 0, "end_offset": 9}, {"id": 1459, "label": "Software", "start_offset": 524, "end_offset": 533}]}
{"id": 4883, "text": "cath-superpose provides the optimal structural superposition between two protein structures. \n\nWhen deciding on which residues to use for the superposition, the tool takes into account the structural environment of each residue. This focuses the superposition on the parts of the alignment that align well rather that variable regions that can disrupt superpositions. In contrast with methods that simply attempt to minimise the RMSD, this approach can be used to build superpositions of hundreds of protein structures that clearly show the highly conserved ancient structural core within distantly related protein domain structures.\n\n - written and tested in strict C++ \n - removed a number of local dependencies to allow the tool to be used by the wider community \n - source code released on GitHub under the GPLv3 license (as part of the cath-tools suite)\n - incorporated into a robust continuous integration (CI) build with tests and releases", "entities": [{"id": 1692, "label": "Software", "start_offset": 0, "end_offset": 14}]}
{"id": 4884, "text": "TeSS (Training eSupport system) is a platform that was developed to provide a one-stop shop for trainers and trainees to discover online information and content, including training materials, events and interactive tutorials. For training providers, TeSS provides opportunities to promote training events and news, and to contribute to a growing catalogue of materials; for trainers, the portal offers an environment for sharing materials and event information; for trainees, it offers a convenient gateway via which to identify relevant training events and resources, and to perform specific, guided analysis tasks via customised training workflows.", "entities": [{"id": 594, "label": "Software", "start_offset": 0, "end_offset": 4}, {"id": 595, "label": "Software", "start_offset": 6, "end_offset": 30}, {"id": 596, "label": "Software", "start_offset": 250, "end_offset": 255}]}
{"id": 4885, "text": "Scripts for our RNA-seq analysis of tau and amyloid pathology", "entities": []}
{"id": 4886, "text": "Py-ChemShell is the python-based version of the ChemShell multiscale computational chemistry environment, a leading package for combined quantum mechanical/molecular mechanical simulations.", "entities": [{"id": 1036, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 4887, "text": "Py-ChemShell is the python-based version of the ChemShell multiscale computational chemistry environment, a leading package for combined quantum mechanical/molecular mechanical simulations.", "entities": [{"id": 1242, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 4888, "text": "This is the source code of our INLG 2019 paper (Li R., Li X., Lin C, Collinson M. and Mao R. A Stable Variational Autoencoder for Text Modelling, The 12th International Conference on Natural Language Generation (INLG), Tokyo, 2019).", "entities": []}
{"id": 4889, "text": "This is the source code of our CoNLL 2019 paper (Li R., Lin C., Collinson M., Li X. and Chen G. A Dual-Attention Hierarchical Recurrent Neural Network for Dialogue Act Classification, The SIGNLL Conference on Computational Natural Language Learning (CoNLL), Hong Kong, 2019).", "entities": []}
{"id": 4890, "text": "artbin estimates power or total sample size for trials with binary outcomes.", "entities": [{"id": 597, "label": "Software", "start_offset": 0, "end_offset": 6}]}
{"id": 4891, "text": "artcat is a program for calculating the sample size required in a clinical trial with an ordered categorical outcome. It runs in the statistical package Stata.", "entities": []}
{"id": 4892, "text": "Code written by Teun Vissers to automatically identify and analyze the trajectories of bacteria in microscopy videos. Code is available from:\nhttps://git.ecdf.ed.ac.uk/tvissers/findRods2Dt \nhttps://git.ecdf.ed.ac.uk/tvissers/trackRods2Dt \nhttps://git.ecdf.ed.ac.uk/tvissers/filterTracks2Dt \nhttps://git.ecdf.ed.ac.uk/tvissers/analyzeBugTracks2Dt\n\nand is described and used in:\nhttps://doi.org/10.1371/journal.pone.0217823", "entities": [{"id": 1037, "label": "Software_Url", "start_offset": 142, "end_offset": 188}, {"id": 1038, "label": "Software_Url", "start_offset": 190, "end_offset": 238}, {"id": 1039, "label": "Software_Url", "start_offset": 239, "end_offset": 289}, {"id": 1040, "label": "Software_Url", "start_offset": 291, "end_offset": 345}]}
{"id": 4893, "text": "GitHub repository of code to support the DataCAMPP units\nSource of practical examples to support the units", "entities": []}
{"id": 4894, "text": "GrowthGrids allows for quick and easy plotting of arrayed growth curves, an assay commonly used in yeast and microbial genetics. The app permits for multiple conditions, such as temperatures, to be compared with each other in one plot.", "entities": [{"id": 1460, "label": "Software", "start_offset": 0, "end_offset": 11}]}
{"id": 4895, "text": "The dashboard presents delivery data in a map, allowing the user to filter the data by area, journey start or end time, journey length, and origin/destination information. The deployment of the dashboard is done in two parts: The backend (server-side) containing the database and a server for handling requests and data queries, and the frontend (client-side) which contains the visualisation and interaction elements. The dashboard is accessed through any modern web-browser, by pointing to the relevant URL.\nThe database used by the dashboard is a MongoDB instance, Request handling and queries to the database are done through a server application written in JavaScript using the node.js environment. The dashboard backend (server and database) is stored locally at the current stage, however the technologies used for each of the components (node.js and MongoDb) are designed primarily for web applications and therefore the dashboard can be easily deployed online.\nThe frontend part of the dashboard (the user interface) is written in HTML and JavaScript, combining multiple visualisation, charting, and mapping libraries. The layout and overall User Interface uses an HTML dashboard template published by Keen, modified to accommodate the required elements. The visualisation and filtering functionality is implemented in JavaScript. Specifically, overall data manipulation is handled using the dc.js library, which in itself combines more fundamental libraries: d3.js is used for data visualisation in the form of charts, and Crossfilter for filtering the data over multiple attributes. Finally, mapping and spatial filtering is implemented through the use of the Leaflet library.", "entities": []}
{"id": 4896, "text": "The framework is a piece of software developed in the Java programming language, making use of the MASON agent-based modelling simulation toolkit. It allows the user to generate synthetic environments from data including transportation networks, parcel demand location, and depot information; to populate these environments with individual, independent delivery personnel; and to explore how changes or modifications to the environment or personnel translate into different patterns of delivery. Thus, by changing the demand for parcels or the availability of parking, the user can explore how current practices would translate into outcomes.", "entities": []}
{"id": 4897, "text": "transTide is a software that allows to estimate the loads generated by a tidal turbine under a turbulent, sheared inflow in the presence of yaw and surface waves.", "entities": [{"id": 823, "label": "Software", "start_offset": 0, "end_offset": 9}]}
{"id": 4898, "text": "This software allows to estimate the performance of a tidal turbine equipped with passively pitching blades.", "entities": []}
{"id": 4899, "text": "Design of the webpage, with animation - provided by Linda Gusia", "entities": []}
{"id": 4900, "text": "Used to generate monte carlo data for the near detector (called ND280) of T2K. It is also used to reconstruct measured data and compare with the monte carlo data.", "entities": []}
{"id": 4901, "text": "The ALEA profiler is a cross-platform statistical profiling tool for Linux, which provides time and energy profiling at the basic block level on Intel and ARM architectures (32 and 64 bit). Energy profiling is available for platforms with energy or power meters. Currently, ALEA supports all Intel platforms with enabled RAPL interface and ARM-based Odoroid-XU/Odroid-XU3 platforms. The tool can be used for profiling both sequential and multi-threaded applications. Energy and execution time accounting to source code is also supported for applications compiled with debugging information (DWARF).", "entities": [{"id": 1693, "label": "Software", "start_offset": 4, "end_offset": 8}, {"id": 1694, "label": "Software", "start_offset": 274, "end_offset": 278}]}
{"id": 4902, "text": "This release combines a large number of changes over the past year or so, some bug fixes and a couple of long-awaited enhancements.\n\nThe main enhancements are in the ability to read simulated data from NPTool and PACE4. The histogrammer now makes a complete set of recoil time-random plots that can be used for subtraction, although the user must make the subtraction themselves.\n\nSome bug fixes included the n-side mapping, array histogram z bin limits, and some energy-loss and pulse-height-correction fixes.\n\nWhat's Changed\n\n\n\nFixed missing dep for &quot;make -j&quot;. by @hanstt in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/18\n\nSilencing some compiler warnings. by @inkdot7 in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/19\n\nTry a CI action file. by @inkdot7 in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/20\n\nAdd recoil E and dE eloss spectra. by @dj-clarke in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/21\n\nExtend ex histograms by @ACeulemans in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/22\n\nPrint as (int) in error output. by @inkdot7 in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/24\n\nSmall bug fix and improvements to energy loss and pulse-height correction calculation by @berjones in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/25\n\nB jones correct nside mapping by @berjones in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/23\n\nBug in autocal residuals plot by @dj-clarke in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/27\n\nFix bug #26 reported by Andreas Ceulemans by @lpgaff in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/28\n\nRevert some changes and apply correct fix for issue #26 by @lpgaff in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/29\n\nUpdate histogram limits for the z axis of the array by @lpgaff in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/30\n\nMake -j fix by @inkdot7 in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/31\n\nCorrect the module indexing of detecors from nptool by @berjones in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/32\n\nHistogrammer updates by @lpgaff in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/33\n\nSet the Sumw2 method by default on histograms by @lpgaff in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/34\n\n\nNew Contributors\n\n\n\n@hanstt made their first contribution in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/18\n\n@inkdot7 made their first contribution in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/19\n\n@berjones made their first contribution in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/25\n\n@lpgaff made their first contribution in https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/pull/28\n\n\nFull Changelog: https://github.com/ISOLDESolenoidalSpectrometer/ISSSort/compare/v2.4...v3.0", "entities": [{"id": 599, "label": "Software_Url", "start_offset": 2893, "end_offset": 2968}]}
{"id": 4903, "text": "Software takes a fits image containing a cross-dispersed spectrum and extracts the spectral orders regardless of separation and curvature, applies wavelength correction and other standard data reduction procedures.", "entities": []}
{"id": 4904, "text": "Transit Follow Up Tool Website code in PHP to predict transit events with the ability to include off transit time before and after. Also the ability to predict the uncertainty of the photometry on CCD cameras.", "entities": [{"id": 1041, "label": "Software", "start_offset": 0, "end_offset": 30}]}
{"id": 4905, "text": "PEXO, a package for Precise EXOplanetology to facilitate the efficient modeling of timing, astrometry, and radial velocity data, which will benefit not only exoplanet science but also various astrophysical studies in general. PEXO is general enough to account for binary motion and stellar reflex motions induced by planetary companions and is precise enough to treat various relativistic effects both in the solar system and in the target system. We also model the post-Newtonian barycentric motion for future tests of general relativity in extrasolar systems. We benchmark PEXO with the pulsar timing package TEMPO2 and find that PEXO produces numerically similar results with timing precision of about 1 ns, space-based astrometry to a precision of 1 µas, and radial velocity of 1 µm s-1 and improves on TEMPO2 for decade-long timing data of nearby targets, due to its consideration of third-order terms of Roemer delay. PEXO is able to avoid the bias introduced by decoupling the target system and the solar system and to account for the atmospheric effects that set a practical limit for ground-based radial velocities close to 1 cm s-1.", "entities": [{"id": 1243, "label": "Software", "start_offset": 0, "end_offset": 4}, {"id": 1244, "label": "Software", "start_offset": 226, "end_offset": 230}, {"id": 1245, "label": "Software", "start_offset": 632, "end_offset": 636}, {"id": 1246, "label": "Software", "start_offset": 575, "end_offset": 579}, {"id": 1247, "label": "Software", "start_offset": 611, "end_offset": 617}, {"id": 1248, "label": "Software", "start_offset": 807, "end_offset": 813}, {"id": 1249, "label": "Software", "start_offset": 924, "end_offset": 928}]}
{"id": 4906, "text": "for the first time a method was developed to use phase solution method for analysing aeroelasticity for large offshore wind turbines.", "entities": []}
{"id": 4907, "text": "Allows statistical sampling of uncertainty in satellite derived land cover data.", "entities": []}
{"id": 4908, "text": "Starting from model code developed by ECMWF, we have developed a variational data assimilation system for a single-column coupled atmosphere-ocean model. This includes strongly and weakly coupled assimilation systems, plus the ability to calculate covariance information from ensembles.", "entities": [{"id": 600, "label": "Software", "start_offset": 65, "end_offset": 101}]}
{"id": 4909, "text": "A python implementation of the Sellers two-stream radiative transfer model that can faithfully mimic the set-up of major land surface models (JULES, CLM, etc) as well as providing general solutions to leaf angle distribution, clumping and up/down scatter.", "entities": [{"id": 824, "label": "Software", "start_offset": 30, "end_offset": 75}]}
{"id": 4910, "text": "EMPIRE is a data-assimilation software package that contains state-of-the-art ensemble data-assimilation methods and that can be combined very easily with any numerical model via MPI.", "entities": [{"id": 1042, "label": "Software", "start_offset": 0, "end_offset": 6}]}
{"id": 4911, "text": "The SHAW App has been designed and tested as a bespoke web-based App, which uses a combination of self-assessed questions drawn from validated scales, and AI (LLM) technology to help individuals Reflect on and Review their health and work, and then take Action to get the support they need.", "entities": [{"id": 1250, "label": "Software", "start_offset": 4, "end_offset": 12}]}
{"id": 4912, "text": "DNA methylation microarrays are widely used in clinical epigenetics and are\noften processed using R packages like ChAMP or RnBeads by trained bioinfomaticians.\nHowever, looking at specific genes requires bespoke coding which wet-lab biologists or\nclinicians are not trained for. This leads to high demands on bioinfomaticians, who in turn\nmay lack insight into the specific biological problem. We therefore wished to develop a tool\nfor mapping and quantification of methylation differences at candidate genomic features of\ninterest, without using coding, to bridge this gap. We therefore generated the workflow CandiMeth \n(CANDIdate METHylation) in the web-based\nenvironment Galaxy. CandiMeth takes as input any table listing differences in\nmethylation generated by either of the popular R-based packages above and maps these to the\nhuman genome. A simple interface then allows the user to query the data using lists of gene\nnames. CandiMeth generates 1)Tracks in the popular UCSC genome browser with an\nintuitive visual indicator of where differences in methylation occur between samples, or\ngroups of samples 2) Tables containing quantitative data on the candidate regions, allowing\ninterpretation of significance. In addition to genes and promoters, CandiMeth can analyse\nmethylation differences at LINEs and SINEs. Cross-comparison to other open-resource\ngenomic data at UCSC facilitates interpretation of the biological significance of the data and\nthe design of wet lab assays to further explore methylation changes and their consequences\nfor the candidate genes. CandiMeth allows rapid, quantitative analysis of methylation at user-specified\nfeatures without the need for coding and is freely available through Github", "entities": [{"id": 1461, "label": "Software", "start_offset": 611, "end_offset": 620}, {"id": 1462, "label": "Software", "start_offset": 623, "end_offset": 644}, {"id": 1463, "label": "Software", "start_offset": 683, "end_offset": 692}, {"id": 1464, "label": "Software", "start_offset": 932, "end_offset": 941}, {"id": 1465, "label": "Software", "start_offset": 1253, "end_offset": 1262}, {"id": 1466, "label": "Software", "start_offset": 1570, "end_offset": 1579}]}
{"id": 4913, "text": "Ossian is a collection of Python code for building text-to-speech (TTS) systems, with an emphasis on easing research into building TTS systems with minimal expert supervision. \nUpdates to this repository occurred in the SCRIPT project.", "entities": [{"id": 1695, "label": "Software", "start_offset": 51, "end_offset": 79}, {"id": 1696, "label": "Software", "start_offset": 131, "end_offset": 142}]}
{"id": 4914, "text": "waffler\n\nThis repository contains code used to build the proposed systems presented in the following paper:\n\n@inproceedings{watts2019speech,\n title={Speech waveform reconstruction using convolutional neural networks with noise and periodic inputs},\n author={Oliver Watts and Cassia Valentini-Botinhao and Simon King},\n booktitle={2019 {IEEE} International Conference on Acoustics, Speech and Signal Processing, {ICASSP} 2019},\n year={2019}\n}\nThe instructions below explain how to produce a system comparable to the new system (P0) proposed in that paper.", "entities": [{"id": 601, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4915, "text": "nickery\n\nThis repository contains code used to build the proposed systems presented in the papers Exemplar-based speech waveform generation and Exemplar-based speech waveform generation for text-to-speech.\n\nExemplar-based speech waveform generation\n\n\n\n@inproceedings{watts18examplar,\n title = {Exemplar-based speech waveform generation},\n author = {Oliver Watts and Cassia Valentini-Botinhao and Felipe Espic and Simon King},\n booktitle = {Interspeech},\n year = {2018},\n}\nThe first part of this README is about use of scripts:\n\nscript/train_simple.py\nscript/synth_simple.py \n... which can only build a few restricted types of system (selection of epoch-based fragments, greedy search only). They can be used to replicate the system proposed in the paper Exemplar-based speech waveform generation", "entities": [{"id": 825, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4916, "text": "A modified version of Kyubyong Park's dc_tts repository, which implements a variant of the system described in Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention.", "entities": [{"id": 1043, "label": "Software", "start_offset": 22, "end_offset": 55}]}
{"id": 4917, "text": "Merlin: The Neural Network (NN) based Speech Synthesis System\n\nThis repository contains the Neural Network (NN) based Speech Synthesis System\ndeveloped at the Centre for Speech Technology Research (CSTR), University of Edinburgh.\n\nMerlin is a toolkit for building Deep Neural Network models for statistical parametric speech synthesis. It must be used in combination with a front-end text processor (e.g., Festival) and a vocoder (e.g., STRAIGHT or WORLD).\n\nThe system is written in Python and relies on the Theano numerical computation library.\n\nMerlin comes with recipes (in the spirit of the Kaldi automatic speech recognition toolkit) to show you how to build state-of-the art systems.\n\nMerlin is free software, distributed under an Apache License Version 2.0, allowing unrestricted commercial and non-commercial use alike.", "entities": [{"id": 1251, "label": "Software", "start_offset": 0, "end_offset": 6}, {"id": 1252, "label": "Software", "start_offset": 231, "end_offset": 237}, {"id": 1254, "label": "Software", "start_offset": 547, "end_offset": 553}, {"id": 1255, "label": "Software", "start_offset": 691, "end_offset": 697}]}
{"id": 4918, "text": "GenotypeChecker is a desktop tool for identifying likely data errors in pedigree/genotype datasets and to assist data cleansing.\n\nDatapoint errors in pedigree genotype datasets are difficult to identify and adversely affect downstream genetic analyses. Errors that are inconsistent with the rules of Mendelian inheritance typically invalidate linkage analysis algorithms, and cause such analyses to fail. Genotype errors may arise from a variety of systematic or sporadic errors in either the genotyping assay, or in recording the pedigree or genotype information.\n\nBy applying an inheritance-checking algorithm for markers across the pedigree and visualising the inheritance data in an exploratory user interface, GenotypeChecker allows the sources of data inconsistency can be resolved.", "entities": [{"id": 1467, "label": "Software", "start_offset": 0, "end_offset": 15}]}
{"id": 4919, "text": "VIPER combines an improved ResSpecies algorithm for genotype inheritance checking and inference with a novel space-efficient visualisation of pedigree structure in a desktop tool for exploring then cleaning data errors in pedigree/genotype datasets.\n\nDatapoint errors in pedigree genotype datasets are difficult to identify and adversely affect downstream genetic analyses. Errors that are inconsistent with the rules of Mendelian inheritance typically invalidate linkage analysis algorithms, and cause such analyses to fail. Genotype errors may arise from a variety of systematic or sporadic errors in either the genotyping assay, or in recording the pedigree or genotype information.\n\nBy applying an inheritance-checking algorithm for markers across the pedigree and visualising the inheritance data in an exploratory user interface, VIPER allows the sources of data inconsistency can be resolved.\n\nVIPER displays the structure of the study population in a novel pedigree visualisation of generation sandwiches. Error rates reported by the inheritance algorithm are overlaid on the pedigree structure, allowing the inheritance pattern of reported errors to be explored, and the likely underlying bad datapoint resolved.", "entities": [{"id": 1720, "label": "Software", "start_offset": 0, "end_offset": 5}, {"id": 1721, "label": "Software", "start_offset": 901, "end_offset": 906}, {"id": 1722, "label": "Software", "start_offset": 836, "end_offset": 841}]}
{"id": 4920, "text": "Topographic analysis software", "entities": [{"id": 602, "label": "Software", "start_offset": 0, "end_offset": 29}]}
{"id": 4921, "text": "Software for extracting channel networks from topographic data", "entities": []}
{"id": 4922, "text": "A suite of Fortran programmes has been developed for analysis of cerebral haemodynamic measurements, including data editing, transfer function analysis, time-domain modelling and coherent averaging. This software has been shared with collaborators in different international centres.", "entities": []}
{"id": 4923, "text": "The File checker is a user tool to help longitudinal population study data managers bring their file submissions in line with the requirements set out in &quot;UK Longitudinal Linkage Collaboration: Guidance for Depositing Data into the UK LLC&quot;. The checker conducts several automated checks on the file name, file formatting and file contents where appropriate.", "entities": [{"id": 1256, "label": "Software", "start_offset": 4, "end_offset": 16}]}
{"id": 4924, "text": "The program consists of 2 R scripts a &quot;helper&quot; and &quot;functions&quot;. The latter providing functions to the former for extracting data from the database and applying metadata (value and variable) labelling via the expss package.", "entities": [{"id": 1468, "label": "Software", "start_offset": 44, "end_offset": 50}, {"id": 1469, "label": "Software", "start_offset": 67, "end_offset": 76}]}
{"id": 4925, "text": "This process runs following receipt of quarterly NHS extracts. It unions/appends, deduplicates and runs qc checks to ensure the data as been received and loaded as per specifications.", "entities": []}
{"id": 4926, "text": "This program is written in python and stata using the pystata python package for interoperability. The program extracts all approved database views for a project, saves local versions to a users working area and applies value and variable labelling where available.", "entities": []}
{"id": 4927, "text": "The UK LLC data provisioning pipeline (python) takes a research user defined request for data and creates a series of project-specific SQL views. The views are the data representation of the user request. The user request has 2 inputs. Firstly a list of the data tables required, these are datasets selectable from approx. 20 longitudinal population studies. Secondly, for selection of NHS D data this is done at the row level using medical code lists for data where this is practicable. Both of these selection steps allow data minimisation so research data users are provide only with data which is pertinent to the research question. The process also creates a set of project specific IDs and matches these to all datasets at the individual-level. This is an extra control so that data cannot be joined between projects in the TRE.", "entities": [{"id": 826, "label": "Software", "start_offset": 0, "end_offset": 37}]}
{"id": 4928, "text": "The UK LLC receives data from over 20 studies from the LPS community as well as linked records from NHS D. The receipt and upload of data to the UK LLC database is performed by the Population Data Science development team at Swansea University (SU) and Managed by the UK LLC team at the University of Bristol (UoB). The database sits within the UK LLC's Secure eResearch Platform (SeRP UK). This is a Trusted Research Environment (TRE) enabling research data users a safe a secure method to access and analyse data approved as part of their project. \n\nWhen data arrives in the database the UK LLC team are required to check the data is expected and any cleaning and data harmonisation tasks are performed. This is done to enable data provisioning to research data users in an efficient manner maintaining data integrity.\n\nThe data processing pipeline is a modular system directed by a single controlling script to transform data that arrives in the database to a state that can be presented to UK LLC research data users, and to thoroughly document all data in the database. Each subprocess is addressed in its own script. Subprocesses are run sequentially in a required order.&nbsp;Each modules is written in python with embedded T-SQL to enable inaction with the UK LLC database.\n\nThe subprocess cover the following broad actions:\n1) Check contents of database and creates initial data asset register \n2) Harmonise metadata column names in meta data tables (variable and value labels) and merge meta data tables where necessary \n3) Rename tables where tables do not follow table naming conventions as per UK LLC file guidance. This process includes a manual review that the suggestions are correct. \n4) Harmonising metadata (value and variable labels) cell values so their fields and values match with the master data tables and are thus linkable \n5) Creation of master lookup tables/views for all value and variable label metadata\n6) Re-check contents of database and creates final (but pre-disclosure risk assessment) data asset register", "entities": [{"id": 1044, "label": "Software", "start_offset": 822, "end_offset": 850}]}
{"id": 4929, "text": "The software creates a series of random/fake address pulled from the OS AddressBase+ database. The idea is that studies that collect address data can have masking address generated maintaining a distribution that is realistic. When de-coupled from other identifiers the list of real+fake address can be shared maintaining a high degree of confidentially, allowing external parties to model and add data e.g. air pollution measures to study participants datasets. The user supplies the program with a definitions input file where they can define:\n1) geocoordinate centres (important for geographically constrained studies)\n2) A search radius \n3) Start year\n4) Number of individuals to create fake addresses for\n5) Whether to include full address or postcode only\nThe software uses the OS AddressBase+ database which includes every residential address in the UK. It then searches for addresses (randomly) using search criteria. it will then assign start and end dates to the addresses (randomly) although maintaining a realistic distribution as per the study definition information. The program will also added dirtyness (commonly mistyped chars/digits) to the postcode field. This is done so that when joined to a list of real addresses there is a degree of error consistent with reality.", "entities": []}
{"id": 4930, "text": "This software consists of 2 parts, a python &quot;notebook_helper.py&quot; script this contains a helper class with a variety of functions which can be used with the second part, the jupyter notebook itself. The jupyter notebook has pre-pared code to access and analyse data contained within a users working space in the SeRP TRE. It deals with fetching of data and associated metadata and gives examples of how to display this with the notebook.", "entities": [{"id": 1470, "label": "Software", "start_offset": 50, "end_offset": 68}]}
{"id": 4931, "text": "Before data is made available to researchers, it must pass a secondary disclosure control check. This is a failsafe check to catch any disclosure risks not identified before data was loaded into the UKLLC Database. The check involves an automated pass to identify and new or changed database tables and identify possible risks. A UK LLC operator then review each for these tables, using the automatically suggested potential risks as guidance. Only once a table has been explcitly approved by the operator will it be available to researchers.", "entities": []}
{"id": 4932, "text": "BiForce Toolbox to address the demand for high-throughput analysis of pairwise epistasis in either quantitative or disease traits across all commonly used computer systems. BiForce Toolbox is a stand-alone Java program that integrates bitwise computing with multithreaded parallelization and thus allows rapid full pairwise genome scans via a graphical user interface or the command line. Furthermore, BiForce Toolbox incorporates additional tests of interactions involving SNPs with significant marginal effects, potentially increasing the power of detection of epistasis.", "entities": [{"id": 603, "label": "Software", "start_offset": 0, "end_offset": 15}, {"id": 604, "label": "Software", "start_offset": 173, "end_offset": 188}, {"id": 605, "label": "Software", "start_offset": 402, "end_offset": 417}]}
{"id": 4933, "text": "Online learning resources targeted at web designers to help them build websites which are accessible to people with learning disabilities.", "entities": []}
{"id": 4934, "text": "CCDC API for obtaining CSD coordinate data for molecules in the PDB", "entities": [{"id": 1045, "label": "Software", "start_offset": 0, "end_offset": 9}]}
{"id": 4935, "text": "REST API for all PDBe information", "entities": []}
{"id": 4936, "text": "A package for simulating community dynamics. Useful for studying synchrony because one can simulate communties and thereby understand how population become synchronized. Based on Cheddar.", "entities": []}
{"id": 4937, "text": "A software package released on the Comprehensive R Archive Network and described in a publication also listed on this system. For manipulating ecological community data.", "entities": []}
{"id": 4938, "text": "This repository was released on GitHub. It allows the reproduction of the neural network used for audio-visual sound event detection and localisation (AV-SELD) described in the paper. This represents one of the earliest works on AV-SELD, performed on the recently-released STARSS23 dataset.", "entities": []}
{"id": 4939, "text": "This repository was released on GitHub. It allows the reproduction of the neural network used for horizontal active speaker detection described in the paper. The network leverages multichannel audio captured with a microphone array to locate the active speaker on the video frames. The repository includes the trained models.", "entities": []}
{"id": 4940, "text": "This is an automated method to detect and quantify distribution and density of fungiform papillae across the anterior 2 cm of the tongue from a high resolution digital image.", "entities": []}
{"id": 4941, "text": "We have developed a number of modifications to the 7T MR scanner code, image analysis steps in MR tools, and stand-alone matlab scripts.", "entities": []}
{"id": 4942, "text": "A novel algorithm to reconstruct ancestral chromosome structures from both completely assembled and fragmented animal genomes have been developed.", "entities": []}
{"id": 4943, "text": "G-Anchor is a new software designed to quickly align complete mammalian genomes utilising conserved non coding elements", "entities": [{"id": 1719, "label": "Software", "start_offset": 0, "end_offset": 8}]}
{"id": 4944, "text": "The Web-based App is a platform that links Ethiopian parliamentarians and their constituents, enhancing political communication and engagement in a country transitioning to democracy.", "entities": []}
{"id": 4945, "text": "A Kilobot simulator to enable effective research in swarm robotics", "entities": [{"id": 827, "label": "Software", "start_offset": 1, "end_offset": 19}]}
{"id": 4946, "text": "Two new computational models, implemented in the rule-based language Chromar: \n - FM-lite for the vegetative growth of Arabidopsis thaliana, including modifications to use real weather data.\n- FM-life for the entire lifecycle of Arabidopsis, from seed to seed.", "entities": []}
{"id": 4947, "text": "Chromar is a rule-based modelling language, implemented in the general-purpose programming language Haskell. Chromar supports multi-scale models that create and destroy agents; it extends the formalisms simialr to coloured Petri nets using externally-defined functions (fluents, useful to represent meteorological or experimental inputs) and observables (model outputs that are calculated from the primary agents and their attributes). This makes it helpful in multi-scale applications such as whole-organism models, in our case the Arabidopsis Framework Model.", "entities": [{"id": 1257, "label": "Software", "start_offset": 0, "end_offset": 8}, {"id": 1258, "label": "Software", "start_offset": 109, "end_offset": 116}]}
{"id": 4948, "text": "&quot;Gamma MaP&quot; can be used for computations involving various objects related to spinors in physics, such as gamma matrices, spinors and tensors. The package implements the relations satisfied by the gamma matrices and other relevant objects completely abstractly using the properties of a relevant Clifford algebra and thus does not require use of any particular representation of Clifford algebra. In particular, this allows the package to work for any dimension and signature and makes it possible for the user specify flexibly how they like some computations performed i.e. how some of the relevant expressions are simplified.\n\nThe lengthy computations that the software can perform find numerous applications in physics, in particularly for computations related to supersymmetry and -gravity, as demonstrated in the documentation.", "entities": [{"id": 1471, "label": "Software", "start_offset": 6, "end_offset": 15}]}
{"id": 4949, "text": "De novo DNA synthesis is in need of new ideas for increasing production rate and reducing cost. DNA reuse in combinatorial library construction is one such idea. Here, we describe an algorithm for planning multistage assembly of DNA libraries with shared intermediates that greedily attempts to maximize DNA reuse, and show both theoretically and empirically that it runs in linear time. We compare solution quality and algorithmic performance to the best results reported for computing DNA assembly graphs, finding that our algorithm achieves solutions of equivalent quality but with dramatically shorter running times and substantially improved scalability. We also show that the related computational problem bounded-depth min-cost string production (BDMSP), which captures DNA library assembly operations with a simplified cost model, is NP-hard and APX-hard by reduction from vertex cover. The algorithm presented here provides solutions of near-minimal stages and thanks to almost instantaneous planning of DNA libraries it can be used as a metric of ?manufacturability? to guide DNA library design. Rapid planning remains applicable even for DNA library sizes vastly exceeding today's biochemical assembly methods, future-proofing our method.", "entities": []}
{"id": 4950, "text": "ssapredict is a web service designed to automate the process of determining the fastest stochastic simulation algorithm (SSA) for a bio-chemical model. It calculates the topological properties of a model to predict the best performing algorithm.\n\nssapredict is easy to use. With one-button click you upload a model and receive a prediction.\nYou can then download the simulator customised for your model (for GNU/Linux, Windows or Mac OS).", "entities": [{"id": 606, "label": "Software", "start_offset": 247, "end_offset": 257}, {"id": 607, "label": "Software", "start_offset": 0, "end_offset": 10}]}
{"id": 4951, "text": "Simbiotics is a 3D simulation tool offering a range of modelling features to describe bacterial populations. Bacterial cells are represented as discrete geometric entities which may have internal processes and interact with their environment. Modellers may describe specific bacterial behaviour, environmental factors and the spatial arrangement of cellular populations, this is achieved via composing library modules into a model specification. Modules describe specific features to be simulated and are parameterisable, the library is extendable to allow for novel models of relevant processes to be added to the tool. Simulations can be run on mulit-threaded and multi-CPU environments to ensure the platform can represent industrially relevant systems.\n\nSimbiotics can be initialised via common standards experimentalists use such as microscopy image data and SBML models, allowing for the rapid development of 3D population models. An optional live 3D rendering and data graphing is available, alternatively exporting data in common formats (CSV and JSON) allow for the integration of Simbiotics into existing tools such as Blender or PovRay. The tool requires minimal programming experience to use.", "entities": [{"id": 828, "label": "Software", "start_offset": 0, "end_offset": 10}, {"id": 829, "label": "Software", "start_offset": 758, "end_offset": 768}, {"id": 830, "label": "Software", "start_offset": 1090, "end_offset": 1100}]}
{"id": 4952, "text": "The webserver presented here provides solutions of near-minimal stages and thanks to almost instantaneous planning of DNA libraries it can be used as a metric of ?manufacturability? to guide DNA library design. Rapid planning remains applicable even for DNA library sizes vastly exceeding today's biochemical assembly methods, future-proofing our method.", "entities": []}
{"id": 4953, "text": "The Infobiotics Workbench is a executable biology framework implementing multi-compartmental stochastic and deterministic simulation, formal model analysis and structural/parameter model optimisation for computational systems and synthetic biology.\n\nThe Infobiotics Workbench is comprised of the following components:\n\n a modelling language based on P systems which allows modular and parsimonious multi-cellular model development where the outermost compartments can be positioned in 2-dimensional space to facilitate modelling at either extra-, inter- or intracellular levels of detail\n\n deterministic and stochastic simulator using algorithms optimised for large multi-compartmental systems (the simulator also accept a subset of SBML, allowing for visual model specification using tools such as CellDesigner)\n\n formal model analysis for the study of temporal and spatial model properties supported the model checkers PRISM and MC2\n\n model structure and parameter optimisation using a variety of evolutionary and population-based algorithms to automatically generate models whose dynamics match specified target timeseries\n\n a user-friendly front-end for performing in-silico experiments, plotting and visualisation of simulations with many runs and compartments", "entities": [{"id": 1260, "label": "Software", "start_offset": 4, "end_offset": 25}, {"id": 1261, "label": "Software", "start_offset": 254, "end_offset": 275}]}
{"id": 4954, "text": "The main outcome of the project was the development of our research prototype into commercial software. This software is now available on the app store, as Syncphonia Conductor and Syncphonia Performer. It was released in sept 2017", "entities": [{"id": 1472, "label": "Software", "start_offset": 156, "end_offset": 176}, {"id": 1473, "label": "Software", "start_offset": 181, "end_offset": 201}]}
{"id": 4955, "text": "Pilot version of networked synchronised music notation for musical ensembles, available via app store (free).", "entities": []}
{"id": 4956, "text": "This repository includes the R code associated with the analysis and visualisation of datasets containing energy proxy traits (EPT). Whilst the majority of functions are written for EPT data, there are some additional methods that can be applied to other datasets produced by EmbryoCV.", "entities": []}
{"id": 4957, "text": "vimbaPy is a set of python classes for interfacing with the two main python wrappers for the Vimba C API: pymba and VimbaPython. Differences in the implementations of either wrapper can mean that functions written in one may work better for your particular workflow, and so a combination of both wrappers may provide the most complete solution. As such, both have been included here to allow users to easily experiment with either wrapper through a simple declarative interface:", "entities": [{"id": 831, "label": "Software", "start_offset": 116, "end_offset": 127}, {"id": 832, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4958, "text": "LabEmbryoCam is an opensource imaging apparatus for automated screening of developing aquatic embryos, integrating custom hardware and software.", "entities": [{"id": 1046, "label": "Software", "start_offset": 0, "end_offset": 12}]}
{"id": 4959, "text": "We developed this library to make coding up computer vision interfaces fast and efficient, allowing users to focus on their given application and bypass the challenges associated with developing a working user interface. We have since extended this to other areas of the [`OpenCV`](https://opencv.org/) library, writing wrappers where we feel the reduction in code verbosity improves both readability and reduces complexity in codebases.", "entities": []}
{"id": 4960, "text": "HeartCV is an easy to use library for automated, noninvasive quantification of cardiac traits in transparent animals. We developed this library to primarily reduce the barrier to entry for researchers seeking to assess the cardiac physiology of their animals through bioimaging.", "entities": [{"id": 1474, "label": "Software", "start_offset": 0, "end_offset": 7}]}
{"id": 4961, "text": "This project has been led by Dr Ruth Wilcox in partnership with Simpleware Limited. The development of the software add-on has been completed and the final validations with the Leeds data set-set are coming to an end. It is anticipated that a technology demonstrator project will now be undertaken with a company that can demonstrate the utility of the software for evaluating spinal implants. The commercial team is now engaged and discussions with Simpleware around a possible license deal are on-going. It is envisaged that as part of this license deal Simpleware will engage Leeds expertise as part of their offer to companies. In addition Leeds personnel will retain the right to undertake consultancy in their own capacity.", "entities": []}
{"id": 4962, "text": "Automated software to check algebraic properties of pubich and private announcements in multi-agent systems", "entities": []}
{"id": 4963, "text": "Allows the user to search through and visualise a gene network that was describes how genes are regulated in the early morning. Several edges of the network have already been experimentally validated.", "entities": []}
{"id": 4964, "text": "This is a statistical package for clustering time series RNA-seq data on the basis of the functional map between time series datasets. This can help with identifying groups of genes that are regulated in the same way as a result of environmental perturbation and help with experimental design.", "entities": []}
{"id": 4965, "text": "Summarises biological gene networks in a format that makes it easier to interpret and develop new biological hypotheses", "entities": [{"id": 1262, "label": "Software", "start_offset": 0, "end_offset": 35}]}
{"id": 4966, "text": "The Controller-Responder Socket (CRSocket) is a web app component that can be used to develop digital tasks where testers use a controller device to administer trials and a separate responder device to present stimuli and collect responses. In addition to providing a more streamlined and comfortable test situation, this approach may improve measurement quality because potentially distracting activities related to configuration and initiation of tasks are hidden from the participant. It also facilitates more flexible data collection protocols where testers can make real-time adjustments based on direct observations of the test situation and feedback from various sources presented on the controller device. In addition to communication functionality, the CRSocket also provides client-side buffering of events and server-side plug-in interfaces related to access control and data storage. Please note that usage of this software requires programming skills and experience with the PHP and JavaScript programming languages.", "entities": [{"id": 1475, "label": "Software", "start_offset": 4, "end_offset": 31}, {"id": 1476, "label": "Software", "start_offset": 33, "end_offset": 41}, {"id": 1477, "label": "Software", "start_offset": 762, "end_offset": 770}]}
{"id": 4967, "text": "The code underlying the current app can be downloaded here: https://figshare.com/articles/software/ECITT_Web_App/13258814\n\nThe app is still in development.", "entities": [{"id": 1718, "label": "Software_Url", "start_offset": 60, "end_offset": 121}]}
{"id": 4968, "text": "This software has been developed for presentation of visual stimuli in studies with infants and young children. It also controls a Tobii eye-tracker and synchronises several data streams.", "entities": []}
{"id": 4969, "text": "All the woolz image-processing software, applications and the IIP3D 3D tile-image servers re now available from the ma-tech github repository.", "entities": []}
{"id": 4970, "text": "A new app for the detection of dementia", "entities": []}
{"id": 4971, "text": "We developed an online cognitive battery for collection of data linked to different brain networks involved in dementia", "entities": []}
{"id": 4972, "text": "In collaboration with ProteinMetrics (https://www.proteinmetrics.com/), we are trying to customize available software solutions for peptidoglycan analysis. This has been facilitated by a BBSRC iCASE studentship (2017-2021). The source code has been modified to improve both the annotation of spectra and scoring method of peptidoglycan fragments (2017-2018).\nWe are currently working towards a complete automated process whereby several software solutions are combined to provide a comprehensive analysis of MS1 and MS2 data as well as a quantification of peptidoglycan fragments.\nSince October 2018, we have generated a dedicated software which can predict fragmentation products from any peptidoglycan fragment using a graphic representation of molecules. This is being tested with Clostridium difficile peptidoglycan as a model system.", "entities": []}
{"id": 4973, "text": "COMPLEX-IT (a free R-Studio App) improves the user-centeredness of computational modelling (CM) by opening-up its 'black-box' in two key ways: functionality and interface design. COMPLEX-IT's functionality is unique because it runs a specific suite of techniques that support case-based data exploration, multi-agent modeling and prediction. Second, COMPLEX-IT's tab-driven interface provides users a seamless, simpler and visually intuitive platform. Also, advanced users can examine, download or modify COMPLEX-IT's algorithms, results, and code.", "entities": [{"id": 1714, "label": "Software", "start_offset": 0, "end_offset": 10}, {"id": 1715, "label": "Software", "start_offset": 179, "end_offset": 189}, {"id": 1716, "label": "Software", "start_offset": 350, "end_offset": 360}, {"id": 1717, "label": "Software", "start_offset": 505, "end_offset": 515}]}
{"id": 4974, "text": "Uniqueness of the model is in very granular spatial and temporal resolution while considering multi-energy vectors including electricity, heat, transport.", "entities": []}
{"id": 4975, "text": "This is the first software that can deal with natural volatilities existing in consumer homes, many conversion efficiencies cross subsystems, such as DC/DC conversion, DC/AC conversation. This is achieved by substantially simplifying the management problem by converting all efficiency issues into the impact to the main's supply.", "entities": []}
{"id": 4976, "text": "The software combines technical modelling of power system and economic appraisal in the Excel platform, able to quantify the long-term network investment cost from connecting a generator or demand at each node in the system. Using the traditional approach, the process is an iterative method between technical modelling and economic appraisal and requires operates to transfer data from modelling to economic analyses. Not only it takes nearly 100 times of Bath platform, it is prone to human errors. The software development is supported by the University of Bath IAA fund and WPD's cash support.", "entities": []}
{"id": 4977, "text": "Modification of existing pipelines to handle sequence data from eukaryote microbes. \n\nOEDS: This pipeline takes (publically) available genome sequences for a range of pathogens (within the Phytophthora genus) and identifies regions of genomes that are unique to a given pathogen. By using sequences from multiple isolates within a species, the pipeline can automatically design species-specific primers for validation and deployment in the lab and field respectively.\n\nPDP: Primer Diagnostic Pipeline (PDP) is a modular pipeline derived from the Find Differential Primers pipeline. The published pipeline has seven steps - validate input config file, concatenate sequences, identify features, predict primer locations, cross amplification, BLAST screen and classify. PDP has the ability to produce diagnostic primer candidate-specific at species, sub-species and isolate level (depending on the dataset). The sub-species-specific primers can group particular isolates together whilst distinguishing them from other isolates.", "entities": [{"id": 1265, "label": "Software", "start_offset": 86, "end_offset": 90}, {"id": 1266, "label": "Software", "start_offset": 469, "end_offset": 472}, {"id": 1267, "label": "Software", "start_offset": 474, "end_offset": 500}, {"id": 1268, "label": "Software", "start_offset": 502, "end_offset": 505}, {"id": 1269, "label": "Software", "start_offset": 767, "end_offset": 770}]}
{"id": 4978, "text": "Software correctness analysis tool associated with Mokapot (described separately).", "entities": []}
{"id": 4979, "text": "Village doctors in the intervention arm are provided with the SINEMA APP, designed for this study to standardize the flow of the monthly follow-up visit. With the assistance of SINEMA APP, during each monthly follow-up visit, village doctors will collect information about participants' health conditions, medication use, blood pressure level, etc.; and provide health education to participants on medication adherence and physical activity.", "entities": [{"id": 1712, "label": "Software", "start_offset": 0, "end_offset": 15}, {"id": 1713, "label": "Software", "start_offset": 226, "end_offset": 241}]}
{"id": 4980, "text": "We extended the GESIS Search Engine for social scientists with large language models, e.g., to summarise search results. This is implemented as Web-based micro services.", "entities": [{"id": 608, "label": "Software", "start_offset": 16, "end_offset": 35}]}
{"id": 4981, "text": "The Rothamsted carbon model Python version (RothC_Py) Purpose RothC models the turnover of organic carbon in non-waterlogged top-soil. It accounts for the effects of soil texture, temperature, moisture content and plant cover on the turnover process. It uses a monthly time step to calculate total organic carbon (t ha-1), microbial biomass carbon (t ha-1) and ?14C (from which the equivalent radiocarbon age of the soil can be calculated). Development history The first version of RothC created by David Jenkinson and James Rayner in 1977 (Jenkinson and Rayner, 1977). In 1987 an updated version was published, see Jenkinson et al. (1987). This version included the prediction of the radiocarbon age of the soil, the pools POM (physically stabilized organic matter) and COM (chemically stabilized organic matter) were replaced with Hum (humified organic matter) and IOM (inert organic matter), and the microbial biomass pool was split into BioA (autochthonous biomass) and BioZ (zymogenous biomass). In 1990, the two biomass pools were combined into a single pool (Jenkinson, 1990) this version is the standard version of the model, that this code refers to. Other published developments of the model include: Farina et al. (2013) modified the soil water dynamics for semi-arid regions. Giongo et al. (2020) created a daily version and modified the soil water dynamics, for Caatinga shrublands, in the semiarid region, North-East Brazil. Description of files included RothC_description.pdf This file contains the description of the model. RothC_Py.py This file contains the RothC code in Python language. Details of the inputs required, pools modelled, and units are in the code. RothC_input.dat This file contains input variables for the model. At the start of the file values for clay (%), soil depth (cm), inert organic matter (IOM, t C ha-1) and number of steps (nsteps) are recorded.Following that there is a table which records monthly data on year, month, percentage of modern carbon (%), mean air temperature (Tmp, &deg;C), total monthly rainfall (Rain, mm), total monthly open-pan evaporation (Evap, mm), all carbon input entering the soil (from plants, roots, root exudates) (C_inp, t C ha-1), carbon input from farmyard manure (FYM, t C ha-1), plant cover (PC, 0 for no plants e.g. bare or post-harvest, 1 for plants e.g. crop or grass), and the DPM/RPM ratio (DPM_RPM) of the carbon inputs from plants. year_results.csv This file contains the yearly values of the SOC (both the pools and Total) and the delta 14-carbon. The pools are:YearMonth - Always December for the yearly outputDPM - Decomposable plant material (t C ha-1)RPM - Resistant plant material (t C ha-1)BIO - Microbial biomass (t C ha-1)HUM - Humified organic matter (t C ha-1)IOM - Inert organic matter (t C ha-1)SOC - Total soil organic carbon (t C ha-1)deltaC - delta 14C (‰) The total organic carbon (soil organic carbon) is equal to the sum of the 5 pools. TOC or SOC = DRM + RPM + BIO + HUM + IOM month_results.csv This file contains the monthly inputs, rate modifying factors, SOC pools. YearMonthDPM_t_C_ha - Decomposable plant material (t C ha-1)RPM_t_C_ha - Resistant plant material (t C ha-1)BIO_t_C_ha - Microbial biomass (t C ha-1)HUM_t_C_ha - Humified organic matter (t C ha-1)IOM_t_C_ha - Inert organic matter (t C ha-1)SOC_t_C_ha - Total soil organic carbon (t C ha-1) Requirements The code was written in Python 3.9.7. Installation/set-up A directory path will need to be provided as indicated in the code ([&quot;INPUT DIRECTORY PATH&quot;]), to read in RothC_input.dat. Example of how to run the modelThe file RothC_input.dat contains all the inputs data needed to run the model. The month results (month_results.csv) and year results (year_results.csv) files correspond to this input file as an example. The model is normally run to equilibrium using average temperature, rainfall, open pan evaporation, an average carbon input to the soil, the equilibrium run is to initialise the soil carbon pools. Once the soil carbon pools have been initialised, the model is run for the period of interest. The met data (temperature, rainfall and evaporation) can be average or actual weather data. The carbon input to the soil can be: 1) adjusted so the modelled output matches the measured data, or 2) can be estimated from yield data (Bolinder et al., 2007), or NPP data. References Bolinder MA, Janzen HH, Gregorich EG, Angers DA, VandenBygaart AJ. An approach for estimating net primary productivity and annual carbon inputs to soil for common agricultural crops in Canada. Agriculture, Ecosystems &amp; Environment 2007; 118: 29-42.Farina R, Coleman K, Whitmore AP. Modification of the RothC model for simulations of soil organic C dynamics in dryland regions. Geoderma 2013; 200: 18-30.Giongo V, Coleman K, Santana MD, Salviano AM, Olszveski N, Silva DJ, et al. Optimizing multifunctional agroecosystems in irrigated dryland agriculture to restore soil carbon - Experiments and modelling. Science of the Total Environment 2020; 725.Jenkinson DS. The Turnover of Organic-Carbon and Nitrogen in Soil. Philosophical Transactions of the Royal Society of London, Series B: Biological Sciences 1990; 329: 361-368.Jenkinson DS, Hart PBS, Rayner JH, Parry LC. Modelling the turnover of organic matter in long-term experiments at Rothamsted. INTECOL Bulletin 1987; 15: 1-8.Jenkinson DS, Rayner JH. Turnover of soil organic matter in some of the Rothamsted classical experiments. Soil Science 1977; 123: 298-305.", "entities": [{"id": 834, "label": "Software", "start_offset": 3, "end_offset": 35}, {"id": 835, "label": "Software", "start_offset": 44, "end_offset": 52}]}
{"id": 4982, "text": "The code models the invasion and spread of the Emerald Ash Borer in Great Britain", "entities": []}
{"id": 4983, "text": "The Rothamsted carbon model (RothC) Purpose Roth C models the turnover of organic carbon in non-waterlogged top-soil. It accounts for the effects of soil texture, temperature, moisture content and plant cover on the turnover process. It uses a monthly time step to calculate total organic carbon (t ha -1), microbial biomass carbon (t ha -1) and ?14C (from which the equivalent radiocarbon age of the soil can be calculated). Development history The first version of RothC created by David Jenkinson and James Rayner in 1977 (Jenkinson and Rayner, 1977). In 1987 an updated version was published, see Jenkinson et al. (1987). This version included the prediction of the radiocarbon age of the soil, the pools POM (physically stabilized organic matter) and COM (chemically stabilized organic matter) were replaced with Hum (humified organic matter) and IOM (inert organic matter), and the microbial biomass pool was split into BioA (autochthonous biomass) and BioZ (zymogenous biomass). In 1990, the two biomass pools were combined into a single pool (Jenkinson, 1990) this version is the standard version of the model, that this code refers to. Other published developments of the model include: Farina et al. (2013) modified the soil water dynamics for semi-arid regions. Giongo et al. (2020) created a daily version and modified the soil water dynamics, for Caatinga shrublands, in the semiarid region, North-East Brazil. Description of files included RothC_description.docx This file contains the description of the model. RothC.for This file contains the RothC code, it can be used as a standalone subroutine or used with shell.for to create an exe file. Details of the inputs required, pools modelled, and units are in the code. Shell.for This file is intended as an example of how to: 1) read in the input data 2) call the subroutine 3) created monthly and yearly outputs The file can be used to create a standalone exe, or you can replace it with your own code to call and run RothC. Details of the inputs required, pools modelled, and units are in the code. RothC_input.dat This file contains input variables for the model. At the start of the file values for clay (%), soil depth (cm), inert organic matter (IOM, t C ha-1) and number of steps (nsteps) are recorded. Following that there is a table which records monthly data on year, month, percentage of modern carbon (%), mean air temperature (Tmp, &deg;C), total monthly rainfall (Rain, mm), total monthly open-pan evaporation (Evap, mm), all carbon input entering the soil (from plants, roots, root exudates) (C_inp, t C ha-1), carbon input from farmyard manure (FYM, t C ha-1), plant cover (PC, 0 for no plants e.g. bare or post-harvest, 1 for plants e.g. crop or grass), and the DPM/RPM ratio (DPM_RPM) of the carbon inputs from plants. year_results.out This file contains the yearly values of the SOC (both the pools and Total) and the delta 14-carbon. The pools are: Year Month - Always December for the yearly output DPM - Decomposable plant material (t C ha-1) RPM - Resistant plant material (t C ha-1) BIO - Microbial biomass (t C ha-1) HUM - Humified organic matter (t C ha-1) IOM - Inert organic matter (t C ha-1) SOC - Total soil organic carbon (t C ha-1) deltaC - delta 14C (‰) The total organic carbon (soil organic carbon) is equal to the sum of the 5 pools. TOC or SOC = DRM + RPM + BIO + HUM + IOM month_results.out This file contains the monthly inputs, rate modifying factors, SOC pools. Year Month C_Inp_t_C_ha - C input (t C ha-1) FYM_Inp_t_C_ha - Farmyard manure (t C ha-1) TEMP_C - Air temperature (C) RM_TMP - Rate modifying factor for temperature (-) RAIN_mm - Rainfall (mm) PEVAP_mm - Open pan evaporation (mm) SWC_mm - Accumulated soil water deficit (mm) RM_Moist - Rate modifying factor for soil moisture (-) PC - Soil plant cover (0 bare or 1 covered) RM_PC - rate modifying factor for crop cover DPM_t_C_ha - Decomposable plant material (t C ha-1) RPM_t_C_ha - Resistant plant material (t C ha-1) BIO_t_C_ha - Microbial biomass (t C ha-1) HUM_t_C_ha - Humified organic matter (t C ha-1) IOM_t_C_ha - Inert organic matter (t C ha-1) SOC_t_C_ha - Total soil organic carbon (t C ha-1) Requirements The code does not require any particular of version of Fortran, so can be compiled in both windows and Linux. Installation/set-up A Fortran compiler is needed. The code can be used in the following ways: 1. The two Fortran files (RothC.for and Shell.for) can either be compiled and linked to create a standalone exe, which uses the input file (RothC_input.dat), when run, monthly (month_results.out) and yearly (year_results.out) output files are created. 2. The file (shell.for) can be modified to read in required data in the format you have, your modified code can be compiled and linked to RothC.for. 3. The file (RothC.for) can be called by your exiting code as a subroutine. Example of how to run the model The file RothC_input.dat contains all the inputs data needed to run the model. The month results (month_results.out) and year results (year_results.out) files correspond to this input file as an example. The model is normally run to equilibrium using average temperature, rainfall, open pan evaporation, an average carbon input to the soil, the equilibrium run is to initialise the soil carbon pools. Once the soil carbon pools have been initialised, the model is run for the period of interest. The met data (temperature, rainfall and evaporation) can be average or actual weather data. The carbon input to the soil can be: 1) adjusted so the modelled output matches the measured data, or 2) can be estimated from yield data (Bolinder et al., 2007), or NPP data. References Bolinder MA, Janzen HH, Gregorich EG, Angers DA, VandenBygaart AJ. An approach for estimating net primary productivity and annual carbon inputs to soil for common agricultural crops in Canada. Agriculture, Ecosystems &amp; Environment 2007; 118: 29-42. Farina R, Coleman K, Whitmore AP. Modification of the RothC model for simulations of soil organic C dynamics in dryland regions. Geoderma 2013; 200: 18-30. Giongo V, Coleman K, Santana MD, Salviano AM, Olszveski N, Silva DJ, et al. Optimizing multifunctional agroecosystems in irrigated dryland agriculture to restore soil carbon - Experiments and modelling. Science of the Total Environment 2020; 725. Jenkinson DS. The Turnover of Organic-Carbon and Nitrogen in Soil. Philosophical Transactions of the Royal Society of London, Series B: Biological Sciences 1990; 329: 361-368. Jenkinson DS, Hart PBS, Rayner JH, Parry LC. Modelling the turnover of organic matter in long-term experiments at Rothamsted. INTECOL Bulletin 1987; 15: 1-8. Jenkinson DS, Rayner JH. Turnover of soil organic matter in some of the Rothamsted classical experiments. Soil Science 1977; 123: 298-305.", "entities": [{"id": 1270, "label": "Software", "start_offset": 4, "end_offset": 28}, {"id": 1271, "label": "Software", "start_offset": 29, "end_offset": 34}, {"id": 1272, "label": "Software", "start_offset": 44, "end_offset": 50}, {"id": 1273, "label": "Software", "start_offset": 1526, "end_offset": 1531}, {"id": 1274, "label": "Software", "start_offset": 1559, "end_offset": 1564}, {"id": 1275, "label": "Software", "start_offset": 1984, "end_offset": 1989}]}
{"id": 4984, "text": "PyPSA-GB is a dataset and model of the Great Britain electricity system. It uses PyPSA (Python for Power Systems Analysis) to peform power dispatch and planning studies. Energy system models with high spatial and temporal resolution are required to analyse systems reliant on variable renewable generation. PyPSA-GB is an open dataset and power dispatch model of the GB transmission network using country-specific data over historical years and for future energy scenarios. Two aspects of the GB electricity market can be readily modelled: (i) the wholesale electricity market, by solving a single bus unit commitment optimisation problem to dispatch generators and storage, and (ii) the balancing mechanism, by solving a network constrained linear optimal power flow.", "entities": [{"id": 1478, "label": "Software", "start_offset": 0, "end_offset": 8}, {"id": 1479, "label": "Software", "start_offset": 307, "end_offset": 315}]}
{"id": 4985, "text": "A data use register (also known as a data release register or list of approved projects) offers the public a clear record of how their data is being used, by who and most importantly for what purpose. The Gateway has implemented a Data Use Register to improve the transparency and visibility of research projects undertaken across our Alliance data custodians. \n\nA widget for the data use register is also available and aims to provide further transparency in the use of health data for research by making data uses more accessible. Once embedded in a custodian's website, a clickable button takes visitors from a custodian's webpage to the Gateway data use register - prefiltered to display their data uses only - in a single step.", "entities": []}
{"id": 4986, "text": "Federated metadata onboarding allows data providers to synchronise existing metadata catalogues with the Gateway", "entities": []}
{"id": 4987, "text": "Cohort Discovery is a new Gateway feature that will allow users to carry out a more specific search and assessment on datasets listed in the Gateway to improve the discovery of datasets. Using the tool users can search across multiple datasets to find cohorts (groups) of patients with specific, defined characteristics (e.g patients that don't smoke aged between 18-30 and who live in England).\n\nWe hope the tool will save both researchers time in finding datasets they need for their research, and also save data custodians time, by minimising enquiries to them about the content of the datasets they hold.\n\nStatistical disclosure control policies are in place by default by data custodians on the query results, so low numbers of patients will be excluded to minimise any potential risk of identification.", "entities": [{"id": 836, "label": "Software", "start_offset": 0, "end_offset": 16}]}
{"id": 4988, "text": "Pre-prints papers and articles which site the use of health datasets for research (uploaded by Gateway users)", "entities": []}
{"id": 4989, "text": "Software, scripts and useful resources (uploaded by Gateway users)", "entities": []}
{"id": 4990, "text": "Our ambition is for the Gateway to support a streamlined, proportionate approach to access requests based on the five safes model for research and innovation uses with a clearpublic benefit, in line with the Principles for Participation.\n\nWe aim to make life easier for both requestors and decision makers through a combinationof automation, built-in validation, transparency of progress and the capability to hostvirtual data access request panels.\n\n The intention is to build on existing cross-sector best practice both nationally across the UKand internationally.", "entities": []}
{"id": 4991, "text": "The Health Data Research Innovation Gateway is a common entry point for researchers and innovators to search for and find datasets of interest and to request access to. It is possible to search for health datasets and health data assets via a keyword search and filtering options.", "entities": [{"id": 1710, "label": "Software", "start_offset": 4, "end_offset": 43}]}
{"id": 4992, "text": "Innovation Gateway Standards", "entities": []}
{"id": 4993, "text": "Courses and qualifications related to health data research", "entities": []}
{"id": 4994, "text": "The metadata onboarding form enables data custodians to make their datasets findable through the Gateway by providing rich metadata descriptions of their datasets.", "entities": []}
{"id": 4995, "text": "The Innovation Gateway provides a common entry point to discover and enquire about access to UK health datasets for research and innovation. It provides detailed information about the datasets, which are held by members of the UK Health Data Research Alliance, such as a description, size of the population, and the legal basis for access.\nThe Gateway includes the ability to search for research projects, publications and health data tools, such as those related to COVID-19. New interactive features provide a community forum for researchers to collaborate and connect and the ability to add research projects.\nThe Innovation Gateway does not hold or store any datasets or patient or health data but rather acts as a portal to allow discovery of datasets and to request access to them for health research. To access the data, users need to sign in and then follow the access request process.", "entities": [{"id": 1263, "label": "Software", "start_offset": 4, "end_offset": 22}, {"id": 1264, "label": "Software", "start_offset": 617, "end_offset": 635}]}
{"id": 4996, "text": "Open-source code for the Innovation Gateway", "entities": []}
{"id": 4997, "text": "The HDR UK Phenotype Library is a comprehensive, open access resource providing the research community with information, tools and phenotyping algorithms for UK electronic health records.", "entities": [{"id": 1709, "label": "Software", "start_offset": 4, "end_offset": 28}]}
{"id": 4998, "text": "The Health Data Research Innovation Gateway API service source code", "entities": [{"id": 610, "label": "Software", "start_offset": 0, "end_offset": 56}]}
{"id": 4999, "text": "The technical advisor and computer scientist on the project (Matthew Williams) created a new database for the Grosvenor Museum's collection of objects for the period 1000-2000. The database is designed to be 'front facing' to allow members of the public to search the Grosvenor Museum's collections. It has also been designed so that members of the public and university students can add content to the database. The database will eventually be hosted by the University of Chester and by CWAC museums.", "entities": []}
{"id": 5000, "text": "Virtual Reality Reconstruction of Medieval St John's Church Chester. Participants can move through the medieval church and interact with the medieval objects in the church.", "entities": [{"id": 1047, "label": "Software", "start_offset": 0, "end_offset": 67}]}
{"id": 5001, "text": "Software for interpreting CCD data , removing pixel level noise, and delivering an absorbance spectra", "entities": []}
{"id": 5002, "text": "CEH developed a Matlab program for analysis of the full waveform spectra from the instrument. The software used Ed Tipping's algorithm for prediction of DOC in mg/l, using a pair fo wavelengths in the range 290 to 350 nm. The tool estimates extinction coefficients for any pair of wavelengths, before applying these values before calculating an estimate of DOC.", "entities": [{"id": 1480, "label": "Software", "start_offset": 0, "end_offset": 3}]}
{"id": 5003, "text": "pml is a tool that composes POETS applications from manifest, code and graph files. It provides a developer-friendly input format, abstract programming models and programmable code generation functions to developers wishing to write software for POETS.", "entities": [{"id": 1708, "label": "Software", "start_offset": 0, "end_offset": 3}]}
{"id": 5004, "text": "pstack is a distributed POETS simulation stack based on Redis. It exposes the compute power of a hetrogeneous array of POETS back-end engines to multiple users in a POSIX-like environment.", "entities": [{"id": 611, "label": "Software", "start_offset": 0, "end_offset": 6}]}
{"id": 5005, "text": "This is our ports of the Unikraft and FlexOS operating systems to the ARM Morello platform, using its hybrid capability mode. This software was developed as part of the research effort that led to this paper:\nJohn Alistair Kressel, Hugo Lefeuvre, and Pierre Olivier, &quot;Software Compartmentalization Trade-Offs with Hardware Capabilities&quot;, Workshop on Programming Languages and Operating Systems (PLOS), 2023\n\nFor more information see the project's website https://olivierpierre.github.io/project-flexcap/", "entities": [{"id": 838, "label": "Software_Url", "start_offset": 465, "end_offset": 513}]}
{"id": 5006, "text": "Loupe is a tool designed to help you analyze the system call usage of applications. Loupe can do primarily two things: (1) collect data about the system call usage of a given set of applications, and (2) analyse the data collected for these applications. It can tell you what system calls a custom OS needs to implement to run the applications, and visualise these numbers in a variety of plots.", "entities": [{"id": 1048, "label": "Software", "start_offset": 0, "end_offset": 5}, {"id": 1049, "label": "Software", "start_offset": 84, "end_offset": 89}]}
{"id": 5007, "text": "THERM (THrough-life Energy and Resource Modelling) is a software tool for sustainable manufacturing, which integrates modelling of factory processes within their environment, assesses the materials, energy and waste of the processes and uses data analysis tools to understand the opportunities that exist for reducing energy consumption and carbon emissions, integrated with the factory building. Initially being released as an IES consulting service, THERM will in due course be available as part of the IES software suite.", "entities": [{"id": 1276, "label": "Software", "start_offset": 0, "end_offset": 5}, {"id": 1277, "label": "Software", "start_offset": 7, "end_offset": 49}, {"id": 1278, "label": "Software", "start_offset": 452, "end_offset": 457}]}
{"id": 5008, "text": "https://github.com/maprdhm/synpopCanada/commits/v2.0.0 Code to generate a synthetic population of individuals and households at a fine geographical level (DA) for Canada for the years 2016 to 2042, based on 2016 census data and population projections. Generate the synthetic population of individuals and households for 9 population growth scenarios: five medium-growth scenarios (M1, M2, M3, M4 and M5) reflect different internal migration patterns observed in the past, low-growth (LG) and high-growth (HG) scenarios explore either lower or higher population growth than in the medium-growth scenarios, and fast-aging (FA) and slow-aging (SA) scenarios consider either faster or slower population aging than in the medium-growth scenarios. These scenarios are defined by Statistics Canada.", "entities": [{"id": 1481, "label": "Software_Url", "start_offset": 0, "end_offset": 54}]}
{"id": 5009, "text": "A relational database and bespoke front end that integrates community reporting of violence against women and girls with institutional records of consultations, responses, and referrals,", "entities": []}
{"id": 5010, "text": "Development of Little Sister 2.0, an application that integrates monitoring of gender-based violence through smartphones with an administrative dashboard that allows allocation and follow-up of crisis centre clients. Developed by Mindnerves technology, India.", "entities": [{"id": 612, "label": "Software", "start_offset": 15, "end_offset": 29}]}
{"id": 5011, "text": "The app allows you to interactively explore drought datasets generated by the STAR project for the whole of Thailand. The drought indicators included reflect the outcomes of engagement activities with our project stakeholders in Thailand, and they are applied to a range of observed and state-of-the-art satellite remote-sensed data.", "entities": []}
{"id": 5012, "text": "First official release of Driftfusion. The recent application of lead-halide perovskites as an active layer material in thin film semiconductor devices including solar cells, light emitting diodes (LEDs), and memristors has motivated the development of several new drift-diffusion models that can include the effects of both mobile electronic and ionic charge carriers. Here, we present Driftfusion, a versatile simulation tool built for simulating one-dimensional ordered semiconductor devices with mixed ionic-electronic conducting layers. Driftfusion enables users to simulate devices with virtually any number of layers and with up to four charge carrier species (electrons and holes by default plus up to two ionic species). The time-dependent carrier continuity equations are fully-coupled to Poisson's equation enabling transient optoelectronic device measurement protocols to be simulated. In addition to the material parameters, users have direct access to adapt carrier transport, recombination and generation models as well as the system boundary conditions. Furthermore, a graded-interface approach circumvents the requirement for boundary conditions at material interfaces and enables interface-specific properties, such as high rates of interfacial recombination, to be introduced.", "entities": [{"id": 1050, "label": "Software", "start_offset": 26, "end_offset": 37}, {"id": 1051, "label": "Software", "start_offset": 542, "end_offset": 553}]}
{"id": 5013, "text": "First official release of Driftfusion. The recent application of lead-halide perovskites as an active layer material in thin film semiconductor devices including solar cells, light emitting diodes (LEDs), and memristors has motivated the development of several new drift-diffusion models that can include the effects of both mobile electronic and ionic charge carriers. Here, we present Driftfusion, a versatile simulation tool built for simulating one-dimensional ordered semiconductor devices with mixed ionic-electronic conducting layers. Driftfusion enables users to simulate devices with virtually any number of layers and with up to four charge carrier species (electrons and holes by default plus up to two ionic species). The time-dependent carrier continuity equations are fully-coupled to Poisson's equation enabling transient optoelectronic device measurement protocols to be simulated. In addition to the material parameters, users have direct access to adapt carrier transport, recombination and generation models as well as the system boundary conditions. Furthermore, a graded-interface approach circumvents the requirement for boundary conditions at material interfaces and enables interface-specific properties, such as high rates of interfacial recombination, to be introduced.", "entities": [{"id": 1279, "label": "Software", "start_offset": 26, "end_offset": 37}, {"id": 1280, "label": "Software", "start_offset": 387, "end_offset": 398}, {"id": 1281, "label": "Software", "start_offset": 542, "end_offset": 553}]}
{"id": 5014, "text": "This is an initial iteration of an R package to read the WINFAP files which are routinely used for Flood Frequency Estimation in the UK. A standard way to read the data is a first step towards more reproducible workflows for flood frequency estimation and for a more through investigation of the POT records which have been underutilised until now.", "entities": []}
{"id": 5015, "text": "Coastal ocean model", "entities": [{"id": 1707, "label": "Software", "start_offset": 0, "end_offset": 19}]}
{"id": 5016, "text": "We published (https://github.com/csynbiosys/PLac_CDC_paper) the software we use for the in-silico characterisation of genetic promoter. This software automatically identifies the best perturbation to be applied to cells in order to maximise the information extracted from the in vivo characterisation experiments we carry out in microfluidics.", "entities": [{"id": 613, "label": "Software_Url", "start_offset": 14, "end_offset": 58}]}
{"id": 5017, "text": "Bela (formerly called BeagleRT) is an ultra-low-latency real-time audio platform for the BeagleBone Black embedded computer. It can be used to build musical instruments, including the D-Box hackable musical instrument developed for the EPSRC Hackable Instruments project. The software is of particular interest to audio and music researchers, especially those building real-time systems.\n\nWith less than 1ms of latency between action and sound, Bela performs faster than any other computer-based environment on the market, including high-spec laptops. It also features audio-rate sampling of every analog and digital input which makes design of sensor systems convenient. In 2015, a built-in browser-based IDE was added along with support for the Pure Data graphical computer music language widely used in the digital music community. Since 2016, we have continued to add support for other programming languages and hardware accessories, as well as extending the documentation and online resources available to the community.", "entities": [{"id": 840, "label": "Software", "start_offset": 0, "end_offset": 4}, {"id": 841, "label": "Software", "start_offset": 22, "end_offset": 30}, {"id": 842, "label": "Software", "start_offset": 445, "end_offset": 449}]}
{"id": 5018, "text": "We developed in collaboration with University of Manchester the first implementation of quantum entanglement into the GEANT4 software. This is currently in use in our InnovateUK programme, but as it is developed as part of the GEANT4 package it will eventually be open source and available to all GEANT4 users. \n\nThe package was improved and finalised in late 2017", "entities": [{"id": 1052, "label": "Software", "start_offset": 118, "end_offset": 124}, {"id": 1053, "label": "Software", "start_offset": 227, "end_offset": 233}, {"id": 1054, "label": "Software", "start_offset": 297, "end_offset": 303}]}
{"id": 5019, "text": "The pipeline provides a simple method to segment and extract grain traits from 3D models", "entities": []}
{"id": 5020, "text": "The software is an open-source toolbox to perform MRI image analysis using a technique I have developed, called Soma And Neurite Density Imaging (SANDI), using a fast and robust framework called Accelerated Microstructure Imaging via Convex Optimisation (AMICO).", "entities": [{"id": 1483, "label": "Software", "start_offset": 112, "end_offset": 144}, {"id": 1484, "label": "Software", "start_offset": 146, "end_offset": 151}, {"id": 1485, "label": "Software", "start_offset": 195, "end_offset": 253}, {"id": 1486, "label": "Software", "start_offset": 255, "end_offset": 260}]}
{"id": 5021, "text": "The CaCHE Data Navigator is a web-based software application which will enhance a researcher's ability to discover housing and housing-related data, with the aim of encouraging re-use and re-purposing of existing data. It is being designed to make the search and discovery of these data easier by proving access to meta-data on a wide variety of housing data sets including Government Surveys, routinely collected administrative data, private sector data and industry data. The data will be for a variety of spatial scales from the whole of the UK down to the four nations, regions, local authorities and smaller spatial units. As well as providing access to meta-data, where possible the CaCHE Data Navigator will also provide access to existing open data through various APIs and Data Centres. The CaCHE Data Navigator will also host a small number of bespoke open source data sets that have been identified as being valuable to the housing research community. The CaCHE Data Navigator is still in development and it's technical specification will change over time.", "entities": [{"id": 1704, "label": "Software", "start_offset": 4, "end_offset": 24}, {"id": 1705, "label": "Software", "start_offset": 800, "end_offset": 820}, {"id": 1706, "label": "Software", "start_offset": 967, "end_offset": 987}]}
{"id": 5022, "text": "This software computes properties of composite electrodes using large-scale x-ray tomography data. It uses high-performance parallel solvers to scale to millions of voxels in a dataset. The HPC-based parallel design allows to operate on extremely large datasets (40GB and larger) in a timely fashion. This code allows to process tomographies with an order of magnitude improvement in computation speed (minutes rather than days) over alternative existing codes.", "entities": []}
{"id": 5023, "text": "One of our project's ambitions was to introduce Explainable AI techniques into the digital humanities (e.g. in using gradient-based heatmaps in our online exhibition to explain neural network behaviour visually). Explainability is an issue in using OpenAI's CLIP network, because the dataset it has been trained on is has not been publicly released. Therefore in attempting to understand the cultural bias in CLIP, alternatives to 'dataset critique' must be sought. \n\nStapler is an attempt to do this by generating a large, controlled set of prompts based on existing artworks from an existing dataset (the Web Gallery of Art). Stapler uses a CLIP-guided image generation system to generate images from these prompts (each prompt leading to several images to account for randomisation). Stapler then contains code to compare these generations to the originals, in terms of colour palettes, neural 'style' and 'content' distances (from style transfer methods), and CLIP embeddings themselves. It also contains code to extract the relative search popularity of individual artists from Google Trends, in order to investigate the hypothesis that better-known artists are more precisely 'remembered' by the CLIP network.", "entities": [{"id": 843, "label": "Software", "start_offset": 468, "end_offset": 475}, {"id": 844, "label": "Software", "start_offset": 628, "end_offset": 635}, {"id": 845, "label": "Software", "start_offset": 786, "end_offset": 794}]}
{"id": 5024, "text": "This software repository is the basis for our interactive online exhibition (see &quot;Artistic and Creative Products&quot;), and in particular produces the machine learning results which many GLAM sector organisations may not have the knowledge to implement themselves. In particular, it contains code to:\n- automatically generate images from artwork titles (CLIP-guided GANs)\n- automatically extract keywords from artwork descriptions (via DistilBERT)\n- automatically generate descriptive captions from images (via Caption Transformers)\n- automatically generate heatmaps for captions (via Grad-CAM)\n- compute text-text similarities, image-image similarities, and image-text similarities (via CLIP). \n\nThe code is designed to be reusable, in that other GLAM sector institutions, research projects etc can use the same code on different datasets. Although it was developed using a high performance GPU cluster (see Infrastructure), the final models can be run on free-to-use cloud computing systems (e.g. Google Colab), and therefore don't require specialised hardware to reproduce. The code is relatively well-documented and liberally licensed (MIT) so that future research projects can also adapt it, building on the codebase or adding functionality.", "entities": []}
{"id": 5025, "text": "Software for text extraction and analysis, including workflows to handle big data sets extracted from social media", "entities": []}
{"id": 5026, "text": "Crowdsourcing templates to support content analysis. These are available on the Ancient Identities Today GitHub account, together with other research software developed (i.e. scrapers).", "entities": []}
{"id": 5027, "text": "Bespoke research software developed to undertake research on the Heritage of Brexit. Programming languages: R, Python.", "entities": [{"id": 1703, "label": "Software", "start_offset": 0, "end_offset": 25}]}
{"id": 5028, "text": "Software developed for the article: Bonacchi, C, Krzyzanska, M (2021) Heritage-based tribalism in Big Data Ecologies. Big Data &amp; Society\nThis repository is a supplement to the paper Human origins and antagonistic othering: a study of heritage-based tribalism on Twitter. It contains the codes used for data collection and analysis, carried out using Mongo Database, R and Python", "entities": []}
{"id": 5029, "text": "Automatically tune the location, number, transmit power, and antenna configuration of cells or individual antennas within a network or multiple networks based on the configurable spatial-temporary traffic pattern to achieve predefined KPIs in various scenarios.", "entities": []}
{"id": 5030, "text": "The software automates the scoring of seed germination of lots of cereal, Brassica, tomato, pepper, maize and rice seeds.", "entities": []}
{"id": 5031, "text": "This is the release of a new version (v2.0.0) of TREvoSim. The first release and the underlying model was described in detail in the following paper: Keating, J.N., Sansom, R.S., Sutton, M.D., Knight, C.G. &amp; Garwood, R.J. 2020. Morphological phylogenetics evaluated using novel evolutionary simulations. Systematic Biology 69(5): 897-912. doi:10.1093/sysbio/syaa012 Version 2.0.0 accompanies the preprint and paper below: Mongiardino Koch, N., Garwood, R.J. &amp; Parry, L.A. Preprint. Fossils improve phylogenetic analyses of morphological characters. bioRxiv. doi: 10.1101/2020.12.03.410068v1 Mongiardino Koch, N., Garwood, R.J. &amp; Parry, L.A. 2021. Fossils improve phylogenetic analyses of morphological characters. Proceedings of the Royal Society B: Biological Sciences The code is archived on zenodo.org: Documentation: TREvoSim Online Documentation Change log: The changes in v2.0.0 are described and discussed fully in the associated paper. In brief, these allow TREvoSim v2.0.0 trees and data to achieve benchmarks calculated from twelve total evidence analyses, as well as respresenting ongoing development of the package. Changes are: Addition of multiple playing fields option. Playing fields can have independent or identical environments. The option to overwrite a random individual when a juveniles is returned to the playing field (instead of the least fit one). User control of the fitness target in the fitness algorithm (see Keating et al. 2020). A fitness histogram functionality to assess the fitness landscape in the simulation. User control of the strength of selection (see Mongiardino Koch et al. 2021 for discussion). Multiple environments per playing field. Organism fitness is assessed against each environment, and the fitness of an organism is defined by the environment they are best suited to. The code has been refactored (the biggest change being to the underlying data structures/classes), and the simulation now uses Qt QRandomGenerator tools rather than incorporating random data. A user-accessible test suite has been added. Release information: Windows A zip containing all required binaries can be downloaded from the assets below. Alternatively an installer is provided. See notes below: Note 1: The .zip archive contains an executable TREvoSim_2.0.0.exe. The .zip can be extracted and the program run by double clicking this.exe file in the ./bin folder. All the required libraries have been included and are found in the ./bin folder. Mac A zip containing TREovSim can be downloaded from the assets below. To install the software, drag and drop the required .app folder(s) into the Applications folder. You may be required to the approve the software in security and privacy settings before it will launch. Linux Any Linux users willing to test a Linux build should contact palaeoware@gmail.com.", "entities": [{"id": 1282, "label": "Software", "start_offset": 49, "end_offset": 57}, {"id": 1283, "label": "Software", "start_offset": 833, "end_offset": 841}, {"id": 1284, "label": "Software", "start_offset": 978, "end_offset": 986}, {"id": 1285, "label": "Software", "start_offset": 2284, "end_offset": 2292}, {"id": 1286, "label": "Software", "start_offset": 2506, "end_offset": 2514}]}
{"id": 5032, "text": "A web tool to allow volcanologists to determine the volume of a volcanic deposit from their own field data", "entities": []}
{"id": 5033, "text": "The software has been developed as part of the SKA Science Data Processor Platform. It adds new functionality to the OpenStack platform to enable high performance workflows and other monitoring. The software has been added back into the main OpenStack repository for general use.", "entities": []}
{"id": 5034, "text": "This is a software architecture and associated prototype code for the SKA Science Data Processor.\n\nThe software implements a novel architecture for a highly scalable data analytics engine able to scale to at least 250 PFlop performance. The design is highly innovative and supports extensibility and maintainability as key drivers as well as performance.", "entities": []}
{"id": 5035, "text": "The software is a reference implementation of the imaging and calibration algorithms required for SKA imaging. It is written in python and will be delivered to the SKA Organisation as part of the deliverables form the design work.\n\nThe latest version of the library has also significant performance and scalability itself in conjunction with the DASK execution framework / environment", "entities": []}
{"id": 5036, "text": "The aviation industry is set for a huge increase in emissions with the government planning for an extra 70 million passengers a year by 2050. Despite years of opposition from groups, Bristol Airport has been granted an expansion - albeit with constrained planning conditions, such as limits on night flights and other metrics. However, it is difficult to check whether these limits are being upheld. Eyes on Bristol Airport brings local direct action group BAAN (Bristol Airport Action Network) with designers and developers to capture and communicate air traffic data to hold Bristol Airport accountable to its pledges. The software used monitors flights to check adherence to legal quotas and could also be rolled out to other groups fighting airport expansion across Europe.", "entities": []}
{"id": 5037, "text": "Englicious is a web-based platform developed for schoolteachers to teach English grammar in classrooms in a way that is both consistent with modern linguistic thinking and aligned to the UK National Curriculum goals and terminology. Initially developed for secondary schools, a follow-on project extended it to primary. Englicious contains large numbers of resources, including interactive assessments and games, that use examples taken from real English in use as far as possible (and dependent on the level).", "entities": [{"id": 1287, "label": "Software", "start_offset": 0, "end_offset": 10}, {"id": 1288, "label": "Software", "start_offset": 320, "end_offset": 330}]}
{"id": 5038, "text": "LIME is an advanced deep representation learning framework that can effectively extract high-quality network representation with significantly reduced memory footprints and computational time. The enhanced representation is critical to the procedure of decision making, such as scheduling or anomaly detection.", "entities": [{"id": 1487, "label": "Software", "start_offset": 0, "end_offset": 4}]}
{"id": 5039, "text": "C++ library of optimisation algorithms for the Vector Bin Packing problem. It contains C++ implementations of all algorithms presented in our paper &quot;Classification and evaluation of the algorithms for vector bin packing&quot; (submitted to Computers and OR and available in pre-print version at https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4450606).", "entities": []}
{"id": 5040, "text": "Open source framework for malware detection through heterogeneous graph attention networks", "entities": []}
{"id": 5041, "text": "Network emulation plays a important role in the design and prototyping of network technologies and architectures, and its relevance has only increased with the advent of recent network paradigms, such as Software Defined Networking (SDN) and Network Function Virtualization (NFV). The increasing interest in improving network automation and\nexpand softwarization has motivated the development of several novel application scenarios for network experimentation, including Network DevOps and Network Twins (NT). Nonetheless, automation in current emulation tools remains limited beyond topology creation and is negatively affected by the lack of high-level APIs capable of capturing and synchronizing complex node interaction scenarios. As well as this, current platforms tend to depend on human interaction in order to execute experimental scenarios. NES is an automated, cloud-native, and highly-parallelizable NEaaS platform, designed from the ground up for facilitating codeless experiment specification and autonomous network testing workflows in cloud Continuous Integration/Continuous Development (CI/CD) environments. NES can improve topology instantiation times in comparison to existing emulation platforms, whilst its life-cycle model can automate testing processes for complex network configurations using existing CI/CD platforms, like\nGitHub Actions.\n\nhttps://github.com/WillFantom/nescript", "entities": [{"id": 846, "label": "Software", "start_offset": 850, "end_offset": 853}, {"id": 847, "label": "Software", "start_offset": 1124, "end_offset": 1127}, {"id": 848, "label": "Software_Url", "start_offset": 1364, "end_offset": 1402}]}
{"id": 5042, "text": "An implementation of CAPA (Collective And Point Anomaly) for the detection\nof anomalies in time series data.", "entities": []}
{"id": 5043, "text": "Network Emulation-based Automated Testing (NEAT) is an automated testing framework for network configuration. NEAT allows network managers to define network topologies and tests through YAML files and run realistic network topologies and tests. Furthermore, network managers can control the fidelity of their network tests and bound the execution time of testing suites, as well as exploit parallelization of modern servers to speed up test execution.", "entities": [{"id": 1289, "label": "Software", "start_offset": 0, "end_offset": 41}, {"id": 1290, "label": "Software", "start_offset": 43, "end_offset": 47}, {"id": 1291, "label": "Software", "start_offset": 110, "end_offset": 114}]}
{"id": 5044, "text": "Wayfinder is a generic OS performance evaluation platform. Wayfinder is fully automated and ensures both the accuracy and reproducibility of results, all the while speeding up how fast tests are run on a system. Wayfinder is easily extensible and offers convenient APIs to: (i) Implement custom configuration space exploration techniques, (ii) Add new benchmarks; and, (iii) Support additional OS projects.", "entities": [{"id": 1488, "label": "Software", "start_offset": 0, "end_offset": 9}, {"id": 1489, "label": "Software", "start_offset": 59, "end_offset": 68}, {"id": 1490, "label": "Software", "start_offset": 212, "end_offset": 221}]}
{"id": 5045, "text": "The DataPlane Broker is an open and extensible service providing WIM management capabilities over SDN networks. The system can build point-to-multipoint virtual network over SDN networks. Furthermore, a driver for the service is available in the main source tree of the OSM orchestration framework.", "entities": [{"id": 1701, "label": "Software", "start_offset": 4, "end_offset": 20}]}
{"id": 5046, "text": "mzTab is the most recent standard format developed by the Proteomics Standards Initiative (PSI). mzTab is a flexible tab-delimited file that can capture identification and quantification results coming from mass spectrometry (MS)-based proteomics and metabolomics approaches. We here present an open-source Java Application Programming Interface (API) for mzTab called jmzTab. \nThe software allows the efficient processing of mzTab files, providing read and write capabilities, and is designed to be embedded in other software packages. The second key feature of the jmzTab model is that it provides a flexible framework to maintain the logical integrity between the metadata and the table-based sections in the mzTab files. In this article, as two example implementations, we also describe two stand-alone tools that can be used to validate mzTab files and to convert PRIDE XML files to mzTab.", "entities": [{"id": 615, "label": "Software", "start_offset": 369, "end_offset": 375}, {"id": 616, "label": "Software", "start_offset": 567, "end_offset": 573}]}
{"id": 5047, "text": "The ms-data-core-api is a free, open-source library for developing computational proteomics tools and pipelines. The Application Program Interface, written in Java, enables rapid tool creation by providing a robust, pluggable programming interface and common data model. The data model is based on controlled vocabularies/ontologies and captures the whole range of data types included in common proteomics experimental workflows, going from spectra to identifications to quantitative results. The library contains readers for three of the most used Proteomics Standards Initiative standard file formats: mzML, mzIdentML, and mzTab. In addition to mzML, it also supports other common mass spectra formats: dta, ms2, mgf, pkl, apl (text-based), mzXML and mzData (XML-based). Also, it can be used to read PRIDE XML, the original format used by the PRIDE database, one of the world-leading proteomics resources. Finally, we present a set of algorithms and tools whose implementation illustrates the simplicity of developing applications using the library.", "entities": [{"id": 849, "label": "Software", "start_offset": 4, "end_offset": 20}]}
{"id": 5048, "text": "One of the main objectives of the project was to deliver a simple user interface to provide access to all quantitative software in a single environment. This software is newly developed in this project, led by the Liverpool group, entitled Proteosuite (http://www.proteosuite.org/).", "entities": [{"id": 1055, "label": "Software", "start_offset": 240, "end_offset": 251}, {"id": 1056, "label": "Software_Url", "start_offset": 253, "end_offset": 280}]}
{"id": 5049, "text": "This software emulates a chromatography/mass spectrometry system for the purposes of exploring behaviours of different run controllers for metabolomics.", "entities": []}
{"id": 5050, "text": "The first public release of the Software Sustainability Institute Event Organisation Guide (SSI-EOG) - see https://www.software.ac.uk/news/announcing-ssi-event-organisation-guide for further information!", "entities": []}
{"id": 5051, "text": "The Software Sustainability Institute Event Organisation Guide (SSI-EOG) is host on Read the Docs - https://event-organisation-guide.readthedocs.io The GitHub project is available at - https://github.com/softwaresaved/event-organisation-guide The page is the release on Zenodo - https://zenodo.org/record/3970898 (the citation information on this page should be used when citing SSI-EOG, individual pages can be referenced from the Read the Docs site).", "entities": [{"id": 1697, "label": "Software", "start_offset": 4, "end_offset": 62}, {"id": 1698, "label": "Software", "start_offset": 64, "end_offset": 71}, {"id": 1699, "label": "Software_Url", "start_offset": 185, "end_offset": 242}, {"id": 1700, "label": "Software_Url", "start_offset": 279, "end_offset": 312}]}
{"id": 5052, "text": "The Software Sustainability Institute's low effort Fellowship Administration Tool (lowFAT) https://softwaresaved.github.io/lowfat/", "entities": [{"id": 617, "label": "Software", "start_offset": 40, "end_offset": 81}, {"id": 618, "label": "Software_Url", "start_offset": 91, "end_offset": 130}]}
{"id": 5053, "text": "esearch software is an integral part of the modern research ecosystem. Taken together, research software, alongside data, facilities, equipment and an overarching research question can be viewed as a research activity or experiment, worthy to be published. Conversely, a publication can be considered as a narrative that describes how the research objects are used together to reply to the research question.\n\nDepositing research software into a digital repository can offer significant benefits. By depositing not just papers, but software, and data sets, as well, researchers can store a more complete record of this ecosystem for future use to both the researchers who undertook the research and also the wider research community. Making research software available allows other researchers to inspect, replicate, reproduce and reuse the research, as manifested in the software, in the short term and to inspect, for the historical record, in the long term. It allows research software to remain available beyond the lifetime of any current project, or a researcher's current employment at a specific institution. Digital repositories can also provide unique persistent digital identifiers for software which can be cited and help researchers to get attribution and credit for their research software when it is used by others.\n\nThe Software Sustainability Institute, funded by Jisc, developed a set of complementary guides covering the main aspects of depositing software into digital repositories. These guides are intended for researchers, principal investigators and research leaders and research data and digital repository managers.\n\nThis deposit holds the sources of these guides, used to generate PDF and HTML (online) versions of the guides, and a PDF of the index page of the online version of the guides.", "entities": []}
{"id": 5054, "text": "This is a first pass at understanding software-related research outcomes recorded in ResearchFish. The data used has not been released, but can be downloaded from Gateway to Research. The forthcoming release will include data as well as software.", "entities": []}
{"id": 5055, "text": "An extension of the DMPOnline webtool to allow for the creation and management of software management plans.", "entities": []}
{"id": 5056, "text": "uCONFLY is an unconference resource management system. It provides document templates for a range of resource types and a means to allow event attendees to created documents based upon the templates made available to them.\n\nThe production deployment of uCONFLY is hosted at https://uconfly.org/.", "entities": [{"id": 1491, "label": "Software", "start_offset": 0, "end_offset": 7}, {"id": 1492, "label": "Software", "start_offset": 253, "end_offset": 260}, {"id": 1493, "label": "Software_Url", "start_offset": 274, "end_offset": 294}]}
{"id": 5057, "text": "A Software Management Plan (SMP) can help you to define a set of structures and goals to understand your research software including what you are going to develop; who the software is for (even if it is just for yourself); how you will deliver your software to its intended users; how it will help them; and how you will assess whether it has helped them, and contributed to research, in the ways that you intended. An SMP also helps you to understand how you can support those who wish to, or do, use your research software; how your software relates to other artefacts in your research ecosystem; and how you will ensure that your software remains available beyond the lifetime of your current project.\n\nThis checklist will help you to write an SMP. It consists of sections that cover the key elements that an SMP should include.", "entities": [{"id": 933, "label": "Software", "start_offset": 2, "end_offset": 27}, {"id": 934, "label": "Software", "start_offset": 28, "end_offset": 31}, {"id": 935, "label": "Software", "start_offset": 419, "end_offset": 422}, {"id": 936, "label": "Software", "start_offset": 746, "end_offset": 750}, {"id": 937, "label": "Software", "start_offset": 812, "end_offset": 816}]}
{"id": 5058, "text": "CodeMeta contributors are creating a minimal metadata schema for science software and code, in JSON and XML. The goal of CodeMeta is to create a concept vocabulary that can be used to standardize the exchange of software metadata across repositories and organizations. CodeMeta started by comparing the software metadata used across multiple repositories, which resulted in the CodeMeta Metadata Crosswalk. That crosswalk was then used to generate a set of software metadata concepts, which were arranged into a JSON-LD context for serialization (see codemeta.jsonld, or an example CodeMeta document).", "entities": [{"id": 619, "label": "Software", "start_offset": 0, "end_offset": 8}, {"id": 620, "label": "Software", "start_offset": 121, "end_offset": 129}, {"id": 621, "label": "Software", "start_offset": 269, "end_offset": 277}, {"id": 622, "label": "Software", "start_offset": 378, "end_offset": 386}, {"id": 623, "label": "Software", "start_offset": 582, "end_offset": 590}]}
{"id": 5059, "text": "The Software Assessment Framework is a pilot implementation to make it easier for developers to understand the &quot;quality&quot; of a piece of research software, which in turn will allow them to improve software reuse and increase recognition for good software development practice.", "entities": [{"id": 852, "label": "Software", "start_offset": 4, "end_offset": 33}]}
{"id": 5060, "text": "Collaboration tool to create surveys and analyse data about Research Software Engineers around the world\n\nThis software is used to create and analyse international surveys. It use csv files to store questions and answers that are later transformed into a limesurvey TSV file. The analysis are using python and are shared within jupyter notebooks.", "entities": []}
